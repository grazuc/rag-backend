2025-05-04 11:28:04,886 - api.main - INFO - Iniciando aplicación API RAG
2025-05-04 11:28:35,294 - api.main - INFO - Iniciando aplicación API RAG
2025-05-04 11:29:19,002 - api.main - INFO - Iniciando aplicación API RAG
2025-05-04 11:29:25,715 - api.main - INFO - Request: GET /docs | Status: 200 | Duration: 0.0009s
2025-05-04 11:29:26,251 - api.main - INFO - Request: GET /openapi.json | Status: 200 | Duration: 0.0150s
2025-05-04 11:30:11,498 - api.main - ERROR - Error no manejado: POST /query | Error: 'QueryRequest' object has no attribute 'get'
2025-05-04 11:30:11,499 - api.main - INFO - Request failed: POST /query | Duration: 0.0161s
2025-05-04 11:30:33,765 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-04 11:30:33,766 - api.main - INFO - Inicializando conexión a PGVector
2025-05-04 11:30:33,766 - api.main - INFO - Inicializando modelo de embeddings
2025-05-04 11:30:35,588 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-04 11:30:50,217 - api.main - INFO - Request: POST /search | Status: 200 | Duration: 16.4544s
2025-05-04 11:32:36,112 - api.main - ERROR - Error no manejado: POST /query | Error: 'QueryRequest' object has no attribute 'get'
2025-05-04 11:32:36,116 - api.main - INFO - Request failed: POST /query | Duration: 0.0512s
2025-05-04 11:35:51,312 - api.main - INFO - Cerrando recursos y conexiones
2025-05-04 11:38:17,100 - api.main - INFO - Iniciando aplicación API RAG
2025-05-04 11:38:25,553 - api.main - INFO - Request: GET /docs | Status: 200 | Duration: 0.0007s
2025-05-04 11:38:26,171 - api.main - INFO - Request: GET /openapi.json | Status: 200 | Duration: 0.0101s
2025-05-04 11:38:30,993 - api.main - INFO - Nueva consulta: {"query_id": "q-1746369510", "timestamp": "2025-05-04T11:38:30.993889", "query_length": 83, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-04 11:38:30,994 - api.main - INFO - Inicializando modelo de reescritura de consultas
2025-05-04 11:38:33,178 - api.main - ERROR - Error en procesamiento de consulta: name 'get_llm' is not defined
Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 774, in query_documents
    chain = get_qa_chain()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 326, in get_qa_chain
    llm=get_llm(),
        ^^^^^^^
NameError: name 'get_llm' is not defined
2025-05-04 11:38:33,181 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 2.1915s
2025-05-04 11:40:22,762 - api.main - INFO - Cerrando recursos y conexiones
2025-05-04 11:40:45,096 - api.main - INFO - Iniciando aplicación API RAG
2025-05-04 11:40:45,112 - api.main - INFO - Request: GET /docs | Status: 200 | Duration: 0.0009s
2025-05-04 11:40:46,097 - api.main - INFO - Request: GET /openapi.json | Status: 200 | Duration: 0.0164s
2025-05-04 11:40:55,355 - api.main - INFO - Nueva consulta: {"query_id": "q-1746369655", "timestamp": "2025-05-04T11:40:55.355267", "query_length": 83, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-04 11:40:55,356 - api.main - INFO - Inicializando modelo de reescritura de consultas
2025-05-04 11:40:58,018 - api.main - ERROR - Error al obtener LLM de forma síncrona: This event loop is already running
2025-05-04 11:40:58,019 - api.main - ERROR - Error en procesamiento de consulta: No se pudo inicializar el modelo LLM: This event loop is already running
Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 1132, in get_llm
    return loop.run_until_complete(llm_cache.get_llm())
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\Lib\asyncio\base_events.py", line 695, in run_until_complete
    self._check_running()
    ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\Lib\asyncio\base_events.py", line 631, in _check_running
    raise RuntimeError('This event loop is already running')
RuntimeError: This event loop is already running

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 774, in query_documents
    chain = get_qa_chain()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 326, in get_qa_chain
    llm=get_llm(),
        ~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 1135, in get_llm
    raise RuntimeError(f"No se pudo inicializar el modelo LLM: {e}")
RuntimeError: No se pudo inicializar el modelo LLM: This event loop is already running
2025-05-04 11:40:58,026 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 2.6790s
2025-05-04 11:41:18,299 - api.main - INFO - Cerrando recursos y conexiones
2025-05-04 11:41:35,894 - api.main - INFO - Iniciando aplicación API RAG
2025-05-04 11:41:49,406 - api.main - INFO - Iniciando aplicación API RAG
2025-05-04 11:42:01,945 - api.main - INFO - Iniciando aplicación API RAG
2025-05-04 11:42:13,229 - api.main - INFO - Iniciando aplicación API RAG
2025-05-04 11:43:08,867 - api.main - INFO - Nueva consulta: {"query_id": "q-1746369788", "timestamp": "2025-05-04T11:43:08.861581", "query_length": 83, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-04 11:43:08,876 - api.main - INFO - Inicializando modelo de reescritura de consultas
2025-05-04 11:43:12,225 - api.main - ERROR - Error al obtener LLM de forma síncrona: This event loop is already running
2025-05-04 11:43:12,227 - api.main - ERROR - Error en procesamiento de consulta: No se pudo inicializar el modelo LLM: This event loop is already running
Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 261, in get_llm
    return loop.run_until_complete(llm_cache.get_llm())
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\Lib\asyncio\base_events.py", line 695, in run_until_complete
    self._check_running()
    ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\Lib\asyncio\base_events.py", line 631, in _check_running
    raise RuntimeError('This event loop is already running')
RuntimeError: This event loop is already running

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 795, in query_documents
    chain = get_qa_chain()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 347, in get_qa_chain
    llm=get_llm(),
        ~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 264, in get_llm
    raise RuntimeError(f"No se pudo inicializar el modelo LLM: {e}")
RuntimeError: No se pudo inicializar el modelo LLM: This event loop is already running
2025-05-04 11:43:12,250 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 3.6186s
2025-05-04 11:44:42,810 - api.main - INFO - Cerrando recursos y conexiones
2025-05-04 12:01:10,118 - api.main - INFO - Iniciando aplicación API RAG
2025-05-04 12:01:20,738 - api.main - INFO - Request: GET /docs | Status: 200 | Duration: 0.0005s
2025-05-04 12:01:21,774 - api.main - INFO - Request: GET /openapi.json | Status: 200 | Duration: 0.0154s
2025-05-04 12:01:29,895 - api.main - INFO - Nueva consulta: {"query_id": "q-1746370889", "timestamp": "2025-05-04T12:01:29.895793", "query_length": 83, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-04 12:01:29,896 - api.main - INFO - Inicializando modelo de reescritura de consultas
2025-05-04 12:01:32,531 - api.main - ERROR - Error al inicializar LLM: 1 validation error for ChatDeepSeek
model
  Field required [type=missing, input_value={'model_kwargs': {'deepse...c4722bf312a5c3eb6938b'}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
2025-05-04 12:01:32,531 - api.main - ERROR - Error al obtener LLM de forma síncrona: No se pudo inicializar el modelo LLM: 1 validation error for ChatDeepSeek
model
  Field required [type=missing, input_value={'model_kwargs': {'deepse...c4722bf312a5c3eb6938b'}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
2025-05-04 12:01:32,532 - api.main - ERROR - Error en procesamiento de consulta: No se pudo inicializar el modelo LLM: No se pudo inicializar el modelo LLM: 1 validation error for ChatDeepSeek
model
  Field required [type=missing, input_value={'model_kwargs': {'deepse...c4722bf312a5c3eb6938b'}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 495, in get_llm
    llm = ChatDeepSeek(deepseek_api_key=settings.deepseek_api_key)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\load\serializable.py", line 130, in __init__
    super().__init__(*args, **kwargs)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\pydantic\main.py", line 253, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
pydantic_core._pydantic_core.ValidationError: 1 validation error for ChatDeepSeek
model
  Field required [type=missing, input_value={'model_kwargs': {'deepse...c4722bf312a5c3eb6938b'}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 263, in get_llm
    return loop.run_until_complete(llm_cache.get_llm())
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\nest_asyncio.py", line 98, in run_until_complete
    return f.result()
           ~~~~~~~~^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\Lib\asyncio\futures.py", line 199, in result
    raise self._exception.with_traceback(self._exception_tb)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\Lib\asyncio\tasks.py", line 304, in __step_run_and_handle_result
    result = coro.send(None)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 501, in get_llm
    raise RuntimeError(f"No se pudo inicializar el modelo LLM: {e}")
RuntimeError: No se pudo inicializar el modelo LLM: 1 validation error for ChatDeepSeek
model
  Field required [type=missing, input_value={'model_kwargs': {'deepse...c4722bf312a5c3eb6938b'}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 797, in query_documents
    chain = get_qa_chain()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 349, in get_qa_chain
    llm=get_llm(),
        ~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 266, in get_llm
    raise RuntimeError(f"No se pudo inicializar el modelo LLM: {e}")
RuntimeError: No se pudo inicializar el modelo LLM: No se pudo inicializar el modelo LLM: 1 validation error for ChatDeepSeek
model
  Field required [type=missing, input_value={'model_kwargs': {'deepse...c4722bf312a5c3eb6938b'}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
2025-05-04 12:01:32,541 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 2.6499s
2025-05-04 12:01:49,102 - api.main - INFO - Cerrando recursos y conexiones
2025-05-04 21:13:11,059 - api.main - INFO - Iniciando aplicación API RAG
2025-05-04 21:14:30,944 - api.main - INFO - Request: GET /docs | Status: 200 | Duration: 0.0004s
2025-05-04 21:14:31,558 - api.main - INFO - Request: GET /openapi.json | Status: 200 | Duration: 0.0139s
2025-05-04 21:17:27,542 - api.main - INFO - Nueva consulta: {"query_id": "q-1746404247", "timestamp": "2025-05-04T21:17:27.541938", "query_length": 83, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-04 21:17:27,542 - api.main - INFO - Inicializando modelo de reescritura de consultas
2025-05-04 21:17:30,243 - api.main - ERROR - Error al inicializar LLM: 1 validation error for ChatDeepSeek
model
  Field required [type=missing, input_value={'model_kwargs': {'deepse...c4722bf312a5c3eb6938b'}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
2025-05-04 21:17:30,244 - api.main - ERROR - Error al obtener LLM de forma síncrona: No se pudo inicializar el modelo LLM: 1 validation error for ChatDeepSeek
model
  Field required [type=missing, input_value={'model_kwargs': {'deepse...c4722bf312a5c3eb6938b'}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
2025-05-04 21:17:30,245 - api.main - ERROR - Error en procesamiento de consulta: No se pudo inicializar el modelo LLM: No se pudo inicializar el modelo LLM: 1 validation error for ChatDeepSeek
model
  Field required [type=missing, input_value={'model_kwargs': {'deepse...c4722bf312a5c3eb6938b'}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 495, in get_llm
    llm = ChatDeepSeek(deepseek_api_key=settings.deepseek_api_key)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\load\serializable.py", line 130, in __init__
    super().__init__(*args, **kwargs)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\pydantic\main.py", line 253, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
pydantic_core._pydantic_core.ValidationError: 1 validation error for ChatDeepSeek
model
  Field required [type=missing, input_value={'model_kwargs': {'deepse...c4722bf312a5c3eb6938b'}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 263, in get_llm
    return loop.run_until_complete(llm_cache.get_llm())
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\nest_asyncio.py", line 98, in run_until_complete
    return f.result()
           ~~~~~~~~^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\Lib\asyncio\futures.py", line 199, in result
    raise self._exception.with_traceback(self._exception_tb)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\Lib\asyncio\tasks.py", line 304, in __step_run_and_handle_result
    result = coro.send(None)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 501, in get_llm
    raise RuntimeError(f"No se pudo inicializar el modelo LLM: {e}")
RuntimeError: No se pudo inicializar el modelo LLM: 1 validation error for ChatDeepSeek
model
  Field required [type=missing, input_value={'model_kwargs': {'deepse...c4722bf312a5c3eb6938b'}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 797, in query_documents
    chain = get_qa_chain()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 349, in get_qa_chain
    llm=get_llm(),
        ~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 266, in get_llm
    raise RuntimeError(f"No se pudo inicializar el modelo LLM: {e}")
RuntimeError: No se pudo inicializar el modelo LLM: No se pudo inicializar el modelo LLM: 1 validation error for ChatDeepSeek
model
  Field required [type=missing, input_value={'model_kwargs': {'deepse...c4722bf312a5c3eb6938b'}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
2025-05-04 21:17:30,261 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 2.7269s
2025-05-04 21:18:12,403 - api.main - INFO - Nueva consulta: {"query_id": "q-1746404292", "timestamp": "2025-05-04T21:18:12.403866", "query_length": 83, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-04 21:18:12,810 - api.main - ERROR - Error al inicializar LLM: 1 validation error for ChatDeepSeek
model
  Field required [type=missing, input_value={'model_kwargs': {'deepse...c4722bf312a5c3eb6938b'}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
2025-05-04 21:18:12,811 - api.main - ERROR - Error al obtener LLM de forma síncrona: No se pudo inicializar el modelo LLM: 1 validation error for ChatDeepSeek
model
  Field required [type=missing, input_value={'model_kwargs': {'deepse...c4722bf312a5c3eb6938b'}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
2025-05-04 21:18:12,811 - api.main - ERROR - Error en procesamiento de consulta: No se pudo inicializar el modelo LLM: No se pudo inicializar el modelo LLM: 1 validation error for ChatDeepSeek
model
  Field required [type=missing, input_value={'model_kwargs': {'deepse...c4722bf312a5c3eb6938b'}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 495, in get_llm
    llm = ChatDeepSeek(deepseek_api_key=settings.deepseek_api_key)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\load\serializable.py", line 130, in __init__
    super().__init__(*args, **kwargs)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\pydantic\main.py", line 253, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
pydantic_core._pydantic_core.ValidationError: 1 validation error for ChatDeepSeek
model
  Field required [type=missing, input_value={'model_kwargs': {'deepse...c4722bf312a5c3eb6938b'}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 263, in get_llm
    return loop.run_until_complete(llm_cache.get_llm())
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\nest_asyncio.py", line 98, in run_until_complete
    return f.result()
           ~~~~~~~~^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\Lib\asyncio\futures.py", line 199, in result
    raise self._exception.with_traceback(self._exception_tb)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\Lib\asyncio\tasks.py", line 304, in __step_run_and_handle_result
    result = coro.send(None)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 501, in get_llm
    raise RuntimeError(f"No se pudo inicializar el modelo LLM: {e}")
RuntimeError: No se pudo inicializar el modelo LLM: 1 validation error for ChatDeepSeek
model
  Field required [type=missing, input_value={'model_kwargs': {'deepse...c4722bf312a5c3eb6938b'}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 797, in query_documents
    chain = get_qa_chain()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 349, in get_qa_chain
    llm=get_llm(),
        ~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 266, in get_llm
    raise RuntimeError(f"No se pudo inicializar el modelo LLM: {e}")
RuntimeError: No se pudo inicializar el modelo LLM: No se pudo inicializar el modelo LLM: 1 validation error for ChatDeepSeek
model
  Field required [type=missing, input_value={'model_kwargs': {'deepse...c4722bf312a5c3eb6938b'}}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
2025-05-04 21:18:12,815 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 0.4144s
2025-05-04 21:20:04,434 - api.main - INFO - Cerrando recursos y conexiones
2025-05-04 21:20:22,694 - api.main - INFO - Iniciando aplicación API RAG
2025-05-04 21:20:33,502 - api.main - INFO - Iniciando aplicación API RAG
2025-05-04 21:20:41,551 - api.main - INFO - Nueva consulta: {"query_id": "q-1746404441", "timestamp": "2025-05-04T21:20:41.551058", "query_length": 83, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-04 21:20:41,551 - api.main - INFO - Inicializando modelo de reescritura de consultas
2025-05-04 21:20:44,888 - api.main - INFO - Inicializando retriever
2025-05-04 21:20:44,888 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-04 21:20:44,889 - api.main - INFO - Inicializando conexión a PGVector
2025-05-04 21:20:44,889 - api.main - INFO - Inicializando modelo de embeddings
2025-05-04 21:20:46,400 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-04 21:21:06,453 - api.main - ERROR - Error en procesamiento de consulta: Completions.create() got an unexpected keyword argument 'deepseek_api_key'
Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 803, in query_documents
    result = chain({"query": query})
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\_api\deprecation.py", line 191, in warning_emitting_wrapper
    return wrapped(*args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\base.py", line 386, in __call__
    return self.invoke(
           ~~~~~~~~~~~^
        inputs,
        ^^^^^^^
    ...<2 lines>...
        include_run_info=include_run_info,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\base.py", line 167, in invoke
    raise e
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\base.py", line 157, in invoke
    self._call(inputs, run_manager=run_manager)
    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\retrieval_qa\base.py", line 154, in _call
    answer = self.combine_documents_chain.run(
        input_documents=docs, question=question, callbacks=_run_manager.get_child()
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\_api\deprecation.py", line 191, in warning_emitting_wrapper
    return wrapped(*args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\base.py", line 608, in run
    return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[
           ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\_api\deprecation.py", line 191, in warning_emitting_wrapper
    return wrapped(*args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\base.py", line 386, in __call__
    return self.invoke(
           ~~~~~~~~~~~^
        inputs,
        ^^^^^^^
    ...<2 lines>...
        include_run_info=include_run_info,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\base.py", line 167, in invoke
    raise e
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\base.py", line 157, in invoke
    self._call(inputs, run_manager=run_manager)
    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\combine_documents\base.py", line 138, in _call
    output, extra_return_dict = self.combine_docs(
                                ~~~~~~~~~~~~~~~~~^
        docs, callbacks=_run_manager.get_child(), **other_keys
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\combine_documents\stuff.py", line 259, in combine_docs
    return self.llm_chain.predict(callbacks=callbacks, **inputs), {}
           ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\llm.py", line 319, in predict
    return self(kwargs, callbacks=callbacks)[self.output_key]
           ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\_api\deprecation.py", line 191, in warning_emitting_wrapper
    return wrapped(*args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\base.py", line 386, in __call__
    return self.invoke(
           ~~~~~~~~~~~^
        inputs,
        ^^^^^^^
    ...<2 lines>...
        include_run_info=include_run_info,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\base.py", line 167, in invoke
    raise e
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\base.py", line 157, in invoke
    self._call(inputs, run_manager=run_manager)
    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\llm.py", line 127, in _call
    response = self.generate([inputs], run_manager=run_manager)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\llm.py", line 139, in generate
    return self.llm.generate_prompt(
           ~~~~~~~~~~~~~~~~~~~~~~~~^
        prompts,
        ^^^^^^^^
    ...<2 lines>...
        **self.llm_kwargs,
        ^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 947, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 766, in generate
    self._generate_with_cache(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        m,
        ^^
    ...<2 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1012, in _generate_with_cache
    result = self._generate(
        messages, stop=stop, run_manager=run_manager, **kwargs
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_deepseek\chat_models.py", line 296, in _generate
    return super()._generate(
           ~~~~~~~~~~~~~~~~~^
        messages, stop=stop, run_manager=run_manager, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 959, in _generate
    response = self.client.create(**payload)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
TypeError: Completions.create() got an unexpected keyword argument 'deepseek_api_key'
2025-05-04 21:21:06,516 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 24.9686s
2025-05-04 21:24:07,302 - api.main - INFO - Cerrando recursos y conexiones
2025-05-04 21:24:54,562 - api.main - INFO - Iniciando aplicación API RAG
2025-05-04 21:25:05,067 - api.main - INFO - Iniciando aplicación API RAG
2025-05-04 21:25:15,523 - api.main - INFO - Nueva consulta: {"query_id": "q-1746404715", "timestamp": "2025-05-04T21:25:15.523301", "query_length": 83, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-04 21:25:15,524 - api.main - INFO - Inicializando modelo de reescritura de consultas
2025-05-04 21:25:18,178 - api.main - INFO - Inicializando retriever
2025-05-04 21:25:18,178 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-04 21:25:18,179 - api.main - INFO - Inicializando conexión a PGVector
2025-05-04 21:25:18,179 - api.main - INFO - Inicializando modelo de embeddings
2025-05-04 21:25:18,374 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-04 21:25:35,520 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:25:55,071 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:26:04,507 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-04 21:26:05,319 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:26:13,925 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 58.4076s
2025-05-04 21:26:13,929 - api.main - INFO - Metrics: {"timestamp": "2025-05-04T21:26:13.929600", "query_length": 83, "num_sources": 2, "execution_time": 58.39465832710266, "language": "es", "quality": "alta"}
2025-05-04 21:28:02,380 - api.main - INFO - Nueva consulta: {"query_id": "q-1746404882", "timestamp": "2025-05-04T21:28:02.380390", "query_length": 91, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-04 21:28:11,992 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:28:31,651 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:28:41,061 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-04 21:28:41,790 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:28:49,882 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 47.5233s
2025-05-04 21:28:49,885 - api.main - INFO - Metrics: {"timestamp": "2025-05-04T21:28:49.885433", "query_length": 91, "num_sources": 2, "execution_time": 47.49797749519348, "language": "es", "quality": "alta"}
2025-05-04 21:29:40,125 - api.main - INFO - Nueva consulta: {"query_id": "q-1746404980", "timestamp": "2025-05-04T21:29:40.125649", "query_length": 88, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-04 21:29:47,225 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:30:10,162 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:30:19,574 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-04 21:30:20,403 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:30:29,584 - api.main - WARNING - Timeout en verificación de completitud
2025-05-04 21:30:29,585 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 49.4613s
2025-05-04 21:30:29,587 - api.main - INFO - Metrics: {"timestamp": "2025-05-04T21:30:29.587019", "query_length": 88, "num_sources": 2, "execution_time": 49.45885729789734, "language": "es", "quality": "media"}
2025-05-04 21:30:47,650 - api.main - INFO - Nueva consulta: {"query_id": "q-1746405047", "timestamp": "2025-05-04T21:30:47.650019", "query_length": 74, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-04 21:30:54,096 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:31:12,527 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:31:22,045 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-04 21:31:23,589 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:31:32,049 - api.main - WARNING - Timeout en verificación de completitud
2025-05-04 21:31:32,050 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 44.4009s
2025-05-04 21:31:32,051 - api.main - INFO - Metrics: {"timestamp": "2025-05-04T21:31:32.051811", "query_length": 74, "num_sources": 4, "execution_time": 44.39939284324646, "language": "es", "quality": "media"}
2025-05-04 21:31:49,552 - api.main - INFO - Nueva consulta: {"query_id": "q-1746405109", "timestamp": "2025-05-04T21:31:49.552957", "query_length": 100, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-04 21:31:55,435 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:32:12,536 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:32:21,929 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-04 21:32:23,441 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:32:31,932 - api.main - WARNING - Timeout en verificación de completitud
2025-05-04 21:32:31,933 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 42.3815s
2025-05-04 21:32:31,935 - api.main - INFO - Metrics: {"timestamp": "2025-05-04T21:32:31.935142", "query_length": 100, "num_sources": 4, "execution_time": 42.380027055740356, "language": "es", "quality": "media"}
2025-05-04 21:55:02,726 - api.main - INFO - Nueva consulta: {"query_id": "q-1746406502", "timestamp": "2025-05-04T21:55:02.725483", "query_length": 64, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-04 21:55:12,270 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:55:19,357 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:55:28,786 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-04 21:55:30,315 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:55:37,079 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 34.3840s
2025-05-04 21:55:37,084 - api.main - INFO - Metrics: {"timestamp": "2025-05-04T21:55:37.084841", "query_length": 64, "num_sources": 3, "execution_time": 34.3485369682312, "language": "es", "quality": "baja"}
2025-05-04 21:56:19,842 - api.main - INFO - Nueva consulta: {"query_id": "q-1746406579", "timestamp": "2025-05-04T21:56:19.842354", "query_length": 65, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-04 21:56:27,113 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:56:39,847 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:56:49,242 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-04 21:56:50,806 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:56:56,747 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 36.9108s
2025-05-04 21:56:56,749 - api.main - INFO - Metrics: {"timestamp": "2025-05-04T21:56:56.749444", "query_length": 65, "num_sources": 3, "execution_time": 36.90405058860779, "language": "es", "quality": "baja"}
2025-05-04 21:57:30,901 - api.main - INFO - Nueva consulta: {"query_id": "q-1746406650", "timestamp": "2025-05-04T21:57:30.901904", "query_length": 62, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-04 21:57:36,889 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:57:44,466 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:57:53,895 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-04 21:57:55,423 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:58:02,189 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 31.2927s
2025-05-04 21:58:02,192 - api.main - INFO - Metrics: {"timestamp": "2025-05-04T21:58:02.192690", "query_length": 62, "num_sources": 3, "execution_time": 31.281993865966797, "language": "es", "quality": "baja"}
2025-05-04 21:58:29,449 - api.main - INFO - Nueva consulta: {"query_id": "q-1746406709", "timestamp": "2025-05-04T21:58:29.449637", "query_length": 60, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-04 21:58:37,212 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:58:53,282 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:59:02,692 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-04 21:59:03,521 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-04 21:59:12,707 - api.main - WARNING - Timeout en verificación de completitud
2025-05-04 21:59:12,708 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 43.2690s
2025-05-04 21:59:12,710 - api.main - INFO - Metrics: {"timestamp": "2025-05-04T21:59:12.710801", "query_length": 60, "num_sources": 3, "execution_time": 43.25838923454285, "language": "es", "quality": "media"}
2025-05-04 22:01:19,746 - api.main - INFO - Cerrando recursos y conexiones
2025-05-04 22:02:02,176 - api.main - INFO - Iniciando aplicación API RAG
2025-05-04 22:02:16,464 - api.main - INFO - Iniciando aplicación API RAG
2025-05-04 22:02:22,138 - api.main - INFO - Cerrando recursos y conexiones
2025-05-04 22:02:33,889 - api.main - INFO - Iniciando aplicación API RAG
2025-05-04 22:02:44,450 - api.main - INFO - Iniciando aplicación API RAG
2025-05-05 07:51:21,157 - api.main - INFO - Iniciando aplicación API RAG
2025-05-05 07:56:56,744 - api.main - INFO - Cerrando recursos y conexiones
2025-05-05 07:59:43,513 - api.main - INFO - Iniciando aplicación API RAG
2025-05-05 07:59:54,220 - api.main - INFO - Request: GET /docs | Status: 200 | Duration: 0.0005s
2025-05-05 07:59:57,465 - api.main - INFO - Request: GET /openapi.json | Status: 200 | Duration: 0.0192s
2025-05-05 08:00:48,589 - api.main - INFO - Nueva consulta: {"query_id": "q-1746442848", "timestamp": "2025-05-05T08:00:48.588424", "query_length": 64, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 08:00:48,592 - api.main - INFO - Inicializando modelo de reescritura de consultas
2025-05-05 08:00:53,797 - api.main - INFO - Inicializando retriever
2025-05-05 08:00:53,799 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-05 08:00:53,799 - api.main - INFO - Inicializando conexión a PGVector
2025-05-05 08:00:53,800 - api.main - INFO - Inicializando modelo de embeddings
2025-05-05 08:00:56,720 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-05 08:01:25,154 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 08:01:46,472 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 08:01:55,892 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-05 08:01:56,577 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 08:02:05,895 - api.main - WARNING - Timeout en verificación de completitud
2025-05-05 08:02:05,961 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 77.4162s
2025-05-05 08:02:05,993 - api.main - INFO - Metrics: {"timestamp": "2025-05-05T08:02:05.993534", "query_length": 64, "num_sources": 4, "execution_time": 77.3095371723175, "language": "es", "quality": "media"}
2025-05-05 08:02:25,822 - api.main - INFO - Nueva consulta: {"query_id": "q-1746442945", "timestamp": "2025-05-05T08:02:25.822666", "query_length": 65, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 08:02:42,164 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 08:02:50,816 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 08:03:00,419 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-05 08:03:01,600 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 08:03:10,422 - api.main - WARNING - Timeout en verificación de completitud
2025-05-05 08:03:10,439 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 44.6441s
2025-05-05 08:03:10,447 - api.main - INFO - Metrics: {"timestamp": "2025-05-05T08:03:10.447810", "query_length": 65, "num_sources": 4, "execution_time": 44.600481033325195, "language": "es", "quality": "media"}
2025-05-05 08:04:56,661 - api.main - INFO - Nueva consulta: {"query_id": "q-1746443096", "timestamp": "2025-05-05T08:04:56.659131", "query_length": 60, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 08:05:10,678 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 08:05:30,393 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 08:05:40,001 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-05 08:05:40,473 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 08:05:50,007 - api.main - WARNING - Timeout en verificación de completitud
2025-05-05 08:05:50,023 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 53.3998s
2025-05-05 08:05:50,033 - api.main - INFO - Metrics: {"timestamp": "2025-05-05T08:05:50.033711", "query_length": 60, "num_sources": 3, "execution_time": 53.34859895706177, "language": "es", "quality": "media"}
2025-05-05 08:26:15,708 - api.main - INFO - Cerrando recursos y conexiones
2025-05-05 11:25:47,364 - api.main - INFO - Iniciando aplicación API RAG
2025-05-05 11:27:24,511 - api.main - INFO - Nueva consulta: {"query_id": "q-1746455244", "timestamp": "2025-05-05T11:27:24.509914", "query_length": 83, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 11:27:24,513 - api.main - INFO - Inicializando modelo de reescritura de consultas
2025-05-05 11:27:28,601 - api.main - INFO - Inicializando retriever
2025-05-05 11:27:28,604 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-05 11:27:28,605 - api.main - INFO - Inicializando conexión a PGVector
2025-05-05 11:27:28,605 - api.main - INFO - Inicializando modelo de embeddings
2025-05-05 11:27:29,176 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-05 11:27:40,830 - api.main - ERROR - Error en procesamiento de consulta: (psycopg2.errors.DataException) different vector dimensions 1024 and 768

[SQL: SELECT langchain_pg_embedding.collection_id AS langchain_pg_embedding_collection_id, langchain_pg_embedding.embedding AS langchain_pg_embedding_embedding, langchain_pg_embedding.document AS langchain_pg_embedding_document, langchain_pg_embedding.cmetadata AS langchain_pg_embedding_cmetadata, langchain_pg_embedding.custom_id AS langchain_pg_embedding_custom_id, langchain_pg_embedding.uuid AS langchain_pg_embedding_uuid, langchain_pg_embedding.embedding <=> %(embedding_1)s AS distance 
FROM langchain_pg_embedding JOIN langchain_pg_collection ON langchain_pg_embedding.collection_id = langchain_pg_collection.uuid 
WHERE langchain_pg_embedding.collection_id = %(collection_id_1)s::UUID ORDER BY distance ASC 
 LIMIT %(param_1)s]
[parameters: {'embedding_1': '[0.03373139724135399,0.0704718679189682,-0.021061399951577187,0.014580827206373215,0.0064771599136292934,-0.03761361539363861,-0.008317694999277592,- ... (15888 characters truncated) ... ,0.029860494658350945,0.013217308558523655,-0.0033283315133303404,0.0625762790441513,-0.056956399232149124,-0.04588813707232475,0.030426256358623505]', 'collection_id_1': UUID('4e3d543e-c216-418e-ad08-f613c83c42d3'), 'param_1': 20}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)
Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        cursor, str_statement, effective_parameters, context
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\default.py", line 945, in do_execute
    cursor.execute(statement, parameters)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.errors.DataException: different vector dimensions 1024 and 768


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 805, in query_documents
    result = chain({"query": query})
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\_api\deprecation.py", line 191, in warning_emitting_wrapper
    return wrapped(*args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\base.py", line 386, in __call__
    return self.invoke(
           ~~~~~~~~~~~^
        inputs,
        ^^^^^^^
    ...<2 lines>...
        include_run_info=include_run_info,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\base.py", line 167, in invoke
    raise e
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\base.py", line 157, in invoke
    self._call(inputs, run_manager=run_manager)
    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\retrieval_qa\base.py", line 151, in _call
    docs = self._get_docs(question, run_manager=_run_manager)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\retrieval_qa\base.py", line 271, in _get_docs
    return self.retriever.invoke(
           ~~~~~~~~~~~~~~~~~~~~~^
        question, config={"callbacks": run_manager.get_child()}
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\retrievers.py", line 258, in invoke
    result = self._get_relevant_documents(
        input, run_manager=run_manager, **_kwargs
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\retrievers\contextual_compression.py", line 44, in _get_relevant_documents
    docs = self.base_retriever.invoke(
        query, config={"callbacks": run_manager.get_child()}, **kwargs
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\retrievers.py", line 258, in invoke
    result = self._get_relevant_documents(
        input, run_manager=run_manager, **_kwargs
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\vectorstores\base.py", line 1079, in _get_relevant_documents
    docs = self.vectorstore.similarity_search(query, **_kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\vectorstores\pgvector.py", line 585, in similarity_search
    return self.similarity_search_by_vector(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        embedding=embedding,
        ^^^^^^^^^^^^^^^^^^^^
        k=k,
        ^^^^
        filter=filter,
        ^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\vectorstores\pgvector.py", line 990, in similarity_search_by_vector
    docs_and_scores = self.similarity_search_with_score_by_vector(
        embedding=embedding, k=k, filter=filter
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\vectorstores\pgvector.py", line 633, in similarity_search_with_score_by_vector
    results = self._query_collection(embedding=embedding, k=k, filter=filter)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\vectorstores\pgvector.py", line 968, in _query_collection
    .all()
     ~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\query.py", line 2704, in all
    return self._iter().all()  # type: ignore
           ~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\query.py", line 2858, in _iter
    result: Union[ScalarResult[_T], Result[_T]] = self.session.execute(
                                                  ~~~~~~~~~~~~~~~~~~~~^
        statement,
        ^^^^^^^^^^
        params,
        ^^^^^^^
        execution_options={"_sa_orm_load_options": self.load_options},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\session.py", line 2365, in execute
    return self._execute_internal(
           ~~~~~~~~~~~~~~~~~~~~~~^
        statement,
        ^^^^^^^^^^
    ...<4 lines>...
        _add_event=_add_event,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\session.py", line 2251, in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
                          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self,
        ^^^^^
    ...<4 lines>...
        conn,
        ^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\context.py", line 306, in orm_execute_statement
    result = conn.execute(
        statement, params or {}, execution_options=execution_options
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1416, in execute
    return meth(
        self,
        distilled_parameters,
        execution_options or NO_OPTIONS,
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\sql\elements.py", line 523, in _execute_on_connection
    return connection._execute_clauseelement(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self, distilled_params, execution_options
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1638, in _execute_clauseelement
    ret = self._execute_context(
        dialect,
    ...<8 lines>...
        cache_hit=cache_hit,
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1843, in _execute_context
    return self._exec_single_context(
           ~~~~~~~~~~~~~~~~~~~~~~~~~^
        dialect, context, statement, parameters
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1983, in _exec_single_context
    self._handle_dbapi_exception(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        e, str_statement, effective_parameters, cursor, context
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 2352, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        cursor, str_statement, effective_parameters, context
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\default.py", line 945, in do_execute
    cursor.execute(statement, parameters)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.DataError: (psycopg2.errors.DataException) different vector dimensions 1024 and 768

[SQL: SELECT langchain_pg_embedding.collection_id AS langchain_pg_embedding_collection_id, langchain_pg_embedding.embedding AS langchain_pg_embedding_embedding, langchain_pg_embedding.document AS langchain_pg_embedding_document, langchain_pg_embedding.cmetadata AS langchain_pg_embedding_cmetadata, langchain_pg_embedding.custom_id AS langchain_pg_embedding_custom_id, langchain_pg_embedding.uuid AS langchain_pg_embedding_uuid, langchain_pg_embedding.embedding <=> %(embedding_1)s AS distance 
FROM langchain_pg_embedding JOIN langchain_pg_collection ON langchain_pg_embedding.collection_id = langchain_pg_collection.uuid 
WHERE langchain_pg_embedding.collection_id = %(collection_id_1)s::UUID ORDER BY distance ASC 
 LIMIT %(param_1)s]
[parameters: {'embedding_1': '[0.03373139724135399,0.0704718679189682,-0.021061399951577187,0.014580827206373215,0.0064771599136292934,-0.03761361539363861,-0.008317694999277592,- ... (15888 characters truncated) ... ,0.029860494658350945,0.013217308558523655,-0.0033283315133303404,0.0625762790441513,-0.056956399232149124,-0.04588813707232475,0.030426256358623505]', 'collection_id_1': UUID('4e3d543e-c216-418e-ad08-f613c83c42d3'), 'param_1': 20}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)
2025-05-05 11:27:41,214 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 16.7493s
2025-05-05 11:31:30,917 - api.main - INFO - Cerrando recursos y conexiones
2025-05-05 11:36:01,557 - api.main - INFO - Iniciando aplicación API RAG
2025-05-05 11:36:07,505 - api.main - INFO - Nueva consulta: {"query_id": "q-1746455767", "timestamp": "2025-05-05T11:36:07.504987", "query_length": 83, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 11:36:07,505 - api.main - INFO - Inicializando modelo de reescritura de consultas
2025-05-05 11:36:10,683 - api.main - INFO - Inicializando retriever
2025-05-05 11:36:10,685 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-05 11:36:10,685 - api.main - INFO - Inicializando conexión a PGVector
2025-05-05 11:36:10,686 - api.main - INFO - Inicializando modelo de embeddings
2025-05-05 11:36:11,168 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-05 11:36:20,380 - api.main - ERROR - Error en procesamiento de consulta: (psycopg2.errors.DataException) different vector dimensions 1024 and 768

[SQL: SELECT langchain_pg_embedding.collection_id AS langchain_pg_embedding_collection_id, langchain_pg_embedding.embedding AS langchain_pg_embedding_embedding, langchain_pg_embedding.document AS langchain_pg_embedding_document, langchain_pg_embedding.cmetadata AS langchain_pg_embedding_cmetadata, langchain_pg_embedding.custom_id AS langchain_pg_embedding_custom_id, langchain_pg_embedding.uuid AS langchain_pg_embedding_uuid, langchain_pg_embedding.embedding <=> %(embedding_1)s AS distance 
FROM langchain_pg_embedding JOIN langchain_pg_collection ON langchain_pg_embedding.collection_id = langchain_pg_collection.uuid 
WHERE langchain_pg_embedding.collection_id = %(collection_id_1)s::UUID ORDER BY distance ASC 
 LIMIT %(param_1)s]
[parameters: {'embedding_1': '[0.03373139724135399,0.0704718679189682,-0.021061399951577187,0.014580827206373215,0.0064771599136292934,-0.03761361539363861,-0.008317694999277592,- ... (15888 characters truncated) ... ,0.029860494658350945,0.013217308558523655,-0.0033283315133303404,0.0625762790441513,-0.056956399232149124,-0.04588813707232475,0.030426256358623505]', 'collection_id_1': UUID('54402f3a-5813-4c77-9f22-bbe48c7a7037'), 'param_1': 20}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)
Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        cursor, str_statement, effective_parameters, context
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\default.py", line 945, in do_execute
    cursor.execute(statement, parameters)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.errors.DataException: different vector dimensions 1024 and 768


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 805, in query_documents
    result = chain({"query": query})
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\_api\deprecation.py", line 191, in warning_emitting_wrapper
    return wrapped(*args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\base.py", line 386, in __call__
    return self.invoke(
           ~~~~~~~~~~~^
        inputs,
        ^^^^^^^
    ...<2 lines>...
        include_run_info=include_run_info,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\base.py", line 167, in invoke
    raise e
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\base.py", line 157, in invoke
    self._call(inputs, run_manager=run_manager)
    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\retrieval_qa\base.py", line 151, in _call
    docs = self._get_docs(question, run_manager=_run_manager)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\retrieval_qa\base.py", line 271, in _get_docs
    return self.retriever.invoke(
           ~~~~~~~~~~~~~~~~~~~~~^
        question, config={"callbacks": run_manager.get_child()}
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\retrievers.py", line 258, in invoke
    result = self._get_relevant_documents(
        input, run_manager=run_manager, **_kwargs
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\retrievers\contextual_compression.py", line 44, in _get_relevant_documents
    docs = self.base_retriever.invoke(
        query, config={"callbacks": run_manager.get_child()}, **kwargs
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\retrievers.py", line 258, in invoke
    result = self._get_relevant_documents(
        input, run_manager=run_manager, **_kwargs
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\vectorstores\base.py", line 1079, in _get_relevant_documents
    docs = self.vectorstore.similarity_search(query, **_kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\vectorstores\pgvector.py", line 585, in similarity_search
    return self.similarity_search_by_vector(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        embedding=embedding,
        ^^^^^^^^^^^^^^^^^^^^
        k=k,
        ^^^^
        filter=filter,
        ^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\vectorstores\pgvector.py", line 990, in similarity_search_by_vector
    docs_and_scores = self.similarity_search_with_score_by_vector(
        embedding=embedding, k=k, filter=filter
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\vectorstores\pgvector.py", line 633, in similarity_search_with_score_by_vector
    results = self._query_collection(embedding=embedding, k=k, filter=filter)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\vectorstores\pgvector.py", line 968, in _query_collection
    .all()
     ~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\query.py", line 2704, in all
    return self._iter().all()  # type: ignore
           ~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\query.py", line 2858, in _iter
    result: Union[ScalarResult[_T], Result[_T]] = self.session.execute(
                                                  ~~~~~~~~~~~~~~~~~~~~^
        statement,
        ^^^^^^^^^^
        params,
        ^^^^^^^
        execution_options={"_sa_orm_load_options": self.load_options},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\session.py", line 2365, in execute
    return self._execute_internal(
           ~~~~~~~~~~~~~~~~~~~~~~^
        statement,
        ^^^^^^^^^^
    ...<4 lines>...
        _add_event=_add_event,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\session.py", line 2251, in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
                          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self,
        ^^^^^
    ...<4 lines>...
        conn,
        ^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\context.py", line 306, in orm_execute_statement
    result = conn.execute(
        statement, params or {}, execution_options=execution_options
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1416, in execute
    return meth(
        self,
        distilled_parameters,
        execution_options or NO_OPTIONS,
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\sql\elements.py", line 523, in _execute_on_connection
    return connection._execute_clauseelement(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self, distilled_params, execution_options
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1638, in _execute_clauseelement
    ret = self._execute_context(
        dialect,
    ...<8 lines>...
        cache_hit=cache_hit,
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1843, in _execute_context
    return self._exec_single_context(
           ~~~~~~~~~~~~~~~~~~~~~~~~~^
        dialect, context, statement, parameters
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1983, in _exec_single_context
    self._handle_dbapi_exception(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        e, str_statement, effective_parameters, cursor, context
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 2352, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        cursor, str_statement, effective_parameters, context
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\default.py", line 945, in do_execute
    cursor.execute(statement, parameters)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.DataError: (psycopg2.errors.DataException) different vector dimensions 1024 and 768

[SQL: SELECT langchain_pg_embedding.collection_id AS langchain_pg_embedding_collection_id, langchain_pg_embedding.embedding AS langchain_pg_embedding_embedding, langchain_pg_embedding.document AS langchain_pg_embedding_document, langchain_pg_embedding.cmetadata AS langchain_pg_embedding_cmetadata, langchain_pg_embedding.custom_id AS langchain_pg_embedding_custom_id, langchain_pg_embedding.uuid AS langchain_pg_embedding_uuid, langchain_pg_embedding.embedding <=> %(embedding_1)s AS distance 
FROM langchain_pg_embedding JOIN langchain_pg_collection ON langchain_pg_embedding.collection_id = langchain_pg_collection.uuid 
WHERE langchain_pg_embedding.collection_id = %(collection_id_1)s::UUID ORDER BY distance ASC 
 LIMIT %(param_1)s]
[parameters: {'embedding_1': '[0.03373139724135399,0.0704718679189682,-0.021061399951577187,0.014580827206373215,0.0064771599136292934,-0.03761361539363861,-0.008317694999277592,- ... (15888 characters truncated) ... ,0.029860494658350945,0.013217308558523655,-0.0033283315133303404,0.0625762790441513,-0.056956399232149124,-0.04588813707232475,0.030426256358623505]', 'collection_id_1': UUID('54402f3a-5813-4c77-9f22-bbe48c7a7037'), 'param_1': 20}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)
2025-05-05 11:36:20,449 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 12.9497s
2025-05-05 11:38:35,191 - api.main - INFO - Cerrando recursos y conexiones
2025-05-05 11:38:53,764 - api.main - INFO - Iniciando aplicación API RAG
2025-05-05 11:39:34,713 - api.main - INFO - Cerrando recursos y conexiones
2025-05-05 11:43:47,492 - api.main - INFO - Iniciando aplicación API RAG
2025-05-05 11:43:50,728 - api.main - INFO - Nueva consulta: {"query_id": "q-1746456230", "timestamp": "2025-05-05T11:43:50.728290", "query_length": 83, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 11:43:50,729 - api.main - INFO - Inicializando modelo de reescritura de consultas
2025-05-05 11:43:53,868 - api.main - INFO - Inicializando retriever
2025-05-05 11:43:53,869 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-05 11:43:53,869 - api.main - INFO - Inicializando conexión a PGVector
2025-05-05 11:43:53,870 - api.main - INFO - Inicializando modelo de embeddings
2025-05-05 11:43:54,079 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-05 11:44:04,118 - api.main - ERROR - Error en procesamiento de consulta: (psycopg2.errors.DataException) different vector dimensions 1024 and 768

[SQL: SELECT langchain_pg_embedding.collection_id AS langchain_pg_embedding_collection_id, langchain_pg_embedding.embedding AS langchain_pg_embedding_embedding, langchain_pg_embedding.document AS langchain_pg_embedding_document, langchain_pg_embedding.cmetadata AS langchain_pg_embedding_cmetadata, langchain_pg_embedding.custom_id AS langchain_pg_embedding_custom_id, langchain_pg_embedding.uuid AS langchain_pg_embedding_uuid, langchain_pg_embedding.embedding <=> %(embedding_1)s AS distance 
FROM langchain_pg_embedding JOIN langchain_pg_collection ON langchain_pg_embedding.collection_id = langchain_pg_collection.uuid 
WHERE langchain_pg_embedding.collection_id = %(collection_id_1)s::UUID ORDER BY distance ASC 
 LIMIT %(param_1)s]
[parameters: {'embedding_1': '[0.03373139724135399,0.0704718679189682,-0.021061399951577187,0.014580827206373215,0.0064771599136292934,-0.03761361539363861,-0.008317694999277592,- ... (15888 characters truncated) ... ,0.029860494658350945,0.013217308558523655,-0.0033283315133303404,0.0625762790441513,-0.056956399232149124,-0.04588813707232475,0.030426256358623505]', 'collection_id_1': UUID('48b0c660-4e40-4e8b-88c9-dde1bd126c00'), 'param_1': 20}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)
Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        cursor, str_statement, effective_parameters, context
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\default.py", line 945, in do_execute
    cursor.execute(statement, parameters)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.errors.DataException: different vector dimensions 1024 and 768


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 805, in query_documents
    result = chain({"query": query})
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\_api\deprecation.py", line 191, in warning_emitting_wrapper
    return wrapped(*args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\base.py", line 386, in __call__
    return self.invoke(
           ~~~~~~~~~~~^
        inputs,
        ^^^^^^^
    ...<2 lines>...
        include_run_info=include_run_info,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\base.py", line 167, in invoke
    raise e
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\base.py", line 157, in invoke
    self._call(inputs, run_manager=run_manager)
    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\retrieval_qa\base.py", line 151, in _call
    docs = self._get_docs(question, run_manager=_run_manager)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\chains\retrieval_qa\base.py", line 271, in _get_docs
    return self.retriever.invoke(
           ~~~~~~~~~~~~~~~~~~~~~^
        question, config={"callbacks": run_manager.get_child()}
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\retrievers.py", line 258, in invoke
    result = self._get_relevant_documents(
        input, run_manager=run_manager, **_kwargs
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain\retrievers\contextual_compression.py", line 44, in _get_relevant_documents
    docs = self.base_retriever.invoke(
        query, config={"callbacks": run_manager.get_child()}, **kwargs
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\retrievers.py", line 258, in invoke
    result = self._get_relevant_documents(
        input, run_manager=run_manager, **_kwargs
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\vectorstores\base.py", line 1079, in _get_relevant_documents
    docs = self.vectorstore.similarity_search(query, **_kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\vectorstores\pgvector.py", line 585, in similarity_search
    return self.similarity_search_by_vector(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        embedding=embedding,
        ^^^^^^^^^^^^^^^^^^^^
        k=k,
        ^^^^
        filter=filter,
        ^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\vectorstores\pgvector.py", line 990, in similarity_search_by_vector
    docs_and_scores = self.similarity_search_with_score_by_vector(
        embedding=embedding, k=k, filter=filter
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\vectorstores\pgvector.py", line 633, in similarity_search_with_score_by_vector
    results = self._query_collection(embedding=embedding, k=k, filter=filter)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\vectorstores\pgvector.py", line 968, in _query_collection
    .all()
     ~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\query.py", line 2704, in all
    return self._iter().all()  # type: ignore
           ~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\query.py", line 2858, in _iter
    result: Union[ScalarResult[_T], Result[_T]] = self.session.execute(
                                                  ~~~~~~~~~~~~~~~~~~~~^
        statement,
        ^^^^^^^^^^
        params,
        ^^^^^^^
        execution_options={"_sa_orm_load_options": self.load_options},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\session.py", line 2365, in execute
    return self._execute_internal(
           ~~~~~~~~~~~~~~~~~~~~~~^
        statement,
        ^^^^^^^^^^
    ...<4 lines>...
        _add_event=_add_event,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\session.py", line 2251, in _execute_internal
    result: Result[Any] = compile_state_cls.orm_execute_statement(
                          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self,
        ^^^^^
    ...<4 lines>...
        conn,
        ^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\context.py", line 306, in orm_execute_statement
    result = conn.execute(
        statement, params or {}, execution_options=execution_options
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1416, in execute
    return meth(
        self,
        distilled_parameters,
        execution_options or NO_OPTIONS,
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\sql\elements.py", line 523, in _execute_on_connection
    return connection._execute_clauseelement(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self, distilled_params, execution_options
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1638, in _execute_clauseelement
    ret = self._execute_context(
        dialect,
    ...<8 lines>...
        cache_hit=cache_hit,
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1843, in _execute_context
    return self._exec_single_context(
           ~~~~~~~~~~~~~~~~~~~~~~~~~^
        dialect, context, statement, parameters
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1983, in _exec_single_context
    self._handle_dbapi_exception(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        e, str_statement, effective_parameters, cursor, context
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 2352, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        cursor, str_statement, effective_parameters, context
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\default.py", line 945, in do_execute
    cursor.execute(statement, parameters)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.DataError: (psycopg2.errors.DataException) different vector dimensions 1024 and 768

[SQL: SELECT langchain_pg_embedding.collection_id AS langchain_pg_embedding_collection_id, langchain_pg_embedding.embedding AS langchain_pg_embedding_embedding, langchain_pg_embedding.document AS langchain_pg_embedding_document, langchain_pg_embedding.cmetadata AS langchain_pg_embedding_cmetadata, langchain_pg_embedding.custom_id AS langchain_pg_embedding_custom_id, langchain_pg_embedding.uuid AS langchain_pg_embedding_uuid, langchain_pg_embedding.embedding <=> %(embedding_1)s AS distance 
FROM langchain_pg_embedding JOIN langchain_pg_collection ON langchain_pg_embedding.collection_id = langchain_pg_collection.uuid 
WHERE langchain_pg_embedding.collection_id = %(collection_id_1)s::UUID ORDER BY distance ASC 
 LIMIT %(param_1)s]
[parameters: {'embedding_1': '[0.03373139724135399,0.0704718679189682,-0.021061399951577187,0.014580827206373215,0.0064771599136292934,-0.03761361539363861,-0.008317694999277592,- ... (15888 characters truncated) ... ,0.029860494658350945,0.013217308558523655,-0.0033283315133303404,0.0625762790441513,-0.056956399232149124,-0.04588813707232475,0.030426256358623505]', 'collection_id_1': UUID('48b0c660-4e40-4e8b-88c9-dde1bd126c00'), 'param_1': 20}]
(Background on this error at: https://sqlalche.me/e/20/9h9h)
2025-05-05 11:44:04,196 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 13.4737s
2025-05-05 11:44:54,263 - api.main - INFO - Cerrando recursos y conexiones
2025-05-05 12:00:17,887 - api.main - INFO - Iniciando aplicación API RAG
2025-05-05 12:00:23,122 - api.main - INFO - Nueva consulta: {"query_id": "q-1746457223", "timestamp": "2025-05-05T12:00:23.122495", "query_length": 83, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 12:00:23,123 - api.main - INFO - Inicializando modelo de reescritura de consultas
2025-05-05 12:00:27,283 - api.main - INFO - Inicializando retriever
2025-05-05 12:00:27,288 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-05 12:00:27,289 - api.main - INFO - Inicializando conexión a PGVector
2025-05-05 12:00:27,289 - api.main - INFO - Inicializando modelo de embeddings
2025-05-05 12:00:27,742 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-05 12:00:51,216 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:01:11,814 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:01:21,401 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-05 12:01:21,939 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:01:31,417 - api.main - WARNING - Timeout en verificación de completitud
2025-05-05 12:01:31,445 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 68.3289s
2025-05-05 12:01:31,456 - api.main - INFO - Metrics: {"timestamp": "2025-05-05T12:01:31.456665", "query_length": 83, "num_sources": 2, "execution_time": 68.29714322090149, "language": "es", "quality": "media"}
2025-05-05 12:01:57,741 - api.main - INFO - Nueva consulta: {"query_id": "q-1746457317", "timestamp": "2025-05-05T12:01:57.740947", "query_length": 91, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 12:02:15,714 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:02:37,282 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:02:46,879 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-05 12:02:47,344 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:02:56,882 - api.main - WARNING - Timeout en verificación de completitud
2025-05-05 12:02:56,888 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 59.1667s
2025-05-05 12:02:56,890 - api.main - INFO - Metrics: {"timestamp": "2025-05-05T12:02:56.890305", "query_length": 91, "num_sources": 2, "execution_time": 59.141945123672485, "language": "es", "quality": "media"}
2025-05-05 12:03:42,662 - api.main - INFO - Nueva consulta: {"query_id": "q-1746457422", "timestamp": "2025-05-05T12:03:42.662265", "query_length": 88, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 12:03:53,233 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:04:20,550 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:04:30,147 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-05 12:04:30,645 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:04:40,162 - api.main - WARNING - Timeout en verificación de completitud
2025-05-05 12:04:40,167 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 57.5212s
2025-05-05 12:04:40,170 - api.main - INFO - Metrics: {"timestamp": "2025-05-05T12:04:40.169848", "query_length": 88, "num_sources": 2, "execution_time": 57.500455141067505, "language": "es", "quality": "media"}
2025-05-05 12:05:02,205 - api.main - INFO - Nueva consulta: {"query_id": "q-1746457502", "timestamp": "2025-05-05T12:05:02.205468", "query_length": 74, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 12:05:15,745 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:05:38,785 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:05:48,401 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-05 12:05:48,867 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:05:58,406 - api.main - WARNING - Timeout en verificación de completitud
2025-05-05 12:05:58,412 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 56.2168s
2025-05-05 12:05:58,415 - api.main - INFO - Metrics: {"timestamp": "2025-05-05T12:05:58.415796", "query_length": 74, "num_sources": 2, "execution_time": 56.2013304233551, "language": "es", "quality": "media"}
2025-05-05 12:06:18,901 - api.main - INFO - Nueva consulta: {"query_id": "q-1746457578", "timestamp": "2025-05-05T12:06:18.901306", "query_length": 100, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 12:06:33,259 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:06:59,442 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:07:08,369 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-05 12:07:08,861 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:07:18,375 - api.main - WARNING - Timeout en verificación de completitud
2025-05-05 12:07:18,395 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 59.5023s
2025-05-05 12:07:18,403 - api.main - INFO - Metrics: {"timestamp": "2025-05-05T12:07:18.402998", "query_length": 100, "num_sources": 2, "execution_time": 59.475324392318726, "language": "es", "quality": "media"}
2025-05-05 12:15:24,704 - api.main - INFO - Cerrando recursos y conexiones
2025-05-05 12:15:43,572 - api.main - INFO - Iniciando aplicación API RAG
2025-05-05 12:17:06,855 - api.main - INFO - Iniciando aplicación API RAG
2025-05-05 12:18:10,134 - api.main - INFO - Nueva consulta: {"query_id": "q-1746458290", "timestamp": "2025-05-05T12:18:10.134726", "query_length": 83, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 12:18:10,135 - api.main - INFO - Inicializando modelo de reescritura de consultas
2025-05-05 12:18:14,839 - api.main - INFO - Inicializando retriever
2025-05-05 12:18:14,842 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-05 12:18:14,842 - api.main - INFO - Inicializando conexión a PGVector
2025-05-05 12:18:14,843 - api.main - INFO - Inicializando modelo de embeddings
2025-05-05 12:18:15,275 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-05 12:18:39,878 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:19:01,479 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:19:11,024 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-05 12:19:11,497 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:19:21,035 - api.main - WARNING - Timeout en verificación de completitud
2025-05-05 12:19:21,077 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 70.9495s
2025-05-05 12:19:21,090 - api.main - INFO - Metrics: {"timestamp": "2025-05-05T12:19:21.089856", "query_length": 83, "num_sources": 2, "execution_time": 70.9009952545166, "language": "es", "quality": "media"}
2025-05-05 12:19:39,743 - api.main - INFO - Nueva consulta: {"query_id": "q-1746458379", "timestamp": "2025-05-05T12:19:39.743825", "query_length": 91, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 12:19:58,636 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:20:19,245 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:20:28,831 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-05 12:20:29,311 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:20:38,846 - api.main - WARNING - Timeout en verificación de completitud
2025-05-05 12:20:38,867 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 59.1637s
2025-05-05 12:20:38,870 - api.main - INFO - Metrics: {"timestamp": "2025-05-05T12:20:38.870886", "query_length": 91, "num_sources": 2, "execution_time": 59.10464000701904, "language": "es", "quality": "media"}
2025-05-05 12:20:56,769 - api.main - INFO - Nueva consulta: {"query_id": "q-1746458456", "timestamp": "2025-05-05T12:20:56.769122", "query_length": 88, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 12:21:17,869 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:21:47,433 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:21:56,974 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-05 12:21:57,477 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:22:06,983 - api.main - WARNING - Timeout en verificación de completitud
2025-05-05 12:22:07,006 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 70.2558s
2025-05-05 12:22:07,017 - api.main - INFO - Metrics: {"timestamp": "2025-05-05T12:22:07.017452", "query_length": 88, "num_sources": 2, "execution_time": 70.21563673019409, "language": "es", "quality": "media"}
2025-05-05 12:22:22,679 - api.main - INFO - Nueva consulta: {"query_id": "q-1746458542", "timestamp": "2025-05-05T12:22:22.678945", "query_length": 74, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 12:22:25,699 - api.main - WARNING - Error en reescritura de consulta: 
2025-05-05 12:22:44,512 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:23:05,805 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:23:15,377 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-05 12:23:15,874 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:23:25,387 - api.main - WARNING - Timeout en verificación de completitud
2025-05-05 12:23:25,401 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 62.7348s
2025-05-05 12:23:25,409 - api.main - INFO - Metrics: {"timestamp": "2025-05-05T12:23:25.409035", "query_length": 74, "num_sources": 3, "execution_time": 62.7087676525116, "language": "es", "quality": "media"}
2025-05-05 12:23:52,199 - api.main - INFO - Nueva consulta: {"query_id": "q-1746458632", "timestamp": "2025-05-05T12:23:52.199508", "query_length": 100, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 12:24:15,258 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:24:40,338 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:24:49,868 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-05 12:24:51,041 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:24:59,874 - api.main - WARNING - Timeout en verificación de completitud
2025-05-05 12:24:59,893 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 67.7102s
2025-05-05 12:24:59,901 - api.main - INFO - Metrics: {"timestamp": "2025-05-05T12:24:59.900925", "query_length": 100, "num_sources": 2, "execution_time": 67.67553281784058, "language": "es", "quality": "media"}
2025-05-05 12:27:38,695 - api.main - INFO - Cerrando recursos y conexiones
2025-05-05 12:27:58,846 - api.main - INFO - Iniciando aplicación API RAG
2025-05-05 12:28:09,570 - api.main - INFO - Cerrando recursos y conexiones
2025-05-05 12:31:12,681 - api.main - INFO - Iniciando aplicación API RAG
2025-05-05 12:34:29,235 - api.main - INFO - Nueva consulta: {"query_id": "q-1746459269", "timestamp": "2025-05-05T12:34:29.234381", "query_length": 83, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 12:34:29,240 - api.main - INFO - Inicializando modelo de reescritura de consultas
2025-05-05 12:34:32,788 - api.main - INFO - Inicializando retriever
2025-05-05 12:34:32,791 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-05 12:34:32,792 - api.main - INFO - Inicializando conexión a PGVector
2025-05-05 12:34:32,792 - api.main - INFO - Inicializando modelo de embeddings
2025-05-05 12:34:33,209 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-05 12:34:52,427 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:35:13,692 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:35:23,256 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-05 12:35:23,787 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:35:33,273 - api.main - WARNING - Timeout en verificación de completitud
2025-05-05 12:35:33,308 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 64.1380s
2025-05-05 12:35:33,326 - api.main - INFO - Metrics: {"timestamp": "2025-05-05T12:35:33.326636", "query_length": 83, "num_sources": 2, "execution_time": 64.03977990150452, "language": "es", "quality": "media"}
2025-05-05 12:36:18,831 - api.main - INFO - Nueva consulta: {"query_id": "q-1746459378", "timestamp": "2025-05-05T12:36:18.831172", "query_length": 72, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 12:36:40,783 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:36:58,071 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:37:07,653 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-05 12:37:08,132 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:37:17,659 - api.main - WARNING - Timeout en verificación de completitud
2025-05-05 12:37:17,673 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 58.8663s
2025-05-05 12:37:17,680 - api.main - INFO - Metrics: {"timestamp": "2025-05-05T12:37:17.680481", "query_length": 72, "num_sources": 1, "execution_time": 58.82903337478638, "language": "es", "quality": "media"}
2025-05-05 12:37:36,042 - api.main - INFO - Nueva consulta: {"query_id": "q-1746459456", "timestamp": "2025-05-05T12:37:36.042332", "query_length": 86, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 12:37:50,853 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:38:27,759 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:38:37,247 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-05 12:38:37,793 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:38:47,259 - api.main - WARNING - Timeout en verificación de completitud
2025-05-05 12:38:47,266 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 71.2449s
2025-05-05 12:38:47,270 - api.main - INFO - Metrics: {"timestamp": "2025-05-05T12:38:47.270715", "query_length": 86, "num_sources": 1, "execution_time": 71.21766448020935, "language": "es", "quality": "media"}
2025-05-05 12:40:03,368 - api.main - INFO - Cerrando recursos y conexiones
2025-05-05 12:40:25,837 - api.main - INFO - Iniciando aplicación API RAG
2025-05-05 12:42:21,760 - api.main - INFO - Iniciando aplicación API RAG
2025-05-05 12:42:37,350 - api.main - INFO - Nueva consulta: {"query_id": "q-1746459757", "timestamp": "2025-05-05T12:42:37.350624", "query_length": 72, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 12:42:37,352 - api.main - INFO - Inicializando modelo de reescritura de consultas
2025-05-05 12:42:40,827 - api.main - INFO - Inicializando retriever
2025-05-05 12:42:40,830 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-05 12:42:40,831 - api.main - INFO - Inicializando conexión a PGVector
2025-05-05 12:42:40,832 - api.main - INFO - Inicializando modelo de embeddings
2025-05-05 12:42:41,111 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-05 12:43:05,096 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:43:25,813 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:43:35,404 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-05 12:43:35,898 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:43:45,420 - api.main - WARNING - Timeout en verificación de completitud
2025-05-05 12:43:45,461 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 68.1178s
2025-05-05 12:43:45,475 - api.main - INFO - Metrics: {"timestamp": "2025-05-05T12:43:45.474955", "query_length": 72, "num_sources": 2, "execution_time": 68.07115507125854, "language": "es", "quality": "media"}
2025-05-05 12:44:05,005 - api.main - INFO - Nueva consulta: {"query_id": "q-1746459845", "timestamp": "2025-05-05T12:44:05.005149", "query_length": 72, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 12:44:21,141 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:44:49,457 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:44:58,822 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-05 12:44:59,698 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:45:08,836 - api.main - WARNING - Timeout en verificación de completitud
2025-05-05 12:45:08,847 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 63.8726s
2025-05-05 12:45:08,852 - api.main - INFO - Metrics: {"timestamp": "2025-05-05T12:45:08.852071", "query_length": 72, "num_sources": 1, "execution_time": 63.83190441131592, "language": "es", "quality": "media"}
2025-05-05 12:45:29,542 - api.main - INFO - Nueva consulta: {"query_id": "q-1746459929", "timestamp": "2025-05-05T12:45:29.542518", "query_length": 86, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-05 12:45:43,628 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:46:20,124 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:46:29,520 - api.main - WARNING - Timeout en verificación de alucinaciones
2025-05-05 12:46:30,032 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-05 12:46:39,533 - api.main - WARNING - Timeout en verificación de completitud
2025-05-05 12:46:39,550 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 70.0210s
2025-05-05 12:46:39,561 - api.main - INFO - Metrics: {"timestamp": "2025-05-05T12:46:39.561164", "query_length": 86, "num_sources": 1, "execution_time": 69.99115228652954, "language": "es", "quality": "media"}
2025-05-05 13:01:37,546 - api.main - INFO - Cerrando recursos y conexiones
2025-05-05 13:44:30,576 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 13:09:42,954 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 13:10:02,646 - api.main - INFO - Request: GET /docs | Status: 200 | Duration: 0.0009s
2025-05-06 13:10:03,419 - api.main - INFO - Request: GET /openapi.json | Status: 200 | Duration: 0.0176s
2025-05-06 13:11:00,802 - api.main - INFO - Nueva consulta: {"query_id": "q-1746547860", "timestamp": "2025-05-06T13:11:00.802172", "query_length": 158, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-06 13:11:00,802 - api.main - INFO - Inicializando modelo de reescritura de consultas
2025-05-06 13:11:04,872 - api.main - INFO - Inicializando retriever
2025-05-06 13:11:04,872 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-06 13:11:04,872 - api.main - INFO - Inicializando conexión a PGVector
2025-05-06 13:11:04,872 - api.main - INFO - Inicializando modelo de embeddings
2025-05-06 13:11:05,093 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-06 13:11:24,658 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-06 13:11:49,775 - api.main - ERROR - Error en procesamiento de consulta: name 'verification_info' is not defined
Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 751, in query_documents
    quality=verification_info.get("quality", "no_verificada") if verification_info else "no_verificada"
                                                                 ^^^^^^^^^^^^^^^^^
NameError: name 'verification_info' is not defined
2025-05-06 13:11:49,789 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 48.9931s
2025-05-06 13:13:00,679 - api.main - INFO - Cerrando recursos y conexiones
2025-05-06 13:13:19,419 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 13:13:23,337 - api.main - INFO - Cerrando recursos y conexiones
2025-05-06 13:13:33,445 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 13:13:46,307 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 13:14:31,431 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 13:15:37,133 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 13:16:03,533 - api.main - INFO - Cerrando recursos y conexiones
2025-05-06 13:16:19,743 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 13:19:11,403 - api.main - INFO - Cerrando recursos y conexiones
2025-05-06 13:19:31,035 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 13:19:54,516 - api.main - INFO - Cerrando recursos y conexiones
2025-05-06 13:20:15,410 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 13:20:23,617 - api.main - INFO - Cerrando recursos y conexiones
2025-05-06 13:20:50,219 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 13:21:32,015 - api.main - INFO - Nueva consulta: {"query_id": "q-1746548492", "timestamp": "2025-05-06T13:21:32.015237", "query_length": 158, "detected_language": "es", "client_ip": "127.0.0.1"}
2025-05-06 13:21:32,015 - api.main - INFO - Inicializando modelo de reescritura de consultas
2025-05-06 13:21:38,973 - api.main - INFO - Inicializando retriever
2025-05-06 13:21:38,974 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-06 13:21:38,974 - api.main - INFO - Inicializando conexión a PGVector
2025-05-06 13:21:38,975 - api.main - INFO - Inicializando modelo de embeddings
2025-05-06 13:21:41,497 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-06 13:22:12,363 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-06 13:22:43,069 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 71.0621s
2025-05-06 13:22:43,084 - api.main - INFO - Metrics: {"timestamp": "2025-05-06T13:22:43.084111", "query_length": 158, "num_sources": 2, "execution_time": 71.02593183517456, "language": "es", "quality": "no_aplicable"}
2025-05-06 13:59:26,202 - api.main - INFO - Cerrando recursos y conexiones
2025-05-06 15:06:39,887 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 15:06:53,003 - api.main - INFO - Request: GET /docs | Status: 200 | Duration: 0.0006s
2025-05-06 15:06:53,663 - api.main - INFO - Request: GET /openapi.json | Status: 200 | Duration: 0.0133s
2025-05-06 15:07:00,583 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746554820-354612", "timestamp": "2025-05-06T15:07:00.583394", "query_length": 158, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-06 15:07:00,583 - api.main - INFO - Inicializando modelo de reescritura de consultas
2025-05-06 15:07:04,468 - api.main - WARNING - Timeout (2.5s) durante la reescritura de la consulta: 'Che, ¿cómo sería una arquitectura tipo RAG pero usando sólo modelos encoder-only, tipo BERT o similares? ¿Se puede evitar usar un decoder como GPT o DeepSeek?'. Se usará la consulta original.
2025-05-06 15:07:04,468 - api.main - INFO - Usando consulta original para retrieval: 'Che, ¿cómo sería una arquitectura tipo RAG pero usando sólo modelos encoder-only, tipo BERT o similares? ¿Se puede evitar usar un decoder como GPT o DeepSeek?'
2025-05-06 15:07:05,430 - api.main - INFO - Inicializando retriever
2025-05-06 15:07:05,431 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-06 15:07:05,438 - api.main - INFO - Inicializando conexión a PGVector
2025-05-06 15:07:05,439 - api.main - INFO - Inicializando modelo de embeddings
2025-05-06 15:07:05,662 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-06 15:07:24,181 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-06 15:07:37,307 - api.main - INFO - Documentos originales: 4, Documentos fusionados: 1
2025-05-06 15:07:37,325 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 36.7471s
2025-05-06 15:07:37,332 - api.main - INFO - QueryMetrics: {"timestamp": "2025-05-06T15:07:37.332059", "query_length": 158, "num_sources": 1, "execution_time": 36.72787117958069, "language": "es", "quality_assessment": "not_evaluated"}
2025-05-06 15:11:42,736 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746555102-589988", "timestamp": "2025-05-06T15:11:42.735749", "query_length": 216, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-06 15:11:45,239 - api.main - WARNING - Timeout (2.5s) durante la reescritura de la consulta: 'Hola, estoy intentando entender cuál es el mejor programa para sacar texto de unos PDFs de patentes y artículos científicos. ¿Qué dice este estudio sobre eso? ¿Hay alguno que funcione mejor para esos casos difíciles?'. Se usará la consulta original.
2025-05-06 15:11:45,246 - api.main - INFO - Usando consulta original para retrieval: 'Hola, estoy intentando entender cuál es el mejor programa para sacar texto de unos PDFs de patentes y artículos científicos. ¿Qué dice este estudio sobre eso? ¿Hay alguno que funcione mejor para esos casos difíciles?'
2025-05-06 15:11:52,932 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-06 15:12:14,039 - api.main - INFO - Documentos originales: 4, Documentos fusionados: 2
2025-05-06 15:12:14,045 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 31.3377s
2025-05-06 15:12:14,050 - api.main - INFO - QueryMetrics: {"timestamp": "2025-05-06T15:12:14.050387", "query_length": 216, "num_sources": 2, "execution_time": 31.305774688720703, "language": "es", "quality_assessment": "not_evaluated"}
2025-05-06 15:13:39,051 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746555219-087a94", "timestamp": "2025-05-06T15:13:39.051691", "query_length": 194, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-06 15:13:39,550 - api.main - INFO - Consulta original: 'Hey, I was wondering, for just general text extraction, which PDF parsing tools usually did better according to this paper? And did they mention any specific challenges with PDF parsing overall?'
2025-05-06 15:13:39,551 - api.main - INFO - Consulta reescrita: 'no'
2025-05-06 15:13:39,551 - api.main - INFO - Consulta combinada para retrieval: 'Hey, I was wondering, for just general text extraction, which PDF parsing tools usually did better according to this paper? And did they mention any specific challenges with PDF parsing overall? | no'
2025-05-06 15:13:46,601 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-06 15:14:01,567 - api.main - INFO - Documentos originales: 4, Documentos fusionados: 1
2025-05-06 15:14:01,568 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 22.5242s
2025-05-06 15:14:01,570 - api.main - INFO - QueryMetrics: {"timestamp": "2025-05-06T15:14:01.570857", "query_length": 194, "num_sources": 1, "execution_time": 22.51747965812683, "language": "es", "quality_assessment": "not_evaluated"}
2025-05-06 16:55:57,496 - api.main - INFO - Cerrando recursos y conexiones
2025-05-06 16:57:16,935 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 16:57:29,577 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 16:57:40,651 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 16:57:51,149 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 16:59:35,046 - api.main - INFO - Cerrando recursos y conexiones
2025-05-06 16:59:49,284 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 17:00:02,756 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 17:00:35,063 - api.main - INFO - Cerrando recursos y conexiones
2025-05-06 17:00:49,141 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 17:02:39,117 - api.main - INFO - Cerrando recursos y conexiones
2025-05-06 17:03:11,467 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 17:03:51,393 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746561831-087a94", "timestamp": "2025-05-06T17:03:51.393098", "query_length": 194, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-06 17:03:51,396 - api.main - ERROR - Error global inesperado en el endpoint /query para la consulta 'Hey, I was wondering, for just general text extraction, which PDF parsing tools usually did better according to this paper? And did they mention any specific challenges with PDF parsing overall?': 'Settings' object has no attribute 'query_rewrite_strategy'
Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 758, in query_documents
    if settings.query_rewrite_strategy != "original_only": # Solo reescribir si la estrategia no es 'solo original'
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\pydantic\main.py", line 989, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
AttributeError: 'Settings' object has no attribute 'query_rewrite_strategy'
2025-05-06 17:03:51,545 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 0.1923s
2025-05-06 17:04:50,216 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746561890-087a94", "timestamp": "2025-05-06T17:04:50.216109", "query_length": 194, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-06 17:04:50,217 - api.main - ERROR - Error global inesperado en el endpoint /query para la consulta 'Hey, I was wondering, for just general text extraction, which PDF parsing tools usually did better according to this paper? And did they mention any specific challenges with PDF parsing overall?': 'Settings' object has no attribute 'query_rewrite_strategy'
Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 758, in query_documents
    if settings.query_rewrite_strategy != "original_only": # Solo reescribir si la estrategia no es 'solo original'
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\pydantic\main.py", line 989, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
AttributeError: 'Settings' object has no attribute 'query_rewrite_strategy'
2025-05-06 17:04:50,219 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 0.0063s
2025-05-06 17:06:15,352 - api.main - INFO - Cerrando recursos y conexiones
2025-05-06 17:06:32,287 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 17:06:33,273 - api.main - INFO - Cerrando recursos y conexiones
2025-05-06 17:06:47,093 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 17:07:00,447 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 17:07:06,519 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746562026-087a94", "timestamp": "2025-05-06T17:07:06.519479", "query_length": 194, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-06 17:07:06,520 - api.main - INFO - Obteniendo LLM de DeepSeek para reescritura de consultas.
2025-05-06 17:07:07,628 - api.main - ERROR - Error inesperado en reescritura de consulta con DeepSeek 'Hey, I was wondering, for just general text extraction, which PDF parsing tools usually did better according to this paper? And did they mention any specific challenges with PDF parsing overall?': name 'LLMChain' is not defined
Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 777, in query_documents
    rewrite_chain = LLMChain(llm=deepseek_llm_for_rewrite, prompt=prompt_for_rewrite)
                    ^^^^^^^^
NameError: name 'LLMChain' is not defined
2025-05-06 17:07:07,630 - api.main - INFO - Estrategia de consulta: Concatenar. Usando: 'Hey, I was wondering, for just general text extraction, which PDF parsing tools usually did better according to this paper? And did they mention any specific challenges with PDF parsing overall?'
2025-05-06 17:07:07,631 - api.main - INFO - Inicializando retriever
2025-05-06 17:07:07,631 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-06 17:07:07,631 - api.main - INFO - Inicializando conexión a PGVector
2025-05-06 17:07:07,631 - api.main - INFO - Inicializando modelo de embeddings
2025-05-06 17:07:08,837 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-06 17:07:27,635 - api.main - INFO - Recuperados 4 documentos del retriever (post-compresión/reranking).
2025-05-06 17:07:27,639 - api.main - INFO - Documentos originales: 4, Documentos fusionados: 1
2025-05-06 17:07:27,649 - api.main - ERROR - Error durante el pipeline de QA para la consulta 'Hey, I was wondering, for just general text extraction, which PDF parsing tools usually did better according to this paper? And did they mention any specific challenges with PDF parsing overall?': name 'LLMChain' is not defined
Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 853, in query_documents
    final_answer_chain = LLMChain(llm=llm_for_answer, prompt=qa_prompt_template)
                         ^^^^^^^^
NameError: name 'LLMChain' is not defined
2025-05-06 17:07:27,677 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 21.1635s
2025-05-06 17:08:16,616 - api.main - INFO - Cerrando recursos y conexiones
2025-05-06 17:08:35,347 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 17:08:35,362 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746562115-087a94", "timestamp": "2025-05-06T17:08:35.362113", "query_length": 194, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-06 17:08:35,362 - api.main - INFO - Obteniendo LLM de DeepSeek para reescritura de consultas.
2025-05-06 17:08:36,032 - api.main - INFO - Intentando reescribir consulta con DeepSeek: 'Hey, I was wondering, for just general text extraction, which PDF parsing tools usually did better according to this paper? And did they mention any specific challenges with PDF parsing overall?'
2025-05-06 17:08:38,117 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-06 17:08:41,043 - api.main - WARNING - Timeout durante la reescritura de la consulta con DeepSeek: 'Hey, I was wondering, for just general text extraction, which PDF parsing tools usually did better according to this paper? And did they mention any specific challenges with PDF parsing overall?'.
2025-05-06 17:08:41,044 - api.main - INFO - Estrategia de consulta: Concatenar. Usando: 'Hey, I was wondering, for just general text extraction, which PDF parsing tools usually did better according to this paper? And did they mention any specific challenges with PDF parsing overall?'
2025-05-06 17:08:41,044 - api.main - INFO - Inicializando retriever
2025-05-06 17:08:41,045 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-06 17:08:41,045 - api.main - INFO - Inicializando conexión a PGVector
2025-05-06 17:08:41,045 - api.main - INFO - Inicializando modelo de embeddings
2025-05-06 17:08:41,263 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-06 17:08:57,014 - api.main - INFO - Recuperados 4 documentos del retriever (post-compresión/reranking).
2025-05-06 17:08:57,038 - api.main - INFO - Documentos originales: 4, Documentos fusionados: 1
2025-05-06 17:08:58,090 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-06 17:09:11,023 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 35.6665s
2025-05-06 17:09:11,040 - api.main - INFO - QueryMetrics: {"timestamp": "2025-05-06T17:09:11.040031", "query_length": 194, "num_sources": 1, "execution_time": 35.63192296028137, "language": "es", "quality_assessment": "not_evaluated"}
2025-05-06 17:13:39,212 - api.main - INFO - Cerrando recursos y conexiones
2025-05-06 17:13:56,699 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 17:14:02,819 - api.main - INFO - Cerrando recursos y conexiones
2025-05-06 17:14:13,735 - api.main - INFO - Iniciando aplicación API RAG
2025-05-06 17:14:17,825 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746562457-087a94", "timestamp": "2025-05-06T17:14:17.825663", "query_length": 194, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-06 17:14:17,826 - api.main - INFO - Obteniendo LLM de DeepSeek para reescritura de consultas.
2025-05-06 17:14:18,638 - api.main - INFO - Intentando reescribir consulta con DeepSeek: 'Hey, I was wondering, for just general text extraction, which PDF parsing tools usually did better according to this paper? And did they mention any specific challenges with PDF parsing overall?'
2025-05-06 17:14:19,446 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-06 17:14:23,584 - api.main - INFO - Consulta original: 'Hey, I was wondering, for just general text extraction, which PDF parsing tools usually did better according to this paper? And did they mention any specific challenges with PDF parsing overall?'
2025-05-06 17:14:23,585 - api.main - INFO - Consulta reescrita por DeepSeek: 'What are the most effective PDF parsing tools for general text extraction according to the study, and what key challenges in PDF parsing are identified?'
2025-05-06 17:14:23,585 - api.main - INFO - Estrategia de consulta: Solo reescrita. Usando: 'What are the most effective PDF parsing tools for general text extraction according to the study, and what key challenges in PDF parsing are identified?' (fallback a original si reescritura falló o no cambió)
2025-05-06 17:14:23,585 - api.main - INFO - Inicializando retriever
2025-05-06 17:14:23,586 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-06 17:14:23,586 - api.main - INFO - Inicializando conexión a PGVector
2025-05-06 17:14:23,586 - api.main - INFO - Inicializando modelo de embeddings
2025-05-06 17:14:23,758 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-06 17:14:36,770 - api.main - INFO - Recuperados 4 documentos del retriever (post-compresión/reranking).
2025-05-06 17:14:36,773 - api.main - INFO - Documentos originales: 4, Documentos fusionados: 1
2025-05-06 17:14:37,513 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-06 17:14:51,168 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 33.3480s
2025-05-06 17:14:51,173 - api.main - INFO - QueryMetrics: {"timestamp": "2025-05-06T17:14:51.173441", "query_length": 194, "num_sources": 1, "execution_time": 33.33535075187683, "language": "es", "quality_assessment": "not_evaluated"}
2025-05-06 18:59:06,039 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 10:50:15,283 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 10:50:35,839 - api.main - INFO - Request: GET /docs | Status: 200 | Duration: 0.0007s
2025-05-07 10:50:36,758 - api.main - INFO - Request: GET /openapi.json | Status: 200 | Duration: 0.0154s
2025-05-07 10:50:55,131 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746625855-cc9afb", "timestamp": "2025-05-07T10:50:55.131639", "query_length": 64, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-07 10:50:55,132 - api.main - INFO - Obteniendo LLM de DeepSeek para reescritura de consultas.
2025-05-07 10:50:56,198 - api.main - INFO - Intentando reescribir consulta con DeepSeek: '¿Cómo se pagan los feriados si igual tengo que trabajar ese día?'
2025-05-07 10:50:57,387 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 10:51:08,361 - api.main - INFO - Consulta original: '¿Cómo se pagan los feriados si igual tengo que trabajar ese día?'
2025-05-07 10:51:08,361 - api.main - INFO - Consulta reescrita por DeepSeek: '¿Cuál es la normativa legal sobre remuneración por trabajar en días feriados según el código laboral vigente?  

Otra alternativa posible:  
¿Qué criterios determinan el pago de horas trabajadas en días feriados no laborables?  

(Se priorizan términos como *normativa*, *remuneración*, *código laboral*, *días feriados no laborables* y *horas trabajadas*, que son clave en documentos técnicos/jurídicos sobre el tema).'
2025-05-07 10:51:08,363 - api.main - INFO - Estrategia de consulta: Solo reescrita. Usando: '¿Cuál es la normativa legal sobre remuneración por trabajar en días feriados según el código laboral vigente?  

Otra alternativa posible:  
¿Qué criterios determinan el pago de horas trabajadas en días feriados no laborables?  

(Se priorizan términos como *normativa*, *remuneración*, *código laboral*, *días feriados no laborables* y *horas trabajadas*, que son clave en documentos técnicos/jurídicos sobre el tema).' (fallback a original si reescritura falló o no cambió)
2025-05-07 10:51:08,363 - api.main - INFO - Inicializando retriever
2025-05-07 10:51:08,364 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-07 10:51:08,364 - api.main - INFO - Inicializando conexión a PGVector
2025-05-07 10:51:08,364 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 10:51:08,557 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 10:51:24,790 - api.main - INFO - Recuperados 4 documentos del retriever (post-compresión/reranking).
2025-05-07 10:51:24,792 - api.main - INFO - --- Contenido de los documentos recuperados (raw_source_docs) ---
2025-05-07 10:51:24,792 - api.main - INFO - Documento 1 (Score: N/A):
2025-05-07 10:51:24,793 - api.main - INFO - Metadata: {'producer': 'Acrobat Distiller 4.0 for Macintosh', 'creator': 'Microsoft Word: LaserWriter 8 Z1-8.7', 'creationdate': 'D:20020919072653', 'title': 'Microsoft Word - convenio260-75.doc', 'author': 'G3BLUE', 'subject': '', 'keywords': '', 'moddate': '2002-09-19T07:27:20-07:00', 'source': 'Convenio_Colectivo_nro_260-75.pdf', 'total_pages': 194, 'page': 17, 'extension': 'pdf', 'ingest_time': 1746625610.2493477, 'chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-178', 'chunk_index': 178, 'chunk_total': 1667, 'file_size': 427740, 'doc_type': 'pdf', 'process_date': '2025-05-07T10:46:50.249427', 'prev_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-177', 'next_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-179', 'chunk_size_used': 414, 'chunk_overlap_used': 124, 'doc_semantic_density': 0.12023393154062267, 'doc_analysis_details': {'extension': 'pdf', 'doc_type': 'pdf', 'avg_sentence_length': 23.829692832764504, 'avg_paragraph_length': 351.22222222222223, 'semantic_density': 0.12023393154062267, 'has_structures': True, 'complexity': 1.90619102823885}, 'language': 'es', 'content_hash': '736f9908b2aa9a059545c5cf246413e3'}
2025-05-07 10:51:24,793 - api.main - INFO - Content Preview: laborable. La remuneración del obrero jornal izado correspondiente a este día, será liquidada
conforme al régimen de los días feriados de pago obligatorio.
 Capítulo 9
 ORDENAMIENTO DE LAS RELACIONES LABORABLES
Artículo 43° Documento situación laboral: Los empleadores entregarán a todo su personal
una tarjeta, cuyo duplicado firmará el empleado u obrero (firma de notificación), la que llevará...
2025-05-07 10:51:24,794 - api.main - INFO - --------------------------------------------------
2025-05-07 10:51:24,794 - api.main - INFO - Documento 2 (Score: N/A):
2025-05-07 10:51:24,795 - api.main - INFO - Metadata: {'producer': 'Acrobat Distiller 4.0 for Macintosh', 'creator': 'Microsoft Word: LaserWriter 8 Z1-8.7', 'creationdate': 'D:20020919072653', 'title': 'Microsoft Word - convenio260-75.doc', 'author': 'G3BLUE', 'subject': '', 'keywords': '', 'moddate': '2002-09-19T07:27:20-07:00', 'source': 'Convenio_Colectivo_nro_260-75.pdf', 'total_pages': 194, 'page': 22, 'extension': 'pdf', 'ingest_time': 1746625610.4443414, 'chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-228', 'chunk_index': 228, 'chunk_total': 1667, 'file_size': 427740, 'doc_type': 'pdf', 'process_date': '2025-05-07T10:46:50.444436', 'prev_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-227', 'next_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-229', 'chunk_size_used': 414, 'chunk_overlap_used': 124, 'doc_semantic_density': 0.12023393154062267, 'doc_analysis_details': {'extension': 'pdf', 'doc_type': 'pdf', 'avg_sentence_length': 23.829692832764504, 'avg_paragraph_length': 351.22222222222223, 'semantic_density': 0.12023393154062267, 'has_structures': True, 'complexity': 1.90619102823885}, 'language': 'es', 'content_hash': '51df6f5b351d55f7674d26e883bfa365'}
2025-05-07 10:51:24,795 - api.main - INFO - Content Preview: como jornada simple de trabajo. Si el trabajador prestara servicios efectivos el día sábado
después de las trece (13) horas y el día domingo se le pagará el salario de acuerdo a la ley.
e) Si la realización de las tareas encomendadas al trabajador tienen una duración superior a un
día y éste no puede regresar a su domicilio se le deberán pagar, además, los gastos de...
2025-05-07 10:51:24,796 - api.main - INFO - --------------------------------------------------
2025-05-07 10:51:24,796 - api.main - INFO - Documento 3 (Score: N/A):
2025-05-07 10:51:24,796 - api.main - INFO - Metadata: {'producer': 'Acrobat Distiller 4.0 for Macintosh', 'creator': 'Microsoft Word: LaserWriter 8 Z1-8.7', 'creationdate': 'D:20020919072653', 'title': 'Microsoft Word - convenio260-75.doc', 'author': 'G3BLUE', 'subject': '', 'keywords': '', 'moddate': '2002-09-19T07:27:20-07:00', 'source': 'Convenio_Colectivo_nro_260-75.pdf', 'total_pages': 194, 'page': 48, 'extension': 'pdf', 'ingest_time': 1746625611.569067, 'chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-486', 'chunk_index': 486, 'chunk_total': 1667, 'file_size': 427740, 'doc_type': 'pdf', 'process_date': '2025-05-07T10:46:51.569485', 'prev_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-485', 'next_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-487', 'chunk_size_used': 414, 'chunk_overlap_used': 124, 'doc_semantic_density': 0.12023393154062267, 'doc_analysis_details': {'extension': 'pdf', 'doc_type': 'pdf', 'avg_sentence_length': 23.829692832764504, 'avg_paragraph_length': 351.22222222222223, 'semantic_density': 0.12023393154062267, 'has_structures': True, 'complexity': 1.90619102823885}, 'language': 'es', 'content_hash': '94a54d48912a585e6eb72ca973249375'}
2025-05-07 10:51:24,796 - api.main - INFO - Content Preview: durante el día, solo se abonarán los gastos, consideràndose el tiempo de trabajo como horas
trabajadas u el tiempo de viaje comprendido durante las horas de trabajo será abonado de
acuerdo al salario que perciba el obrero. Además, las horas de viaje fuera de la jornada normal
de trabajo, es decir, ocho horas diarias o cuarenta y ocho semanales que determina la Ley...
2025-05-07 10:51:24,797 - api.main - INFO - --------------------------------------------------
2025-05-07 10:51:24,797 - api.main - INFO - Documento 4 (Score: N/A):
2025-05-07 10:51:24,797 - api.main - INFO - Metadata: {'producer': 'Acrobat Distiller 4.0 for Macintosh', 'creator': 'Microsoft Word: LaserWriter 8 Z1-8.7', 'creationdate': 'D:20020919072653', 'title': 'Microsoft Word - convenio260-75.doc', 'author': 'G3BLUE', 'subject': '', 'keywords': '', 'moddate': '2002-09-19T07:27:20-07:00', 'source': 'Convenio_Colectivo_nro_260-75.pdf', 'total_pages': 194, 'page': 49, 'extension': 'pdf', 'ingest_time': 1746625611.59521, 'chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-492', 'chunk_index': 492, 'chunk_total': 1667, 'file_size': 427740, 'doc_type': 'pdf', 'process_date': '2025-05-07T10:46:51.595824', 'prev_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-491', 'next_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-493', 'chunk_size_used': 414, 'chunk_overlap_used': 124, 'doc_semantic_density': 0.12023393154062267, 'doc_analysis_details': {'extension': 'pdf', 'doc_type': 'pdf', 'avg_sentence_length': 23.829692832764504, 'avg_paragraph_length': 351.22222222222223, 'semantic_density': 0.12023393154062267, 'has_structures': True, 'complexity': 1.90619102823885}, 'language': 'es', 'content_hash': 'c098b874e6210233497ff603ce0e5452'}
2025-05-07 10:51:24,798 - api.main - INFO - Content Preview: abonado hasta el momento del reembarque. Si la estadía excede de los seis días de trabajo,
debe computarse el día sábado a partir de las trece horas y el domingo como jornadas simples
de trabajo. Si el obrero trabaja el día sábado después de las trece horas y/o el domingo, se le
abonará el salario de acuerdo a la ley.
Comisión permanente...
2025-05-07 10:51:24,799 - api.main - INFO - --------------------------------------------------
2025-05-07 10:51:24,800 - api.main - INFO - Documentos originales: 4, Documentos fusionados: 3
2025-05-07 10:51:25,446 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 10:51:45,347 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 50.2210s
2025-05-07 10:51:45,352 - api.main - INFO - QueryMetrics: {"timestamp": "2025-05-07T10:51:45.352820", "query_length": 64, "num_sources": 3, "execution_time": 50.20319652557373, "language": "es", "quality_assessment": "not_evaluated"}
2025-05-07 10:52:15,125 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746625935-0b78a5", "timestamp": "2025-05-07T10:52:15.124987", "query_length": 74, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-07 10:52:15,126 - api.main - INFO - Obteniendo LLM de DeepSeek para reescritura de consultas.
2025-05-07 10:52:15,127 - api.main - INFO - Intentando reescribir consulta con DeepSeek: '¿Cuáles son las categorías que existen para los empleados administrativos?'
2025-05-07 10:52:15,720 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 10:52:21,768 - api.main - INFO - Consulta original: '¿Cuáles son las categorías que existen para los empleados administrativos?'
2025-05-07 10:52:21,769 - api.main - INFO - Consulta reescrita por DeepSeek: '¿Qué clasificaciones o niveles jerárquicos existen para el personal administrativo en el ámbito laboral?  

Otra alternativa posible:  
¿Cuáles son las categorías profesionales establecidas para empleados administrativos en normativas laborales o convenios colectivos?'
2025-05-07 10:52:21,770 - api.main - INFO - Estrategia de consulta: Solo reescrita. Usando: '¿Qué clasificaciones o niveles jerárquicos existen para el personal administrativo en el ámbito laboral?  

Otra alternativa posible:  
¿Cuáles son las categorías profesionales establecidas para empleados administrativos en normativas laborales o convenios colectivos?' (fallback a original si reescritura falló o no cambió)
2025-05-07 10:52:26,489 - api.main - INFO - Recuperados 4 documentos del retriever (post-compresión/reranking).
2025-05-07 10:52:26,489 - api.main - INFO - --- Contenido de los documentos recuperados (raw_source_docs) ---
2025-05-07 10:52:26,490 - api.main - INFO - Documento 1 (Score: N/A):
2025-05-07 10:52:26,490 - api.main - INFO - Metadata: {'producer': 'Acrobat Distiller 4.0 for Macintosh', 'creator': 'Microsoft Word: LaserWriter 8 Z1-8.7', 'creationdate': 'D:20020919072653', 'title': 'Microsoft Word - convenio260-75.doc', 'author': 'G3BLUE', 'subject': '', 'keywords': '', 'moddate': '2002-09-19T07:27:20-07:00', 'source': 'Convenio_Colectivo_nro_260-75.pdf', 'total_pages': 194, 'page': 152, 'extension': 'pdf', 'ingest_time': 1746625615.5081503, 'chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-1342', 'chunk_index': 1342, 'chunk_total': 1667, 'file_size': 427740, 'doc_type': 'pdf', 'process_date': '2025-05-07T10:46:55.508214', 'prev_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-1341', 'next_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-1343', 'chunk_size_used': 414, 'chunk_overlap_used': 124, 'doc_semantic_density': 0.12023393154062267, 'doc_analysis_details': {'extension': 'pdf', 'doc_type': 'pdf', 'avg_sentence_length': 23.829692832764504, 'avg_paragraph_length': 351.22222222222223, 'semantic_density': 0.12023393154062267, 'has_structures': True, 'complexity': 1.90619102823885}, 'language': 'es', 'content_hash': '9ee14317e88d2f4ced490b3909f6bb76'}
2025-05-07 10:52:26,490 - api.main - INFO - Content Preview: establecidos:
- OFICIAL MULTIPLE
- OFICIAL
- OPERARIO ESPECIALIZADO MULTIPLE
- OPERARIO ESPECIALIZADO
- MEDIO OFICIAL
- OPERARIO CALIFICADO
- OPERARIO
- PEON
Artículo 3.- Categorías específicas de la Rama: se establecen en la Rama las categorías
específicas de oficio que se detallan a continuación:
- CARPINTERO METALICO
- HERRERO
- FRAGUADOR ARTISTICO
- PLEGADOR
- SOLDADOR
- TORNERO
- FRESADOR
- MECÁNICO...
2025-05-07 10:52:26,491 - api.main - INFO - --------------------------------------------------
2025-05-07 10:52:26,491 - api.main - INFO - Documento 2 (Score: N/A):
2025-05-07 10:52:26,491 - api.main - INFO - Metadata: {'producer': 'Acrobat Distiller 4.0 for Macintosh', 'creator': 'Microsoft Word: LaserWriter 8 Z1-8.7', 'creationdate': 'D:20020919072653', 'title': 'Microsoft Word - convenio260-75.doc', 'author': 'G3BLUE', 'subject': '', 'keywords': '', 'moddate': '2002-09-19T07:27:20-07:00', 'source': 'Convenio_Colectivo_nro_260-75.pdf', 'total_pages': 194, 'page': 155, 'extension': 'pdf', 'ingest_time': 1746625615.5996277, 'chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-1372', 'chunk_index': 1372, 'chunk_total': 1667, 'file_size': 427740, 'doc_type': 'pdf', 'process_date': '2025-05-07T10:46:55.599685', 'prev_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-1371', 'next_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-1373', 'chunk_size_used': 414, 'chunk_overlap_used': 124, 'doc_semantic_density': 0.12023393154062267, 'doc_analysis_details': {'extension': 'pdf', 'doc_type': 'pdf', 'avg_sentence_length': 23.829692832764504, 'avg_paragraph_length': 351.22222222222223, 'semantic_density': 0.12023393154062267, 'has_structures': True, 'complexity': 1.90619102823885}, 'language': 'es', 'content_hash': 'ae9f5066d9bbccbe2c2c080b3a886ef4'}
2025-05-07 10:52:26,492 - api.main - INFO - Content Preview: -OFICIAL
-OPERARIO ESPECIALIZADO MULTIPLE
-OPERARIO ESPECIALIZADO
-MEDIO OFICIAL
-OPERARIO CALIFICADO
-OPERARIO
-PEON
Artículo 3° Categorías especificas de aplicación a la Rama: Son de aplicación a esta Rama la
siguientes categorías en equivalencia relativa con las categorías del artículo 6°, en idéntica
forma también con cuanto a salarios, que la establecida en la Rama Siderúrgica Sector Plantas...
2025-05-07 10:52:26,492 - api.main - INFO - --------------------------------------------------
2025-05-07 10:52:26,492 - api.main - INFO - Documento 3 (Score: N/A):
2025-05-07 10:52:26,493 - api.main - INFO - Metadata: {'producer': 'Acrobat Distiller 4.0 for Macintosh', 'creator': 'Microsoft Word: LaserWriter 8 Z1-8.7', 'creationdate': 'D:20020919072653', 'title': 'Microsoft Word - convenio260-75.doc', 'author': 'G3BLUE', 'subject': '', 'keywords': '', 'moddate': '2002-09-19T07:27:20-07:00', 'source': 'Convenio_Colectivo_nro_260-75.pdf', 'total_pages': 194, 'page': 127, 'extension': 'pdf', 'ingest_time': 1746625614.7122993, 'chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-1128', 'chunk_index': 1128, 'chunk_total': 1667, 'file_size': 427740, 'doc_type': 'pdf', 'process_date': '2025-05-07T10:46:54.712469', 'prev_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-1127', 'next_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-1129', 'chunk_size_used': 414, 'chunk_overlap_used': 124, 'doc_semantic_density': 0.12023393154062267, 'doc_analysis_details': {'extension': 'pdf', 'doc_type': 'pdf', 'avg_sentence_length': 23.829692832764504, 'avg_paragraph_length': 351.22222222222223, 'semantic_density': 0.12023393154062267, 'has_structures': True, 'complexity': 1.90619102823885}, 'language': 'es', 'content_hash': 'dc680e8af91d1e55f2ddd751acef0716'}
2025-05-07 10:52:26,493 - api.main - INFO - Content Preview: Categorías generales establecidas en el Artículo 6to. con las definiciones y alcances allì
establecidas:
- OFICIAL MULTIPLE
- OFICIAL
- OPERARIO ESPECIALIZADO MULTIPLE
- OPERARIO ESPECIALIZADO
- MEDIO OFICIAL
- OPERARIO CALIFICADO
- OPERARIO
- PEON
Artículo 3 - Nòmina de oficiospropios de la Rama: A continuaciòn se discriminan tareas de...
2025-05-07 10:52:26,494 - api.main - INFO - --------------------------------------------------
2025-05-07 10:52:26,494 - api.main - INFO - Documento 4 (Score: N/A):
2025-05-07 10:52:26,494 - api.main - INFO - Metadata: {'producer': 'Acrobat Distiller 4.0 for Macintosh', 'creator': 'Microsoft Word: LaserWriter 8 Z1-8.7', 'creationdate': 'D:20020919072653', 'title': 'Microsoft Word - convenio260-75.doc', 'author': 'G3BLUE', 'subject': '', 'keywords': '', 'moddate': '2002-09-19T07:27:20-07:00', 'source': 'Convenio_Colectivo_nro_260-75.pdf', 'total_pages': 194, 'page': 171, 'extension': 'pdf', 'ingest_time': 1746625616.0674508, 'chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-1501', 'chunk_index': 1501, 'chunk_total': 1667, 'file_size': 427740, 'doc_type': 'pdf', 'process_date': '2025-05-07T10:46:56.067520', 'prev_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-1500', 'next_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-1502', 'chunk_size_used': 414, 'chunk_overlap_used': 124, 'doc_semantic_density': 0.12023393154062267, 'doc_analysis_details': {'extension': 'pdf', 'doc_type': 'pdf', 'avg_sentence_length': 23.829692832764504, 'avg_paragraph_length': 351.22222222222223, 'semantic_density': 0.12023393154062267, 'has_structures': True, 'complexity': 1.90619102823885}, 'language': 'es', 'content_hash': '3116e2f5f99e802eefe78881a84b10a4'}
2025-05-07 10:52:26,495 - api.main - INFO - Content Preview: aglomerados, o briquetas, o sinterizados, o nódulos, mediante un proceso mecánico, o químico
o de fusión.
Artículo 6° Categorías generales de aplicación en la Rama: Son de aplicación a esta Rama y a
todos sus sectores, con las definiciones y alcances establecidos en el artículo 6° del título II
(capítulo 1°), las categorías que a continuación se indican:
a) En tareas de Oficios:
-OFICIAL MULTIPLE
-OFICIAL...
2025-05-07 10:52:26,496 - api.main - INFO - --------------------------------------------------
2025-05-07 10:52:26,497 - api.main - INFO - Documentos originales: 4, Documentos fusionados: 4
2025-05-07 10:52:26,989 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 10:52:38,563 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 23.4572s
2025-05-07 10:52:38,565 - api.main - INFO - QueryMetrics: {"timestamp": "2025-05-07T10:52:38.565214", "query_length": 74, "num_sources": 4, "execution_time": 23.44024133682251, "language": "es", "quality_assessment": "not_evaluated"}
2025-05-07 11:04:37,514 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 11:23:10,488 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 11:23:44,980 - api.main - INFO - Request: GET /docs | Status: 200 | Duration: 0.0003s
2025-05-07 11:23:45,582 - api.main - INFO - Request: GET /openapi.json | Status: 200 | Duration: 0.0112s
2025-05-07 11:23:51,838 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746627831-a4af07", "timestamp": "2025-05-07T11:23:51.838564", "query_length": 65, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-07 11:23:51,839 - api.main - INFO - Obteniendo LLM de DeepSeek para reescritura de consultas.
2025-05-07 11:23:52,611 - api.main - INFO - Intentando reescribir consulta con DeepSeek: 'Como es el algoritmo de diagnostico en mujeres menores a 30 años?'
2025-05-07 11:23:53,552 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 11:24:05,473 - api.main - INFO - Consulta original: 'Como es el algoritmo de diagnostico en mujeres menores a 30 años?'
2025-05-07 11:24:05,474 - api.main - INFO - Consulta reescrita por DeepSeek: '¿Cuáles son los criterios y procedimientos del algoritmo de diagnóstico clínico para condiciones ginecológicas en pacientes femeninas menores de 30 años?  

Otra alternativa:  
¿Qué protocolos diagnósticos estandarizados se aplican en la evaluación de patologías ginecológicas en mujeres de 20 a 30 años?  

(Nota: Las versiones optimizadas incorporan terminología médica formal (criterios, protocolos estandarizados, evaluación), especifican el ámbito clínico (ginecológicas) y delimitan mejor el rango etario. Se asume que el contexto original se refería a salud reproductiva; de ser otro ámbito, ajustar ginecológicas por la especialidad correspondiente, ej.: cardiológicas).'
2025-05-07 11:24:05,474 - api.main - INFO - Estrategia de consulta: Solo reescrita. Usando: '¿Cuáles son los criterios y procedimientos del algoritmo de diagnóstico clínico para condiciones ginecológicas en pacientes femeninas menores de 30 años?  

Otra alternativa:  
¿Qué protocolos diagnósticos estandarizados se aplican en la evaluación de patologías ginecológicas en mujeres de 20 a 30 años?  

(Nota: Las versiones optimizadas incorporan terminología médica formal (criterios, protocolos estandarizados, evaluación), especifican el ámbito clínico (ginecológicas) y delimitan mejor el rango etario. Se asume que el contexto original se refería a salud reproductiva; de ser otro ámbito, ajustar ginecológicas por la especialidad correspondiente, ej.: cardiológicas).' (fallback a original si reescritura falló o no cambió)
2025-05-07 11:24:05,475 - api.main - INFO - Inicializando retriever
2025-05-07 11:24:05,475 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-07 11:24:05,475 - api.main - INFO - Inicializando conexión a PGVector
2025-05-07 11:24:05,476 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 11:24:05,646 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 11:24:21,375 - api.main - INFO - Recuperados 4 documentos del retriever (post-compresión/reranking).
2025-05-07 11:24:21,376 - api.main - INFO - --- Contenido de los documentos recuperados (raw_source_docs) ---
2025-05-07 11:24:21,377 - api.main - INFO - Documento 1 (Score: N/A):
2025-05-07 11:24:21,377 - api.main - INFO - Metadata: {'page': 110, 'title': 'modo en el cual se realizan; significados de la nomenclatura de sus ', 'author': '', 'source': 'MANUAL PARA LA IMPLEMENTACIÓN.pdf', 'creator': 'Adobe InDesign CC (Windows)', 'moddate': '2020-10-14T20:31:11-03:00', 'subject': '', 'chunk_id': 'MANUAL PARA LA IMPLEMENTACIÓN.pdf-516', 'doc_type': 'pdf', 'keywords': ['VPH'], 'language': 'es', 'producer': 'Adobe PDF Library 10.0.1', 'extension': 'pdf', 'file_size': 2684601, 'chunk_index': 516, 'chunk_total': 669, 'ingest_time': 1746627700.6824563, 'total_pages': 148, 'content_hash': 'fa74d1b1ef653620e0575c920be01b62', 'creationdate': '2016-12-16T10:54:21-03:00', 'process_date': '2025-05-07T11:21:40.682517', 'next_chunk_id': 'MANUAL PARA LA IMPLEMENTACIÓN.pdf-517', 'prev_chunk_id': 'MANUAL PARA LA IMPLEMENTACIÓN.pdf-515', 'chunk_size_used': 414, 'chunk_overlap_used': 99, 'doc_analysis_details': {'doc_type': 'pdf', 'extension': 'pdf', 'complexity': 1.0944199036026945, 'has_structures': True, 'semantic_density': 0.14914503865772674, 'avg_sentence_length': 14.596051998074145, 'avg_paragraph_length': 195.7565789473684}, 'doc_semantic_density': 0.14914503865772674}
2025-05-07 11:24:21,378 - api.main - INFO - Content Preview: modo en el cual se realizan; significados de la nomenclatura de sus 
resultados y la recomendación sobre los algoritmos de seguimiento, diagnóstico y tratamiento de las mujeres VPH+....
2025-05-07 11:24:21,379 - api.main - INFO - --------------------------------------------------
2025-05-07 11:24:21,379 - api.main - INFO - Documento 2 (Score: N/A):
2025-05-07 11:24:21,380 - api.main - INFO - Metadata: {'page': 71, 'title': '72', 'author': '', 'source': 'MANUAL PARA LA IMPLEMENTACIÓN.pdf', 'creator': 'Adobe InDesign CC (Windows)', 'moddate': '2020-10-14T20:31:11-03:00', 'subject': '', 'chunk_id': 'MANUAL PARA LA IMPLEMENTACIÓN.pdf-332', 'doc_type': 'pdf', 'keywords': ['VPH', 'ECC'], 'language': 'es', 'producer': 'Adobe PDF Library 10.0.1', 'extension': 'pdf', 'file_size': 2684601, 'chunk_index': 332, 'chunk_total': 669, 'ingest_time': 1746627700.0325334, 'total_pages': 148, 'content_hash': 'a249c35e63a8276942f2e29767c88913', 'creationdate': '2016-12-16T10:54:21-03:00', 'process_date': '2025-05-07T11:21:40.032627', 'next_chunk_id': 'MANUAL PARA LA IMPLEMENTACIÓN.pdf-333', 'prev_chunk_id': 'MANUAL PARA LA IMPLEMENTACIÓN.pdf-331', 'chunk_size_used': 414, 'chunk_overlap_used': 99, 'doc_analysis_details': {'doc_type': 'pdf', 'extension': 'pdf', 'complexity': 1.0944199036026945, 'has_structures': True, 'semantic_density': 0.14914503865772674, 'avg_sentence_length': 14.596051998074145, 'avg_paragraph_length': 195.7565789473684}, 'doc_semantic_density': 0.14914503865772674}
2025-05-07 11:24:21,380 - api.main - INFO - Content Preview: 72
Figura 3.1 Algoritmo de seguimiento y diagnóstico de las mujeres 
VPH+
Fuente: Arrossi S, Thouyaret L y Paul L, 2015.12
Test de VPH negativo
Test de 
VPH a los 
5 años
Colposcopía 
y biopsia de 
imágenes 
anormales
Colposcopía, 
biopsia de 
imágenes 
anormales y 
ECC en ZT3
Colposcopía, 
biopsia de 
imágenes 
anormales, 
ECC y Eco TV
Test de VPH positivo
Test de 
VPH a los 
5 años
Test de 
VPH a los...
2025-05-07 11:24:21,381 - api.main - INFO - --------------------------------------------------
2025-05-07 11:24:21,381 - api.main - INFO - Documento 3 (Score: N/A):
2025-05-07 11:24:21,382 - api.main - INFO - Metadata: {'page': 14, 'title': '', 'author': '', 'source': 'MANUAL PARA LA IMPLEMENTACIÓN.pdf', 'creator': 'Adobe InDesign CC (Windows)', 'moddate': '2020-10-14T20:31:11-03:00', 'subject': '', 'chunk_id': 'MANUAL PARA LA IMPLEMENTACIÓN.pdf-49', 'doc_type': 'pdf', 'keywords': '', 'language': 'es', 'producer': 'Adobe PDF Library 10.0.1', 'extension': 'pdf', 'file_size': 2684601, 'chunk_index': 49, 'chunk_total': 669, 'ingest_time': 1746627698.867966, 'total_pages': 148, 'content_hash': 'deff487c59da768d540c8c4a9f86816a', 'creationdate': '2016-12-16T10:54:21-03:00', 'process_date': '2025-05-07T11:21:38.868064', 'next_chunk_id': 'MANUAL PARA LA IMPLEMENTACIÓN.pdf-50', 'prev_chunk_id': 'MANUAL PARA LA IMPLEMENTACIÓN.pdf-48', 'chunk_size_used': 414, 'chunk_overlap_used': 99, 'doc_analysis_details': {'doc_type': 'pdf', 'extension': 'pdf', 'complexity': 1.0944199036026945, 'has_structures': True, 'semantic_density': 0.14914503865772674, 'avg_sentence_length': 14.596051998074145, 'avg_paragraph_length': 195.7565789473684}, 'doc_semantic_density': 0.14914503865772674}
2025-05-07 11:24:21,383 - api.main - INFO - Content Preview: de criterios de población objetivo, edad y frecuencia del tamizaje basados en la 
evidencia científica; la alta cobertura del tamizaje, el diagnóstico y tratamiento de 
las mujeres con lesiones precancerosas; la implementación de sistemas de información; y la incorporación de la perspectiva y necesidades de las mujeres en todo 
el continuo de cuidado....
2025-05-07 11:24:21,384 - api.main - INFO - --------------------------------------------------
2025-05-07 11:24:21,384 - api.main - INFO - Documento 4 (Score: N/A):
2025-05-07 11:24:21,384 - api.main - INFO - Metadata: {'page': 143, 'title': 'de 30+ años detectadas con test de VPH+ y Pap anormal. ', 'author': '', 'source': 'MANUAL PARA LA IMPLEMENTACIÓN.pdf', 'creator': 'Adobe InDesign CC (Windows)', 'moddate': '2020-10-14T20:31:11-03:00', 'subject': '', 'chunk_id': 'MANUAL PARA LA IMPLEMENTACIÓN.pdf-658', 'doc_type': 'pdf', 'keywords': ['VPH'], 'language': 'es', 'producer': 'Adobe PDF Library 10.0.1', 'extension': 'pdf', 'file_size': 2684601, 'chunk_index': 658, 'chunk_total': 669, 'ingest_time': 1746627701.1749954, 'total_pages': 148, 'content_hash': 'fd16fcbe20181fd1f530fc007d37da18', 'creationdate': '2016-12-16T10:54:21-03:00', 'process_date': '2025-05-07T11:21:41.175170', 'next_chunk_id': 'MANUAL PARA LA IMPLEMENTACIÓN.pdf-659', 'prev_chunk_id': 'MANUAL PARA LA IMPLEMENTACIÓN.pdf-657', 'chunk_size_used': 414, 'chunk_overlap_used': 99, 'doc_analysis_details': {'doc_type': 'pdf', 'extension': 'pdf', 'complexity': 1.0944199036026945, 'has_structures': True, 'semantic_density': 0.14914503865772674, 'avg_sentence_length': 14.596051998074145, 'avg_paragraph_length': 195.7565789473684}, 'doc_semantic_density': 0.14914503865772674}
2025-05-07 11:24:21,385 - api.main - INFO - Content Preview: de 30+ años detectadas con test de VPH+ y Pap anormal. 
Es necesario saber quiénes son las mujeres que se encuentran pendientes de ser 
diagnosticadas y/o tratadas y cuáles se encuentran concluidas. Esta información 
posibilita conocer la situación y el proceso de resolución de los casos de riesgo 
de la provincia....
2025-05-07 11:24:21,385 - api.main - INFO - --------------------------------------------------
2025-05-07 11:24:21,387 - api.main - INFO - Documentos originales: 4, Documentos fusionados: 4
2025-05-07 11:24:21,911 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 11:24:37,509 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 45.6755s
2025-05-07 11:24:37,511 - api.main - INFO - QueryMetrics: {"timestamp": "2025-05-07T11:24:37.510974", "query_length": 65, "num_sources": 4, "execution_time": 45.668500661849976, "language": "es", "quality_assessment": "not_evaluated"}
2025-05-07 11:28:42,625 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 11:32:51,332 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 11:34:13,014 - api.main - INFO - Request: POST /query | Status: 422 | Duration: 0.0080s
2025-05-07 11:34:22,914 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746628462-00926f", "timestamp": "2025-05-07T11:34:22.914249", "query_length": 52, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-07 11:34:22,914 - api.main - INFO - Obteniendo LLM de DeepSeek para reescritura de consultas.
2025-05-07 11:34:23,741 - api.main - INFO - Intentando reescribir consulta con DeepSeek: '¿Qué categorías hay para el personal administrativo?'
2025-05-07 11:34:24,666 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 11:34:32,871 - api.main - INFO - Consulta original: '¿Qué categorías hay para el personal administrativo?'
2025-05-07 11:34:32,872 - api.main - INFO - Consulta reescrita por DeepSeek: '¿Cuáles son las clasificaciones o niveles jerárquicos del personal administrativo en el ámbito laboral o académico?  

Otra alternativa más técnica:  
¿Qué taxonomía o estructura organizacional define los roles y categorías del personal administrativo en instituciones o empresas?  

(Se ajusta según el contexto específico si se conoce, ej: sector público, educación, salud, etc.)'
2025-05-07 11:34:32,872 - api.main - INFO - Estrategia de consulta: Solo reescrita. Usando: '¿Cuáles son las clasificaciones o niveles jerárquicos del personal administrativo en el ámbito laboral o académico?  

Otra alternativa más técnica:  
¿Qué taxonomía o estructura organizacional define los roles y categorías del personal administrativo en instituciones o empresas?  

(Se ajusta según el contexto específico si se conoce, ej: sector público, educación, salud, etc.)' (fallback a original si reescritura falló o no cambió)
2025-05-07 11:34:32,872 - api.main - INFO - Inicializando retriever
2025-05-07 11:34:32,873 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-07 11:34:32,873 - api.main - INFO - Inicializando conexión a PGVector
2025-05-07 11:34:32,873 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 11:34:33,202 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 11:34:50,394 - api.main - INFO - Recuperados 4 documentos del retriever (post-compresión/reranking).
2025-05-07 11:34:50,399 - api.main - INFO - --- Contenido de los documentos recuperados (raw_source_docs) ---
2025-05-07 11:34:50,399 - api.main - INFO - Documento 1 (Score: N/A):
2025-05-07 11:34:50,400 - api.main - INFO - Metadata: {'page': 108, 'title': 'las tareas del personal incluìdo en las Categorías inferiores. Revisten en esta', 'author': 'G3BLUE', 'source': 'Convenio_Colectivo_nro_260-75.pdf', 'creator': 'Microsoft Word: LaserWriter 8 Z1-8.7', 'moddate': '2002-09-19T07:27:20-07:00', 'subject': '', 'chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-954', 'doc_type': 'pdf', 'keywords': ['ASISTENTE', 'TECNICO'], 'language': 'es', 'producer': 'Acrobat Distiller 4.0 for Macintosh', 'extension': 'pdf', 'file_size': 427740, 'chunk_index': 954, 'chunk_total': 1667, 'ingest_time': 1746628166.2952142, 'total_pages': 194, 'content_hash': 'd8a5dad2cebab9a9530835ff3035f243', 'creationdate': 'D:20020919072653', 'process_date': '2025-05-07T11:29:26.295271', 'next_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-955', 'prev_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-953', 'chunk_size_used': 414, 'chunk_overlap_used': 124, 'doc_analysis_details': {'doc_type': 'pdf', 'extension': 'pdf', 'complexity': 1.90619102823885, 'has_structures': True, 'semantic_density': 0.12023393154062267, 'avg_sentence_length': 23.829692832764504, 'avg_paragraph_length': 351.22222222222223}, 'doc_semantic_density': 0.12023393154062267}
2025-05-07 11:34:50,401 - api.main - INFO - Content Preview: las tareas del personal incluìdo en las Categorías inferiores. Revisten en esta
categoria:
ASISTENTE TECNICO: Es aquel empleado/a con capacidad tècnica teòricopractica, que con amplio criterio o iniciativa propia y bajo directivas de sus superiores, modifica, substituye o proyecta partes o elementos de construcciones...
2025-05-07 11:34:50,401 - api.main - INFO - --------------------------------------------------
2025-05-07 11:34:50,402 - api.main - INFO - Documento 2 (Score: N/A):
2025-05-07 11:34:50,402 - api.main - INFO - Metadata: {'page': 98, 'title': 'siguientes', 'author': 'G3BLUE', 'source': 'Convenio_Colectivo_nro_260-75.pdf', 'creator': 'Microsoft Word: LaserWriter 8 Z1-8.7', 'moddate': '2002-09-19T07:27:20-07:00', 'subject': '', 'chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-859', 'doc_type': 'pdf', 'keywords': ['PERSONAL', 'GRUPO', 'ADMINISTRATIVO'], 'language': 'es', 'producer': 'Acrobat Distiller 4.0 for Macintosh', 'extension': 'pdf', 'file_size': 427740, 'chunk_index': 859, 'chunk_total': 1667, 'ingest_time': 1746628165.9174645, 'total_pages': 194, 'content_hash': '0b0254fd8a4f55c45087a475370257b9', 'creationdate': 'D:20020919072653', 'process_date': '2025-05-07T11:29:25.917537', 'next_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-860', 'prev_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-858', 'chunk_size_used': 414, 'chunk_overlap_used': 124, 'doc_analysis_details': {'doc_type': 'pdf', 'extension': 'pdf', 'complexity': 1.90619102823885, 'has_structures': True, 'semantic_density': 0.12023393154062267, 'avg_sentence_length': 23.829692832764504, 'avg_paragraph_length': 351.22222222222223}, 'doc_semantic_density': 0.12023393154062267}
2025-05-07 11:34:50,402 - api.main - INFO - Content Preview: siguientes
Artículo 2 -- Grupos y Categorias: Reconòcese los grupos y categorias
que a continuaciòn se indican:
GRUPO A: PERSONAL ADMINISTRATIVO
Categorías:
 -4 (categorìa)...
2025-05-07 11:34:50,403 - api.main - INFO - --------------------------------------------------
2025-05-07 11:34:50,403 - api.main - INFO - Documento 3 (Score: N/A):
2025-05-07 11:34:50,403 - api.main - INFO - Metadata: {'page': 8, 'title': 'Microsoft Word - convenio260-75.doc', 'author': 'G3BLUE', 'source': 'Convenio_Colectivo_nro_260-75.pdf', 'creator': 'Microsoft Word: LaserWriter 8 Z1-8.7', 'moddate': '2002-09-19T07:27:20-07:00', 'subject': '', 'chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-90', 'doc_type': 'pdf', 'keywords': '', 'language': 'es', 'producer': 'Acrobat Distiller 4.0 for Macintosh', 'extension': 'pdf', 'file_size': 427740, 'chunk_index': 90, 'chunk_total': 1667, 'ingest_time': 1746628163.12613, 'total_pages': 194, 'content_hash': '1bcd14a70c35a0cfc494af02efb65e42', 'creationdate': 'D:20020919072653', 'process_date': '2025-05-07T11:29:23.126257', 'next_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-91', 'prev_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-89', 'chunk_size_used': 414, 'chunk_overlap_used': 124, 'doc_analysis_details': {'doc_type': 'pdf', 'extension': 'pdf', 'complexity': 1.90619102823885, 'has_structures': True, 'semantic_density': 0.12023393154062267, 'avg_sentence_length': 23.829692832764504, 'avg_paragraph_length': 351.22222222222223}, 'doc_semantic_density': 0.12023393154062267}
2025-05-07 11:34:50,404 - api.main - INFO - Content Preview: esta categoría. Si no aprobara el examen cobrará el salario de operario hasta que apruebe
dicho examen.
Artículo 14° Categorías de Empleados: Las categorías del personal de empleados se
encuentran establecidas y definidas en la Rama respectiva (Título VI, Capitulo IX).
Artículo 15° Vacantes: Para llenar las vacantes que se produzcan dentro de cada...
2025-05-07 11:34:50,404 - api.main - INFO - --------------------------------------------------
2025-05-07 11:34:50,405 - api.main - INFO - Documento 4 (Score: N/A):
2025-05-07 11:34:50,405 - api.main - INFO - Metadata: {'page': 172, 'title': 'Microsoft Word - convenio260-75.doc', 'author': 'G3BLUE', 'source': 'Convenio_Colectivo_nro_260-75.pdf', 'creator': 'Microsoft Word: LaserWriter 8 Z1-8.7', 'moddate': '2002-09-19T07:27:20-07:00', 'subject': '', 'chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-1517', 'doc_type': 'pdf', 'keywords': '', 'language': 'es', 'producer': 'Acrobat Distiller 4.0 for Macintosh', 'extension': 'pdf', 'file_size': 427740, 'chunk_index': 1517, 'chunk_total': 1667, 'ingest_time': 1746628168.2758508, 'total_pages': 194, 'content_hash': 'f4c2af2aef987ce96ac1d1b4a7eed04d', 'creationdate': 'D:20020919072653', 'process_date': '2025-05-07T11:29:28.275915', 'next_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-1518', 'prev_chunk_id': 'Convenio_Colectivo_nro_260-75.pdf-1516', 'chunk_size_used': 414, 'chunk_overlap_used': 124, 'doc_analysis_details': {'doc_type': 'pdf', 'extension': 'pdf', 'complexity': 1.90619102823885, 'has_structures': True, 'semantic_density': 0.12023393154062267, 'avg_sentence_length': 23.829692832764504, 'avg_paragraph_length': 351.22222222222223}, 'doc_semantic_density': 0.12023393154062267}
2025-05-07 11:34:50,405 - api.main - INFO - Content Preview: taxativamente se señalan, debiendo reunir el obrero los conocimientos teórico-prácticos
necesarios para desempeñar eficientemente las exigencias de los mismos. Queda aclarado
que el personal que en algunas empresas le fue otorgada la categoría de oficial, deberá
continuar con la misma. La presente categoría tiene el mismo salario básico que la categoría
de oficial....
2025-05-07 11:34:50,406 - api.main - INFO - --------------------------------------------------
2025-05-07 11:34:50,408 - api.main - INFO - Documentos originales: 4, Documentos fusionados: 4
2025-05-07 11:34:51,010 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 11:35:07,757 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 44.8634s
2025-05-07 11:35:07,764 - api.main - INFO - QueryMetrics: {"timestamp": "2025-05-07T11:35:07.764148", "query_length": 52, "num_sources": 4, "execution_time": 44.82993841171265, "language": "es", "quality_assessment": "not_evaluated"}
2025-05-07 11:39:12,046 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 11:39:30,922 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 11:40:24,986 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 11:40:40,089 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 11:41:24,060 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 11:41:38,838 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 11:46:32,011 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 11:47:01,863 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746629221-c6247a", "timestamp": "2025-05-07T11:47:01.862888", "query_length": 134, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-07 11:47:01,863 - api.main - INFO - Obteniendo LLM de DeepSeek para reescritura de consultas.
2025-05-07 11:47:02,606 - api.main - INFO - Intentando reescribir consulta con DeepSeek: '¿Cuál es la jornada máxima legal establecida en el Convenio Colectivo de Trabajo N.º 260/75 para el personal comprendido en su ámbito?'
2025-05-07 11:47:03,570 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 11:47:13,686 - api.main - INFO - Consulta original: '¿Cuál es la jornada máxima legal establecida en el Convenio Colectivo de Trabajo N.º 260/75 para el personal comprendido en su ámbito?'
2025-05-07 11:47:13,686 - api.main - INFO - Consulta reescrita por DeepSeek: '¿Cuál es la duración máxima de la jornada laboral según el Convenio Colectivo N.º 260/75 para el personal cubierto por dicho acuerdo?  

Otra alternativa posible:  
¿Qué estipula el Convenio Colectivo 260/75 sobre la jornada laboral máxima aplicable a los trabajadores incluidos en su ámbito?  

Ambas opciones:  
- Eliminan redundancias (establecida/comprendido).  
- Usan términos más técnicos (duración/estipula/aplicable).  
- Mantienen referencias clave (número de convenio y ámbito).  
- Priorizan un lenguaje conciso y directo.'
2025-05-07 11:47:13,687 - api.main - INFO - Estrategia de consulta: Solo reescrita. Usando: '¿Cuál es la duración máxima de la jornada laboral según el Convenio Colectivo N.º 260/75 para el personal cubierto por dicho acuerdo?  

Otra alternativa posible:  
¿Qué estipula el Convenio Colectivo 260/75 sobre la jornada laboral máxima aplicable a los trabajadores incluidos en su ámbito?  

Ambas opciones:  
- Eliminan redundancias (establecida/comprendido).  
- Usan términos más técnicos (duración/estipula/aplicable).  
- Mantienen referencias clave (número de convenio y ámbito).  
- Priorizan un lenguaje conciso y directo.' (fallback a original si reescritura falló o no cambió)
2025-05-07 11:47:13,688 - api.main - INFO - Inicializando retriever
2025-05-07 11:47:13,688 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-07 11:47:13,688 - api.main - INFO - Inicializando conexión a PGVector
2025-05-07 11:47:13,689 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 11:47:13,886 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 11:47:33,254 - api.main - INFO - Recuperados 4 documentos del retriever (post-compresión/reranking).
2025-05-07 11:47:33,262 - api.main - INFO - Documentos originales: 4, Documentos fusionados: 3
2025-05-07 11:47:33,831 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 11:47:47,513 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 45.6568s
2025-05-07 11:47:47,525 - api.main - INFO - QueryMetrics: {"timestamp": "2025-05-07T11:47:47.524887", "query_length": 134, "num_sources": 3, "execution_time": 45.636343479156494, "language": "es", "quality_assessment": "not_evaluated"}
2025-05-07 11:52:23,861 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 11:52:40,435 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 11:53:00,441 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746629580-c6247a", "timestamp": "2025-05-07T11:53:00.441892", "query_length": 134, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-07 11:53:00,442 - api.main - INFO - Estrategia de consulta: Solo original. Usando: '¿Cuál es la jornada máxima legal establecida en el Convenio Colectivo de Trabajo N.º 260/75 para el personal comprendido en su ámbito?'
2025-05-07 11:53:00,442 - api.main - INFO - Inicializando retriever
2025-05-07 11:53:00,443 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-07 11:53:00,443 - api.main - INFO - Inicializando conexión a PGVector
2025-05-07 11:53:00,443 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 11:53:00,624 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 11:53:16,411 - api.main - INFO - Recuperados 4 documentos del retriever (post-compresión/reranking).
2025-05-07 11:53:16,416 - api.main - INFO - Documentos originales: 4, Documentos fusionados: 4
2025-05-07 11:53:18,286 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 11:53:36,009 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 35.5731s
2025-05-07 11:53:36,016 - api.main - INFO - QueryMetrics: {"timestamp": "2025-05-07T11:53:36.015828", "query_length": 134, "num_sources": 4, "execution_time": 35.550806522369385, "language": "es", "quality_assessment": "not_evaluated"}
2025-05-07 11:55:46,085 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 11:56:04,444 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 11:56:05,858 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 11:56:19,782 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 11:56:30,715 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 11:56:56,491 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 14:11:41,454 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 14:12:08,887 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 14:12:38,080 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 14:12:48,118 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 14:13:02,959 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 14:13:15,534 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 14:14:00,685 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 14:14:12,463 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 14:14:26,315 - api.main - INFO - Request: GET /docs | Status: 200 | Duration: 0.0007s
2025-05-07 14:14:26,875 - api.main - INFO - Request: GET /openapi.json | Status: 200 | Duration: 0.0133s
2025-05-07 14:18:26,971 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746638306-c6247a", "timestamp": "2025-05-07T14:18:26.971115", "query_length": 134, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-07 14:18:26,973 - api.main - INFO - Estrategia de consulta: Solo original. Usando: '¿Cuál es la jornada máxima legal establecida en el Convenio Colectivo de Trabajo N.º 260/75 para el personal comprendido en su ámbito?'
2025-05-07 14:18:26,974 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 14:18:26,977 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-07 14:18:26,977 - api.main - INFO - Inicializando conexión a PGVector
2025-05-07 14:18:26,978 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 14:18:28,965 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 14:18:43,377 - api.main - ERROR - Error al conectar con PGVector: Failed to create vector extension: (psycopg2.OperationalError) connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)
2025-05-07 14:18:45,382 - api.main - WARNING - Reintentando conexión a PGVector (intento 2/3)...
2025-05-07 14:18:45,382 - api.main - INFO - Inicializando conexión a PGVector
2025-05-07 14:18:49,452 - api.main - ERROR - Error al conectar con PGVector: Failed to create vector extension: (psycopg2.OperationalError) connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)
2025-05-07 14:18:51,453 - api.main - WARNING - Reintentando conexión a PGVector (intento 3/3)...
2025-05-07 14:18:51,454 - api.main - INFO - Inicializando conexión a PGVector
2025-05-07 14:18:55,541 - api.main - ERROR - Error al conectar con PGVector: Failed to create vector extension: (psycopg2.OperationalError) connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)
2025-05-07 14:18:55,542 - api.main - ERROR - Error al inicializar retriever: No se pudo inicializar la base de datos vectorial: Failed to create vector extension: (psycopg2.OperationalError) connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)
Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
                             ~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 3298, in raw_connection
    return self.pool.connect()
           ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 1264, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 713, in checkout
    rec = pool._do_get()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\impl.py", line 179, in _do_get
    with util.safe_reraise():
         ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\util\langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\impl.py", line 177, in _do_get
    return self._create_connection()
           ~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 675, in __init__
    self.__connect()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 901, in __connect
    with util.safe_reraise():
         ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\util\langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 897, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\create.py", line 646, in connect
    return dialect.connect(*cargs, **cparams)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\default.py", line 625, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)  # type: ignore[no-any-return]  # NOQA: E501
           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\psycopg2\__init__.py", line 135, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\vectorstores\pgvector.py", line 390, in create_vector_extension
    session.execute(statement)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\session.py", line 2365, in execute
    return self._execute_internal(
           ~~~~~~~~~~~~~~~~~~~~~~^
        statement,
        ^^^^^^^^^^
    ...<4 lines>...
        _add_event=_add_event,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\session.py", line 2241, in _execute_internal
    conn = self._connection_for_bind(bind)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\session.py", line 2110, in _connection_for_bind
    return trans._connection_for_bind(engine, execution_options)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 2, in _connection_for_bind
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\session.py", line 1189, in _connection_for_bind
    conn = bind.connect()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 3274, in connect
    return self._connection_cls(self)
           ~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 148, in __init__
    Connection._handle_dbapi_exception_noconnection(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        err, dialect, engine
        ^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 2439, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
                             ~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 3298, in raw_connection
    return self.pool.connect()
           ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 1264, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 713, in checkout
    rec = pool._do_get()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\impl.py", line 179, in _do_get
    with util.safe_reraise():
         ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\util\langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\impl.py", line 177, in _do_get
    return self._create_connection()
           ~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 675, in __init__
    self.__connect()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 901, in __connect
    with util.safe_reraise():
         ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\util\langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 897, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\create.py", line 646, in connect
    return dialect.connect(*cargs, **cparams)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\default.py", line 625, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)  # type: ignore[no-any-return]  # NOQA: E501
           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\psycopg2\__init__.py", line 135, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 287, in get_vectorstore
    return PGVector(
        embedding_function=get_embeddings(),
        collection_name=settings.collection_name,
        connection_string=settings.pg_conn,
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\_api\deprecation.py", line 224, in warn_if_direct_instance
    return wrapped(self, *args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\vectorstores\pgvector.py", line 348, in __init__
    self.__post_init__()
    ~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\vectorstores\pgvector.py", line 355, in __post_init__
    self.create_vector_extension()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\vectorstores\pgvector.py", line 393, in create_vector_extension
    raise Exception(f"Failed to create vector extension: {e}") from e
Exception: Failed to create vector extension: (psycopg2.OperationalError) connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 301, in get_retriever
    vectorstore = get_vectorstore()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 294, in get_vectorstore
    raise RuntimeError(f"No se pudo inicializar la base de datos vectorial: {e}")
RuntimeError: No se pudo inicializar la base de datos vectorial: Failed to create vector extension: (psycopg2.OperationalError) connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)
2025-05-07 14:18:55,826 - api.main - ERROR - Error durante el pipeline de QA para la consulta '¿Cuál es la jornada máxima legal establecida en el Convenio Colectivo de Trabajo N.º 260/75 para el personal comprendido en su ámbito?': No se pudo inicializar el retriever: No se pudo inicializar la base de datos vectorial: Failed to create vector extension: (psycopg2.OperationalError) connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)
Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
                             ~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 3298, in raw_connection
    return self.pool.connect()
           ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 1264, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 713, in checkout
    rec = pool._do_get()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\impl.py", line 179, in _do_get
    with util.safe_reraise():
         ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\util\langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\impl.py", line 177, in _do_get
    return self._create_connection()
           ~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 675, in __init__
    self.__connect()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 901, in __connect
    with util.safe_reraise():
         ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\util\langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 897, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\create.py", line 646, in connect
    return dialect.connect(*cargs, **cparams)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\default.py", line 625, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)  # type: ignore[no-any-return]  # NOQA: E501
           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\psycopg2\__init__.py", line 135, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\vectorstores\pgvector.py", line 390, in create_vector_extension
    session.execute(statement)
    ~~~~~~~~~~~~~~~^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\session.py", line 2365, in execute
    return self._execute_internal(
           ~~~~~~~~~~~~~~~~~~~~~~^
        statement,
        ^^^^^^^^^^
    ...<4 lines>...
        _add_event=_add_event,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\session.py", line 2241, in _execute_internal
    conn = self._connection_for_bind(bind)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\session.py", line 2110, in _connection_for_bind
    return trans._connection_for_bind(engine, execution_options)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 2, in _connection_for_bind
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\state_changes.py", line 139, in _go
    ret_value = fn(self, *arg, **kw)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\orm\session.py", line 1189, in _connection_for_bind
    conn = bind.connect()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 3274, in connect
    return self._connection_cls(self)
           ~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 148, in __init__
    Connection._handle_dbapi_exception_noconnection(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        err, dialect, engine
        ^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 2439, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
                             ~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 3298, in raw_connection
    return self.pool.connect()
           ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 1264, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 713, in checkout
    rec = pool._do_get()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\impl.py", line 179, in _do_get
    with util.safe_reraise():
         ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\util\langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\impl.py", line 177, in _do_get
    return self._create_connection()
           ~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 675, in __init__
    self.__connect()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 901, in __connect
    with util.safe_reraise():
         ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\util\langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 897, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\create.py", line 646, in connect
    return dialect.connect(*cargs, **cparams)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sqlalchemy\engine\default.py", line 625, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)  # type: ignore[no-any-return]  # NOQA: E501
           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\psycopg2\__init__.py", line 135, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 287, in get_vectorstore
    return PGVector(
        embedding_function=get_embeddings(),
        collection_name=settings.collection_name,
        connection_string=settings.pg_conn,
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_core\_api\deprecation.py", line 224, in warn_if_direct_instance
    return wrapped(self, *args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\vectorstores\pgvector.py", line 348, in __init__
    self.__post_init__()
    ~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\vectorstores\pgvector.py", line 355, in __post_init__
    self.create_vector_extension()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\vectorstores\pgvector.py", line 393, in create_vector_extension
    raise Exception(f"Failed to create vector extension: {e}") from e
Exception: Failed to create vector extension: (psycopg2.OperationalError) connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 301, in get_retriever
    vectorstore = get_vectorstore()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\tenacity\__init__.py", line 338, in wrapped_f
    return copy(f, *args, **kw)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 294, in get_vectorstore
    raise RuntimeError(f"No se pudo inicializar la base de datos vectorial: {e}")
RuntimeError: No se pudo inicializar la base de datos vectorial: Failed to create vector extension: (psycopg2.OperationalError) connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 951, in query_documents
    retriever_instance = get_retriever() # Ya configurado con initial_retrieval_k y final_docs_count
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 330, in get_retriever
    raise RuntimeError(f"No se pudo inicializar el retriever: {e}")
RuntimeError: No se pudo inicializar el retriever: No se pudo inicializar la base de datos vectorial: Failed to create vector extension: (psycopg2.OperationalError) connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)
2025-05-07 14:18:55,844 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 28.9012s
2025-05-07 14:19:48,026 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 14:24:12,368 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 14:24:13,691 - api.main - INFO - Request: GET /docs | Status: 200 | Duration: 0.0008s
2025-05-07 14:24:14,290 - api.main - INFO - Request: GET /openapi.json | Status: 200 | Duration: 0.0185s
2025-05-07 14:24:43,897 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746638683-c6247a", "timestamp": "2025-05-07T14:24:43.897117", "query_length": 134, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-07 14:24:43,897 - api.main - INFO - Estrategia de consulta: Solo original. Usando: '¿Cuál es la jornada máxima legal establecida en el Convenio Colectivo de Trabajo N.º 260/75 para el personal comprendido en su ámbito?'
2025-05-07 14:24:43,898 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 14:24:43,898 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-07 14:24:43,898 - api.main - INFO - Inicializando conexión a PGVector
2025-05-07 14:24:43,898 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 14:24:45,222 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 14:24:53,791 - api.main - ERROR - Error al inicializar retriever: CrossEncoder.__init__() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 312, in get_retriever
    cross_enc = HuggingFaceCrossEncoder(
        model_name=settings.reranker_model,
    ...<3 lines>...
        }
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\cross_encoders\huggingface.py", line 44, in __init__
    self.client = sentence_transformers.CrossEncoder(
                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self.model_name, **self.model_kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sentence_transformers\cross_encoder\util.py", line 39, in wrapper
    return func(self, *args, **kwargs)
TypeError: CrossEncoder.__init__() got an unexpected keyword argument 'batch_size'
2025-05-07 14:24:53,820 - api.main - ERROR - Error durante el pipeline de QA para la consulta '¿Cuál es la jornada máxima legal establecida en el Convenio Colectivo de Trabajo N.º 260/75 para el personal comprendido en su ámbito?': No se pudo inicializar el retriever: CrossEncoder.__init__() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 312, in get_retriever
    cross_enc = HuggingFaceCrossEncoder(
        model_name=settings.reranker_model,
    ...<3 lines>...
        }
    )
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\langchain_community\cross_encoders\huggingface.py", line 44, in __init__
    self.client = sentence_transformers.CrossEncoder(
                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self.model_name, **self.model_kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Lib\site-packages\sentence_transformers\cross_encoder\util.py", line 39, in wrapper
    return func(self, *args, **kwargs)
TypeError: CrossEncoder.__init__() got an unexpected keyword argument 'batch_size'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 951, in query_documents
    retriever_instance = get_retriever() # Ya configurado con initial_retrieval_k y final_docs_count
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\api\main.py", line 330, in get_retriever
    raise RuntimeError(f"No se pudo inicializar el retriever: {e}")
RuntimeError: No se pudo inicializar el retriever: CrossEncoder.__init__() got an unexpected keyword argument 'batch_size'
2025-05-07 14:24:53,824 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 9.9394s
2025-05-07 14:26:17,244 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 14:26:34,628 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 14:26:35,727 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746638795-c6247a", "timestamp": "2025-05-07T14:26:35.727400", "query_length": 134, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-07 14:26:35,728 - api.main - INFO - Estrategia de consulta: Solo original. Usando: '¿Cuál es la jornada máxima legal establecida en el Convenio Colectivo de Trabajo N.º 260/75 para el personal comprendido en su ámbito?'
2025-05-07 14:26:35,728 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 14:26:35,729 - api.main - WARNING - Reintentando conexión a PGVector (intento 1/3)...
2025-05-07 14:26:35,729 - api.main - INFO - Inicializando conexión a PGVector
2025-05-07 14:26:35,729 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 14:26:35,921 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 14:26:51,992 - api.main - INFO - Recuperados 4 documentos del retriever (post-compresión/reranking).
2025-05-07 14:26:52,012 - api.main - INFO - Documentos originales: 4, Documentos fusionados: 3
2025-05-07 14:26:54,505 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 14:27:06,162 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 30.4386s
2025-05-07 14:27:06,179 - api.main - INFO - QueryMetrics: {"timestamp": "2025-05-07T14:27:06.178710", "query_length": 134, "num_sources": 3, "execution_time": 30.408398151397705, "language": "es", "quality_assessment": "not_evaluated"}
2025-05-07 15:26:26,405 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 15:36:27,499 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 15:57:28,893 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 15:58:28,565 - api.main - CRITICAL - Error al cargar configuración: name 'load_settings' is not defined
2025-05-07 15:59:14,473 - api.main - CRITICAL - Error al cargar configuración: name 'load_settings' is not defined
2025-05-07 16:07:06,676 - api.main - CRITICAL - Error al cargar configuración: name 'load_settings' is not defined
2025-05-07 16:08:13,418 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 16:08:31,014 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 16:08:40,203 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 16:10:01,350 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 16:10:12,734 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 16:11:13,289 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 16:11:13,306 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 16:11:13,358 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 16:11:13,358 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 16:11:13,364 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 16:11:13,364 - api.main - INFO - Memoria disponible: 1.23 GB
2025-05-07 16:11:19,597 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 16:11:28,649 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 16:11:28,655 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 16:11:28,686 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 16:11:28,687 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 16:11:28,692 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 16:11:28,693 - api.main - INFO - Memoria disponible: 1.30 GB
2025-05-07 16:11:41,740 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 16:11:51,151 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 16:11:51,157 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 16:11:51,185 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 16:11:51,185 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 16:11:51,190 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 16:11:51,190 - api.main - INFO - Memoria disponible: 1.21 GB
2025-05-07 16:12:36,246 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 16:12:36,250 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 16:12:36,277 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 16:12:36,277 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 16:12:36,281 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 16:12:36,282 - api.main - INFO - Memoria disponible: 0.98 GB
2025-05-07 16:13:02,912 - api.main - INFO - Request: GET /docs | Status: 200 | Duration: 0.0006s | Client: 127.0.0.1
2025-05-07 16:13:03,604 - api.main - INFO - Request: GET /openapi.json | Status: 200 | Duration: 0.0108s | Client: 127.0.0.1
2025-05-07 16:13:28,281 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746645208-c6247a", "timestamp": "2025-05-07T16:13:28.281348", "query_length": 134, "detected_language": "string", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 16:13:28,282 - api.main - ERROR - Error en consulta: name 'query_cache' is not defined
2025-05-07 16:13:28,283 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 0.0072s | Client: 127.0.0.1
2025-05-07 16:13:43,646 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746645223-c6247a", "timestamp": "2025-05-07T16:13:43.646148", "query_length": 134, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 16:13:43,647 - api.main - ERROR - Error en consulta: name 'query_cache' is not defined
2025-05-07 16:13:43,647 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 0.0034s | Client: 127.0.0.1
2025-05-07 16:14:15,131 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 16:14:28,073 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 16:14:28,078 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 16:14:28,120 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 16:14:28,121 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 16:14:28,126 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 16:14:28,126 - api.main - INFO - Memoria disponible: 0.74 GB
2025-05-07 16:14:37,934 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 16:14:37,939 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 16:14:37,993 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 16:14:37,993 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 16:14:37,998 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 16:14:37,998 - api.main - INFO - Memoria disponible: 0.80 GB
2025-05-07 16:14:57,640 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 16:15:07,158 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 16:15:07,164 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 16:15:07,207 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 16:15:07,208 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 16:15:07,213 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 16:15:07,214 - api.main - INFO - Memoria disponible: 0.87 GB
2025-05-07 16:15:14,273 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746645314-c6247a", "timestamp": "2025-05-07T16:15:14.273061", "query_length": 134, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 16:15:14,273 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 16:15:14,274 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 16:15:14,431 - api.main - ERROR - Error al inicializar embeddings: SentenceTransformer.__init__() got an unexpected keyword argument 'torch_dtype'
2025-05-07 16:15:14,432 - api.main - ERROR - Error al inicializar vectorstore: No se pudo inicializar el modelo de embeddings: SentenceTransformer.__init__() got an unexpected keyword argument 'torch_dtype'
2025-05-07 16:15:16,433 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 16:15:16,434 - api.main - ERROR - Error al inicializar embeddings: SentenceTransformer.__init__() got an unexpected keyword argument 'torch_dtype'
2025-05-07 16:15:16,434 - api.main - ERROR - Error al inicializar vectorstore: No se pudo inicializar el modelo de embeddings: SentenceTransformer.__init__() got an unexpected keyword argument 'torch_dtype'
2025-05-07 16:15:18,435 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 16:15:18,436 - api.main - ERROR - Error al inicializar embeddings: SentenceTransformer.__init__() got an unexpected keyword argument 'torch_dtype'
2025-05-07 16:15:18,436 - api.main - ERROR - Error al inicializar vectorstore: No se pudo inicializar el modelo de embeddings: SentenceTransformer.__init__() got an unexpected keyword argument 'torch_dtype'
2025-05-07 16:15:18,437 - api.main - ERROR - Error al inicializar retriever: No se pudo inicializar el modelo de embeddings: SentenceTransformer.__init__() got an unexpected keyword argument 'torch_dtype'
2025-05-07 16:15:18,437 - api.main - ERROR - Error en consulta: No se pudo inicializar el retriever: No se pudo inicializar el modelo de embeddings: SentenceTransformer.__init__() got an unexpected keyword argument 'torch_dtype'
2025-05-07 16:15:18,449 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 4.1802s | Client: 127.0.0.1
2025-05-07 16:15:40,547 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 16:15:49,962 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 16:15:49,967 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 16:15:50,021 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 16:15:50,021 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 16:15:50,025 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 16:15:50,026 - api.main - INFO - Memoria disponible: 1.11 GB
2025-05-07 16:16:39,929 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746645399-c6247a", "timestamp": "2025-05-07T16:16:39.929654", "query_length": 134, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 16:16:39,930 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 16:16:39,931 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 16:16:40,032 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 16:16:54,407 - api.main - ERROR - Error en consulta: object ChatDeepSeek can't be used in 'await' expression
2025-05-07 16:16:54,409 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 14.4900s | Client: 127.0.0.1
2025-05-07 16:17:38,615 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 16:21:35,892 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 16:21:35,899 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 16:21:35,963 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 16:21:35,964 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 16:21:35,969 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 16:21:35,969 - api.main - INFO - Memoria disponible: 1.14 GB
2025-05-07 16:22:53,501 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 16:23:03,183 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 16:23:03,189 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 16:23:03,223 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 16:23:03,223 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 16:23:03,228 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 16:23:03,229 - api.main - INFO - Memoria disponible: 0.89 GB
2025-05-07 16:23:08,972 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746645788-c6247a", "timestamp": "2025-05-07T16:23:08.972731", "query_length": 134, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 16:23:08,973 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 16:23:08,974 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 16:23:09,137 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 16:23:22,161 - api.main - ERROR - Error en consulta: object ChatDeepSeek can't be used in 'await' expression
2025-05-07 16:23:22,170 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 13.2030s | Client: 127.0.0.1
2025-05-07 16:24:12,646 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 16:24:28,847 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 16:24:28,854 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 16:24:28,911 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 16:24:28,911 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 16:24:28,916 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 16:24:28,917 - api.main - INFO - Memoria disponible: 1.01 GB
2025-05-07 16:24:32,280 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746645872-c6247a", "timestamp": "2025-05-07T16:24:32.280445", "query_length": 134, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 16:24:32,281 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 16:24:32,282 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 16:24:32,446 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 16:24:44,578 - api.main - ERROR - Error en consulta: 'list' object has no attribute 'get'
2025-05-07 16:24:44,595 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 12.3168s | Client: 127.0.0.1
2025-05-07 16:25:08,883 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 16:25:22,343 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 16:25:22,352 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 16:25:22,391 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 16:25:22,392 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 16:25:22,396 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 16:25:22,396 - api.main - INFO - Memoria disponible: 1.25 GB
2025-05-07 16:25:54,572 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746645954-c6247a", "timestamp": "2025-05-07T16:25:54.571999", "query_length": 134, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 16:25:54,572 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 16:25:54,573 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 16:25:54,728 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 16:26:07,810 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 16:26:12,847 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 18.2776s | Client: 127.0.0.1
2025-05-07 16:26:12,848 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T16:26:12.848436", "query_length": 134, "num_sources": 4, "execution_time": 18.27468991279602, "language": "es"}
2025-05-07 16:31:56,158 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746646316-30ad74", "timestamp": "2025-05-07T16:31:56.158246", "query_length": 122, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 16:32:00,487 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 16:32:09,916 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 13.7900s | Client: 127.0.0.1
2025-05-07 16:32:09,918 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T16:32:09.918198", "query_length": 122, "num_sources": 3, "execution_time": 13.756879091262817, "language": "es"}
2025-05-07 16:32:29,521 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746646349-64656e", "timestamp": "2025-05-07T16:32:29.521539", "query_length": 82, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 16:32:32,729 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 16:32:44,342 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 14.8227s | Client: 127.0.0.1
2025-05-07 16:32:44,344 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T16:32:44.344407", "query_length": 82, "num_sources": 4, "execution_time": 14.82071304321289, "language": "es"}
2025-05-07 16:36:04,486 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746646564-e09da6", "timestamp": "2025-05-07T16:36:04.486781", "query_length": 73, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 16:36:07,690 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 16:36:15,714 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 11.2284s | Client: 127.0.0.1
2025-05-07 16:36:15,715 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T16:36:15.715907", "query_length": 73, "num_sources": 3, "execution_time": 11.22700309753418, "language": "es"}
2025-05-07 16:36:29,757 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746646589-a1918f", "timestamp": "2025-05-07T16:36:29.757187", "query_length": 111, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 16:36:33,199 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 16:36:40,278 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 10.5222s | Client: 127.0.0.1
2025-05-07 16:36:40,290 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T16:36:40.290561", "query_length": 111, "num_sources": 3, "execution_time": 10.520874261856079, "language": "es"}
2025-05-07 16:59:42,066 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746647982-060052", "timestamp": "2025-05-07T16:59:42.065288", "query_length": 84, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 16:59:47,571 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 16:59:54,558 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 12.5375s | Client: 127.0.0.1
2025-05-07 16:59:54,562 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T16:59:54.562505", "query_length": 84, "num_sources": 3, "execution_time": 12.493881225585938, "language": "es"}
2025-05-07 17:00:58,487 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746648058-3d9d00", "timestamp": "2025-05-07T17:00:58.487314", "query_length": 141, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 17:01:02,929 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 17:01:19,294 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 20.8093s | Client: 127.0.0.1
2025-05-07 17:01:19,297 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T17:01:19.297739", "query_length": 141, "num_sources": 4, "execution_time": 20.805683374404907, "language": "es"}
2025-05-07 17:01:46,966 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746648106-7e68b7", "timestamp": "2025-05-07T17:01:46.966586", "query_length": 81, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 17:01:51,913 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 17:02:07,837 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 20.8727s | Client: 127.0.0.1
2025-05-07 17:02:07,839 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T17:02:07.839748", "query_length": 81, "num_sources": 4, "execution_time": 20.870002031326294, "language": "es"}
2025-05-07 17:02:50,291 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746648170-1989be", "timestamp": "2025-05-07T17:02:50.291138", "query_length": 87, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 17:02:54,187 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 17:03:03,921 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 13.6324s | Client: 127.0.0.1
2025-05-07 17:03:03,923 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T17:03:03.923892", "query_length": 87, "num_sources": 4, "execution_time": 13.628594875335693, "language": "es"}
2025-05-07 17:05:59,847 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 17:07:29,266 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 17:07:29,272 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 17:07:29,369 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 17:07:29,369 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 17:07:29,374 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 17:07:29,375 - api.main - INFO - Memoria disponible: 1.04 GB
2025-05-07 17:07:32,529 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 17:07:42,075 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 17:07:42,080 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 17:07:42,137 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 17:07:42,138 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 17:07:42,143 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 17:07:42,144 - api.main - INFO - Memoria disponible: 1.04 GB
2025-05-07 17:08:20,957 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 17:08:30,147 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 17:08:30,154 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 17:08:30,198 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 17:08:30,198 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 17:08:30,203 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 17:08:30,203 - api.main - INFO - Memoria disponible: 1.08 GB
2025-05-07 17:09:44,940 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746648584-060052", "timestamp": "2025-05-07T17:09:44.940000", "query_length": 84, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 17:09:44,941 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 17:09:44,941 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 17:09:45,135 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 17:09:58,008 - api.main - INFO - Documento en en, consulta en es
2025-05-07 17:09:59,217 - huggingface_hub.file_download - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2025-05-07 17:10:36,560 - huggingface_hub.file_download - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2025-05-07 17:10:36,602 - api.main - ERROR - Error al inicializar traductor: This tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed in order to use this tokenizer.
2025-05-07 17:10:36,603 - api.main - WARNING - Error en traducción: No se pudo inicializar el traductor: This tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed in order to use this tokenizer.
2025-05-07 17:10:36,610 - api.main - ERROR - Timeout en consulta: ¿Cuál es la diferencia principal entre compiladores y ensambladores, según el libro?
2025-05-07 17:10:36,643 - api.main - INFO - Request: POST /query | Status: 504 | Duration: 51.7059s | Client: 127.0.0.1
2025-05-07 17:13:48,566 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746648828-060052", "timestamp": "2025-05-07T17:13:48.566562", "query_length": 84, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 17:13:51,673 - api.main - INFO - Documento en en, consulta en es
2025-05-07 17:13:52,779 - api.main - ERROR - Error al inicializar traductor: This tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed in order to use this tokenizer.
2025-05-07 17:13:52,779 - api.main - WARNING - Error en traducción: No se pudo inicializar el traductor: This tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed in order to use this tokenizer.
2025-05-07 17:13:56,708 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 17:14:02,851 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 14.3084s | Client: 127.0.0.1
2025-05-07 17:14:02,853 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T17:14:02.853377", "query_length": 84, "num_sources": 3, "execution_time": 14.283995628356934, "language": "es"}
2025-05-07 17:14:50,762 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 17:15:07,505 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 17:15:07,512 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 17:15:07,560 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 17:15:07,560 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 17:15:07,565 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 17:15:07,565 - api.main - INFO - Memoria disponible: 1.10 GB
2025-05-07 17:15:20,733 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 17:15:29,974 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 17:15:29,979 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 17:15:30,031 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 17:15:30,032 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 17:15:30,038 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 17:15:30,038 - api.main - INFO - Memoria disponible: 1.15 GB
2025-05-07 17:15:33,633 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746648933-060052", "timestamp": "2025-05-07T17:15:33.633861", "query_length": 84, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 17:15:33,634 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 17:15:33,635 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 17:15:33,793 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 17:15:46,103 - api.main - INFO - Documento en en, consulta en es
2025-05-07 17:15:46,802 - huggingface_hub.file_download - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2025-05-07 17:16:12,122 - api.main - ERROR - Error al inicializar traductor: The model has been loaded with `accelerate` and therefore cannot be moved to a specific device. Please discard the `device` argument when creating your pipeline object.
2025-05-07 17:16:12,123 - api.main - ERROR - Error en la traducción: No se pudo inicializar el traductor: The model has been loaded with `accelerate` and therefore cannot be moved to a specific device. Please discard the `device` argument when creating your pipeline object.
2025-05-07 17:16:12,139 - api.main - ERROR - Timeout en consulta: ¿Cuál es la diferencia principal entre compiladores y ensambladores, según el libro?
2025-05-07 17:16:12,146 - api.main - INFO - Request: POST /query | Status: 504 | Duration: 38.5156s | Client: 127.0.0.1
2025-05-07 17:17:01,975 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 17:17:17,599 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 17:17:17,606 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 17:17:17,662 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 17:17:17,662 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 17:17:17,667 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 17:17:17,668 - api.main - INFO - Memoria disponible: 1.58 GB
2025-05-07 17:17:27,180 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 17:17:27,186 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 17:17:27,229 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 17:17:27,230 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 17:17:27,234 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 17:17:27,235 - api.main - INFO - Memoria disponible: 1.57 GB
2025-05-07 17:17:31,163 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746649051-060052", "timestamp": "2025-05-07T17:17:31.163539", "query_length": 84, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 17:17:31,164 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 17:17:31,165 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 17:17:31,314 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 17:17:41,738 - api.main - INFO - Documento en en, consulta en es
2025-05-07 17:17:42,993 - api.main - ERROR - Error al inicializar traductor: This tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed in order to use this tokenizer.
2025-05-07 17:17:42,994 - api.main - WARNING - Traductor no disponible, usando consulta original
2025-05-07 17:17:44,206 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 17:17:53,498 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 22.3396s | Client: 127.0.0.1
2025-05-07 17:17:53,500 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T17:17:53.500659", "query_length": 84, "num_sources": 3, "execution_time": 22.33388376235962, "language": "es"}
2025-05-07 17:18:38,280 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 17:18:52,054 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 17:18:52,060 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 17:18:52,103 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 17:18:52,103 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 17:18:52,108 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 17:18:52,108 - api.main - INFO - Memoria disponible: 1.65 GB
2025-05-07 17:19:01,338 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 17:19:01,343 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 17:19:01,382 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 17:19:01,383 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 17:19:01,387 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 17:19:01,388 - api.main - INFO - Memoria disponible: 1.70 GB
2025-05-07 17:19:05,633 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746649145-060052", "timestamp": "2025-05-07T17:19:05.633112", "query_length": 84, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 17:19:05,633 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 17:19:05,634 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 17:19:05,785 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 17:19:15,556 - api.main - INFO - Documento en en, consulta en es
2025-05-07 17:21:51,302 - api.main - ERROR - Error al inicializar traductor: This tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed in order to use this tokenizer.
2025-05-07 17:21:51,336 - api.main - WARNING - Traductor no disponible, usando consulta original
2025-05-07 17:21:52,117 - api.main - ERROR - Timeout en consulta: ¿Cuál es la diferencia principal entre compiladores y ensambladores, según el libro?
2025-05-07 17:21:52,141 - api.main - INFO - Request: POST /query | Status: 504 | Duration: 166.5109s | Client: 127.0.0.1
2025-05-07 17:21:53,104 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 17:24:53,033 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746649493-060052", "timestamp": "2025-05-07T17:24:53.033625", "query_length": 84, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 17:24:55,917 - api.main - INFO - Documento en en, consulta en es
2025-05-07 17:25:00,632 - api.main - ERROR - Error al inicializar traductor: This tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed in order to use this tokenizer.
2025-05-07 17:25:00,667 - api.main - WARNING - Traductor no disponible, usando consulta original
2025-05-07 17:25:02,133 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 17:25:09,520 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 16.5003s | Client: 127.0.0.1
2025-05-07 17:25:09,524 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T17:25:09.523464", "query_length": 84, "num_sources": 3, "execution_time": 16.480045557022095, "language": "es"}
2025-05-07 17:28:11,210 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 17:28:30,783 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 17:28:30,789 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 17:28:30,864 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 17:28:30,865 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 17:28:30,870 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 17:28:30,870 - api.main - INFO - Memoria disponible: 0.97 GB
2025-05-07 17:28:35,951 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746649715-060052", "timestamp": "2025-05-07T17:28:35.951294", "query_length": 84, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 17:28:35,952 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 17:28:35,952 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 17:28:36,113 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 17:28:48,639 - api.main - INFO - Documento en en, consulta en es
2025-05-07 17:28:49,905 - api.main - ERROR - Error al inicializar traductor: This tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed in order to use this tokenizer.
2025-05-07 17:28:49,906 - api.main - WARNING - Traductor no disponible, usando consulta original
2025-05-07 17:28:51,355 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 17:28:58,505 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 22.5577s | Client: 127.0.0.1
2025-05-07 17:28:58,508 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T17:28:58.508839", "query_length": 84, "num_sources": 3, "execution_time": 22.54267716407776, "language": "es"}
2025-05-07 17:29:07,208 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 17:29:21,843 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 17:29:21,849 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 17:29:21,897 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 17:29:21,897 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 17:29:21,901 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 17:29:21,902 - api.main - INFO - Memoria disponible: 1.47 GB
2025-05-07 17:43:57,709 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 17:43:57,719 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 17:43:57,837 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 17:43:57,837 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 17:43:57,842 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 17:43:57,842 - api.main - INFO - Memoria disponible: 0.30 GB
2025-05-07 17:44:28,852 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746650668-060052", "timestamp": "2025-05-07T17:44:28.852187", "query_length": 84, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 17:44:28,852 - api.main - ERROR - Error en consulta: module 'asyncio' has no attribute 'timeout'
2025-05-07 17:44:28,853 - api.main - INFO - Request: POST /query | Status: 500 | Duration: 0.0069s | Client: 127.0.0.1
2025-05-07 17:45:31,782 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 17:45:47,617 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 17:45:47,628 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 17:45:47,677 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 17:45:47,677 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 17:45:47,683 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 17:45:47,684 - api.main - INFO - Memoria disponible: 0.42 GB
2025-05-07 17:46:04,383 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 17:46:17,093 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 17:46:17,101 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 17:46:17,136 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 17:46:17,137 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 17:46:17,142 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 17:46:17,143 - api.main - INFO - Memoria disponible: 0.79 GB
2025-05-07 17:46:20,833 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746650780-060052", "timestamp": "2025-05-07T17:46:20.833388", "query_length": 84, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 17:46:20,834 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 17:46:20,835 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 17:46:21,042 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 17:46:39,358 - api.main - INFO - Documento en en, consulta en es
2025-05-07 17:46:41,036 - api.main - ERROR - Error al inicializar traductor: This tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed in order to use this tokenizer.
2025-05-07 17:46:41,038 - api.main - WARNING - Traductor no disponible, usando consulta original
2025-05-07 17:46:42,015 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 17:46:50,837 - api.main - ERROR - Timeout en consulta: ¿Cuál es la diferencia principal entre compiladores y ensambladores, según el libro?
2025-05-07 17:46:50,838 - api.main - INFO - Request: POST /query | Status: 504 | Duration: 30.0104s | Client: 127.0.0.1
2025-05-07 17:47:08,709 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 17:47:46,025 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 17:47:46,032 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 17:47:46,104 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 17:47:46,104 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 17:47:46,110 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 17:47:46,110 - api.main - INFO - Memoria disponible: 0.55 GB
2025-05-07 17:47:49,438 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746650869-060052", "timestamp": "2025-05-07T17:47:49.438243", "query_length": 84, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 17:47:49,439 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 17:47:49,440 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 17:47:49,651 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 17:48:06,453 - api.main - INFO - Documento en en, consulta en es
2025-05-07 17:48:13,620 - api.main - WARNING - Error en proceso de traducción: 'TranslationPipeline' object has no attribute 'initialized', continuando con consulta original
2025-05-07 17:48:14,467 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 17:48:19,463 - api.main - ERROR - Timeout en consulta: ¿Cuál es la diferencia principal entre compiladores y ensambladores, según el libro?
2025-05-07 17:48:19,470 - api.main - INFO - Request: POST /query | Status: 504 | Duration: 30.0366s | Client: 127.0.0.1
2025-05-07 17:49:12,696 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 17:49:32,649 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 17:49:32,658 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 17:49:32,724 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 17:49:32,725 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 17:49:32,731 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 17:49:32,731 - api.main - INFO - Memoria disponible: 0.86 GB
2025-05-07 17:49:44,964 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 17:49:44,973 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 17:49:45,009 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 17:49:45,010 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 17:49:45,014 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 17:49:45,015 - api.main - INFO - Memoria disponible: 0.84 GB
2025-05-07 17:49:49,406 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746650989-060052", "timestamp": "2025-05-07T17:49:49.406269", "query_length": 84, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 17:49:49,407 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 17:49:49,407 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 17:49:49,638 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 17:50:04,072 - api.main - INFO - Documento en en, consulta en es
2025-05-07 17:50:05,701 - api.main - ERROR - Error en proceso de traducción: 'TranslationPipeline' object has no attribute 'initialized', continuando con consulta original
2025-05-07 17:50:06,642 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 17:50:13,835 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 24.4341s | Client: 127.0.0.1
2025-05-07 17:50:13,838 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T17:50:13.838778", "query_length": 84, "num_sources": 3, "execution_time": 24.42857003211975, "language": "es"}
2025-05-07 17:51:04,531 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 17:51:22,456 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 17:51:22,465 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 17:51:22,521 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 17:51:22,522 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 17:51:22,528 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 17:51:22,528 - api.main - INFO - Memoria disponible: 1.52 GB
2025-05-07 17:51:34,729 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 17:51:34,736 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 17:51:34,781 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 17:51:34,782 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 17:51:34,787 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 17:51:34,787 - api.main - INFO - Memoria disponible: 1.47 GB
2025-05-07 17:51:42,931 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746651102-060052", "timestamp": "2025-05-07T17:51:42.931456", "query_length": 84, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 17:51:42,931 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 17:51:42,932 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 17:51:43,152 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 17:51:57,327 - api.main - INFO - Documento en en, consulta en es
2025-05-07 17:51:59,210 - api.main - ERROR - Error en proceso de traducción: 'TranslationPipeline' object has no attribute 'initialized', continuando con consulta original
2025-05-07 17:52:00,106 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 17:52:06,485 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 23.5590s | Client: 127.0.0.1
2025-05-07 17:52:06,488 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T17:52:06.488577", "query_length": 84, "num_sources": 3, "execution_time": 23.555010557174683, "language": "es"}
2025-05-07 17:52:36,602 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 17:54:09,565 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 17:54:09,574 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 17:54:09,618 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 17:54:09,619 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 17:54:09,624 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 17:54:09,624 - api.main - INFO - Memoria disponible: 1.45 GB
2025-05-07 17:54:14,296 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746651254-060052", "timestamp": "2025-05-07T17:54:14.296260", "query_length": 84, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 17:54:14,297 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 17:54:14,297 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 17:54:14,513 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 17:54:27,561 - api.main - INFO - Documento en en, consulta en es
2025-05-07 17:54:27,562 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-07 17:54:30,629 - api.translation - INFO - Successfully translated text from es to en
2025-05-07 17:54:30,644 - api.main - INFO - Query translated from es to en
2025-05-07 17:54:34,636 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 17:54:43,639 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 29.3464s | Client: 127.0.0.1
2025-05-07 17:54:43,642 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T17:54:43.642204", "query_length": 84, "num_sources": 3, "execution_time": 29.34300446510315, "language": "es"}
2025-05-07 17:56:37,026 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 17:56:55,372 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 17:56:55,381 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 17:56:55,457 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 17:56:55,457 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 17:56:55,464 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 17:56:55,464 - api.main - INFO - Memoria disponible: 1.22 GB
2025-05-07 17:57:01,025 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746651421-060052", "timestamp": "2025-05-07T17:57:01.025679", "query_length": 84, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 17:57:01,026 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 17:57:01,027 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 17:57:01,243 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 17:57:14,447 - api.main - INFO - Document in en, query in es
2025-05-07 17:57:17,130 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-07 17:57:19,904 - api.translation - INFO - Successfully translated text from es to en
2025-05-07 17:57:19,916 - api.main - INFO - Query translated from es to en
2025-05-07 17:57:22,361 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-07 17:57:22,361 - api.main - INFO - After merging: 6 unique documents
2025-05-07 17:57:23,514 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 17:57:31,048 - api.main - ERROR - Timeout en consulta: ¿Cuál es la diferencia principal entre compiladores y ensambladores, según el libro?
2025-05-07 17:57:31,051 - api.main - INFO - Request: POST /query | Status: 504 | Duration: 30.0287s | Client: 127.0.0.1
2025-05-07 17:58:22,314 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746651502-060052", "timestamp": "2025-05-07T17:58:22.314926", "query_length": 84, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 17:58:25,078 - api.main - INFO - Document in en, query in es
2025-05-07 17:58:28,321 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-07 17:58:30,754 - api.translation - INFO - Successfully translated text from es to en
2025-05-07 17:58:30,765 - api.main - INFO - Query translated from es to en
2025-05-07 17:58:33,518 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-07 17:58:33,519 - api.main - INFO - After merging: 6 unique documents
2025-05-07 17:58:34,263 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 17:58:48,409 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 26.1038s | Client: 127.0.0.1
2025-05-07 17:58:48,411 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T17:58:48.411310", "query_length": 84, "num_sources": 5, "execution_time": 26.0903799533844, "language": "es"}
2025-05-07 17:59:11,277 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746651551-3d9d00", "timestamp": "2025-05-07T17:59:11.277079", "query_length": 141, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 17:59:15,370 - api.main - INFO - Document in en, query in es
2025-05-07 17:59:18,558 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-07 17:59:21,915 - api.translation - INFO - Successfully translated text from es to en
2025-05-07 17:59:21,927 - api.main - INFO - Query translated from es to en
2025-05-07 17:59:25,071 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-07 17:59:25,071 - api.main - INFO - After merging: 6 unique documents
2025-05-07 17:59:25,981 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 17:59:41,286 - api.main - ERROR - Timeout en consulta: ¿Cómo clasifica el libro a los lenguajes de programación y qué características definen a los lenguajes declarativos frente a los imperativos?
2025-05-07 17:59:41,289 - api.main - INFO - Request: POST /query | Status: 504 | Duration: 30.0141s | Client: 127.0.0.1
2025-05-07 17:59:55,095 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746651595-3d9d00", "timestamp": "2025-05-07T17:59:55.095523", "query_length": 141, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 17:59:58,498 - api.main - INFO - Document in en, query in es
2025-05-07 18:00:01,694 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-07 18:00:05,468 - api.translation - INFO - Successfully translated text from es to en
2025-05-07 18:00:05,480 - api.main - INFO - Query translated from es to en
2025-05-07 18:00:08,566 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-07 18:00:08,567 - api.main - INFO - After merging: 6 unique documents
2025-05-07 18:00:09,520 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 18:00:25,096 - api.main - ERROR - Timeout en consulta: ¿Cómo clasifica el libro a los lenguajes de programación y qué características definen a los lenguajes declarativos frente a los imperativos?
2025-05-07 18:00:25,099 - api.main - INFO - Request: POST /query | Status: 504 | Duration: 30.0056s | Client: 127.0.0.1
2025-05-07 18:01:10,289 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 18:01:29,621 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 18:01:29,629 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 18:01:29,721 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 18:01:29,722 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 18:01:29,727 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 18:01:29,727 - api.main - INFO - Memoria disponible: 1.39 GB
2025-05-07 18:01:41,865 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 18:01:41,872 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 18:01:41,905 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 18:01:41,906 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 18:01:41,911 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 18:01:41,911 - api.main - INFO - Memoria disponible: 1.42 GB
2025-05-07 18:01:45,819 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746651705-3d9d00", "timestamp": "2025-05-07T18:01:45.819815", "query_length": 141, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 18:01:45,819 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 18:01:45,820 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 18:01:46,051 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 18:02:00,918 - api.main - INFO - Document in en, query in es
2025-05-07 18:02:04,107 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-07 18:02:07,556 - api.translation - INFO - Successfully translated text from es to en
2025-05-07 18:02:07,568 - api.main - INFO - Query translated from es to en
2025-05-07 18:02:10,579 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-07 18:02:10,579 - api.main - INFO - After merging: 6 unique documents
2025-05-07 18:02:11,467 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 18:02:27,164 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 41.3490s | Client: 127.0.0.1
2025-05-07 18:02:27,167 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T18:02:27.167812", "query_length": 141, "num_sources": 6, "execution_time": 41.34398555755615, "language": "es"}
2025-05-07 18:02:48,897 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746651768-7e68b7", "timestamp": "2025-05-07T18:02:48.897879", "query_length": 81, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 18:02:51,908 - api.main - INFO - Document in en, query in es
2025-05-07 18:02:54,782 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-07 18:02:57,783 - api.translation - INFO - Successfully translated text from es to en
2025-05-07 18:02:57,794 - api.main - INFO - Query translated from es to en
2025-05-07 18:03:00,240 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-07 18:03:00,241 - api.main - INFO - After merging: 6 unique documents
2025-05-07 18:03:01,030 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 18:03:14,959 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 26.0644s | Client: 127.0.0.1
2025-05-07 18:03:14,962 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T18:03:14.962731", "query_length": 81, "num_sources": 5, "execution_time": 26.06184720993042, "language": "es"}
2025-05-07 18:03:35,566 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746651815-060052", "timestamp": "2025-05-07T18:03:35.566423", "query_length": 84, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 18:03:38,990 - api.main - INFO - Document in en, query in es
2025-05-07 18:03:41,857 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-07 18:03:44,671 - api.translation - INFO - Successfully translated text from es to en
2025-05-07 18:03:44,684 - api.main - INFO - Query translated from es to en
2025-05-07 18:03:47,310 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-07 18:03:47,311 - api.main - INFO - After merging: 6 unique documents
2025-05-07 18:03:48,034 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 18:04:02,024 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 26.4591s | Client: 127.0.0.1
2025-05-07 18:04:02,026 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T18:04:02.026185", "query_length": 84, "num_sources": 5, "execution_time": 26.456761837005615, "language": "es"}
2025-05-07 18:05:46,180 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 18:06:06,622 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 18:06:06,630 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 18:06:06,711 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 18:06:06,711 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 18:06:06,717 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 18:06:06,717 - api.main - INFO - Memoria disponible: 1.10 GB
2025-05-07 18:14:56,513 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746652496-5cc263", "timestamp": "2025-05-07T18:14:56.512825", "query_length": 62, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 18:14:56,518 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 18:14:56,533 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 18:14:57,031 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 18:15:14,150 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 18:15:25,169 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 28.7287s | Client: 127.0.0.1
2025-05-07 18:15:25,174 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T18:15:25.173630", "query_length": 62, "num_sources": 4, "execution_time": 28.657814741134644, "language": "es"}
2025-05-07 18:15:41,279 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746652541-1895e8", "timestamp": "2025-05-07T18:15:41.279641", "query_length": 81, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 18:15:47,124 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 18:15:59,432 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 18.1560s | Client: 127.0.0.1
2025-05-07 18:15:59,436 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T18:15:59.436798", "query_length": 81, "num_sources": 4, "execution_time": 18.150628089904785, "language": "es"}
2025-05-07 19:52:38,960 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746658358-a7f645", "timestamp": "2025-05-07T19:52:38.958882", "query_length": 59, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 19:52:43,055 - api.main - INFO - Document in en, query in es
2025-05-07 19:52:45,565 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-07 19:52:50,082 - api.translation - INFO - Successfully translated text from es to en
2025-05-07 19:52:50,098 - api.main - INFO - Query translated from es to en
2025-05-07 19:52:54,188 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-07 19:52:54,189 - api.main - INFO - After merging: 7 unique documents
2025-05-07 19:52:55,285 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 19:53:14,956 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 36.0271s | Client: 127.0.0.1
2025-05-07 19:53:14,962 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T19:53:14.962608", "query_length": 59, "num_sources": 6, "execution_time": 35.99343967437744, "language": "es"}
2025-05-07 19:53:33,031 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746658413-a82201", "timestamp": "2025-05-07T19:53:33.030495", "query_length": 93, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 19:53:35,898 - api.main - INFO - Document in en, query in es
2025-05-07 19:53:38,312 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-07 19:53:41,565 - api.translation - INFO - Successfully translated text from es to en
2025-05-07 19:53:41,580 - api.main - INFO - Query translated from es to en
2025-05-07 19:53:44,929 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-07 19:53:44,929 - api.main - INFO - After merging: 5 unique documents
2025-05-07 19:53:45,665 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 19:54:06,044 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 33.0190s | Client: 127.0.0.1
2025-05-07 19:54:06,058 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T19:54:06.057596", "query_length": 93, "num_sources": 5, "execution_time": 33.013831615448, "language": "es"}
2025-05-07 20:00:46,466 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746658846-d2da13", "timestamp": "2025-05-07T20:00:46.466823", "query_length": 87, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 20:00:51,424 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 20:01:03,508 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 17.0802s | Client: 127.0.0.1
2025-05-07 20:01:03,510 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T20:01:03.510989", "query_length": 87, "num_sources": 4, "execution_time": 17.04216694831848, "language": "es"}
2025-05-07 20:01:27,531 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746658887-ec64f1", "timestamp": "2025-05-07T20:01:27.531787", "query_length": 83, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 20:01:30,932 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 20:01:46,146 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 18.6161s | Client: 127.0.0.1
2025-05-07 20:01:46,148 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T20:01:46.148949", "query_length": 83, "num_sources": 4, "execution_time": 18.61363434791565, "language": "es"}
2025-05-07 20:14:11,636 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746659651-5885a3", "timestamp": "2025-05-07T20:14:11.635314", "query_length": 49, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 20:14:15,087 - api.main - INFO - Document in en, query in es
2025-05-07 20:14:17,132 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-07 20:14:20,194 - api.translation - INFO - Successfully translated text from es to en
2025-05-07 20:14:20,215 - api.main - INFO - Query translated from es to en
2025-05-07 20:14:22,531 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-07 20:14:22,532 - api.main - INFO - After merging: 7 unique documents
2025-05-07 20:14:23,271 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 20:14:33,040 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 21.4407s | Client: 127.0.0.1
2025-05-07 20:14:33,045 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T20:14:33.045042", "query_length": 49, "num_sources": 7, "execution_time": 21.4045193195343, "language": "es"}
2025-05-07 20:14:51,837 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746659691-381bdf", "timestamp": "2025-05-07T20:14:51.837929", "query_length": 80, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 20:14:54,540 - api.main - INFO - Document in en, query in es
2025-05-07 20:14:57,141 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-07 20:15:00,309 - api.translation - INFO - Successfully translated text from es to en
2025-05-07 20:15:00,325 - api.main - INFO - Query translated from es to en
2025-05-07 20:15:02,839 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-07 20:15:02,840 - api.main - INFO - After merging: 7 unique documents
2025-05-07 20:15:03,464 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 20:15:20,348 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 28.5131s | Client: 127.0.0.1
2025-05-07 20:15:20,351 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T20:15:20.351124", "query_length": 80, "num_sources": 7, "execution_time": 28.50807237625122, "language": "es"}
2025-05-07 20:23:12,968 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746660192-887b30", "timestamp": "2025-05-07T20:23:12.968352", "query_length": 114, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 20:23:17,942 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 20:23:32,242 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 19.3103s | Client: 127.0.0.1
2025-05-07 20:23:32,246 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T20:23:32.246893", "query_length": 114, "num_sources": 4, "execution_time": 19.273245811462402, "language": "es"}
2025-05-07 20:23:48,286 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746660228-9eb3fe", "timestamp": "2025-05-07T20:23:48.286584", "query_length": 106, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 20:23:51,949 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 20:24:06,889 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 18.6029s | Client: 127.0.0.1
2025-05-07 20:24:06,890 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T20:24:06.890921", "query_length": 106, "num_sources": 4, "execution_time": 18.60040044784546, "language": "es"}
2025-05-07 20:57:11,423 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 21:07:46,210 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 21:07:46,219 - fastapi - ERROR - Form data requires "python-multipart" to be installed. 
You can install "python-multipart" with: 

pip install python-multipart

2025-05-07 21:08:43,172 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 21:08:43,179 - fastapi - ERROR - Form data requires "python-multipart" to be installed. 
You can install "python-multipart" with: 

pip install python-multipart

2025-05-07 21:09:34,229 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 21:09:34,236 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 21:09:34,374 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 21:09:34,374 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 21:09:34,381 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 21:09:34,382 - api.main - INFO - Memoria disponible: 0.77 GB
2025-05-07 21:10:50,448 - api.main - INFO - Request: GET /docs | Status: 200 | Duration: 0.0010s | Client: 127.0.0.1
2025-05-07 21:10:50,956 - api.main - INFO - Request: GET /openapi.json | Status: 200 | Duration: 0.0099s | Client: 127.0.0.1
2025-05-07 21:11:50,828 - api.main - ERROR - Error en ingest.py: Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 20, in <module>
    from langchain_community.embeddings import HuggingFaceEmbeddings
ModuleNotFoundError: No module named 'langchain_community'

2025-05-07 21:11:50,829 - api.main - ERROR - Error ejecutando ingest.py: 500: Error al procesar el documento: Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 20, in <module>
    from langchain_community.embeddings import HuggingFaceEmbeddings
ModuleNotFoundError: No module named 'langchain_community'

2025-05-07 21:11:50,830 - api.main - INFO - Request: POST /upload | Status: 500 | Duration: 0.2190s | Client: 127.0.0.1
2025-05-07 21:12:09,468 - api.main - INFO - Request: GET /upload | Status: 405 | Duration: 0.0000s | Client: 127.0.0.1
2025-05-07 21:12:09,874 - api.main - INFO - Request: GET /favicon.ico | Status: 404 | Duration: 0.0000s | Client: 127.0.0.1
2025-05-07 21:12:20,054 - api.main - ERROR - Error en ingest.py: Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 20, in <module>
    from langchain_community.embeddings import HuggingFaceEmbeddings
ModuleNotFoundError: No module named 'langchain_community'

2025-05-07 21:12:20,055 - api.main - ERROR - Error ejecutando ingest.py: 500: Error al procesar el documento: Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 20, in <module>
    from langchain_community.embeddings import HuggingFaceEmbeddings
ModuleNotFoundError: No module named 'langchain_community'

2025-05-07 21:12:20,057 - api.main - INFO - Request: POST /upload | Status: 500 | Duration: 0.2437s | Client: 127.0.0.1
2025-05-07 21:12:58,827 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 21:13:13,777 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 21:13:13,784 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 21:13:13,830 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 21:13:13,830 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 21:13:13,837 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 21:13:13,837 - api.main - INFO - Memoria disponible: 0.36 GB
2025-05-07 21:13:25,116 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 21:13:25,123 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 21:13:25,188 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 21:13:25,190 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 21:13:25,194 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 21:13:25,195 - api.main - INFO - Memoria disponible: 0.36 GB
2025-05-07 21:13:30,301 - api.main - INFO - Request: GET /docs | Status: 200 | Duration: 0.0000s | Client: 127.0.0.1
2025-05-07 21:13:30,715 - api.main - INFO - Request: GET /openapi.json | Status: 200 | Duration: 0.0060s | Client: 127.0.0.1
2025-05-07 21:13:39,194 - api.main - ERROR - Error en ingest.py: Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 20, in <module>
    from langchain_community.embeddings import HuggingFaceEmbeddings
ModuleNotFoundError: No module named 'langchain_community'

2025-05-07 21:13:39,195 - api.main - ERROR - Error ejecutando ingest.py: 500: Error al procesar el documento: Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 20, in <module>
    from langchain_community.embeddings import HuggingFaceEmbeddings
ModuleNotFoundError: No module named 'langchain_community'

2025-05-07 21:13:39,196 - api.main - INFO - Request: POST /upload | Status: 500 | Duration: 0.1864s | Client: 127.0.0.1
2025-05-07 21:13:46,636 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 21:14:10,762 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 21:14:10,769 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 21:14:10,806 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 21:14:10,806 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 21:14:10,811 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 21:14:10,812 - api.main - INFO - Memoria disponible: 0.77 GB
2025-05-07 21:14:15,635 - api.main - INFO - Request: GET /docs | Status: 200 | Duration: 0.0000s | Client: 127.0.0.1
2025-05-07 21:14:15,889 - api.main - INFO - Request: GET /openapi.json | Status: 200 | Duration: 0.0074s | Client: 127.0.0.1
2025-05-07 21:14:34,100 - api.main - ERROR - Error en ingest.py: Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 20, in <module>
    from langchain_community.embeddings import HuggingFaceEmbeddings
ModuleNotFoundError: No module named 'langchain_community'

2025-05-07 21:14:34,101 - api.main - ERROR - Error ejecutando ingest.py: 500: Error al procesar el documento: Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 20, in <module>
    from langchain_community.embeddings import HuggingFaceEmbeddings
ModuleNotFoundError: No module named 'langchain_community'

2025-05-07 21:14:34,103 - api.main - INFO - Request: POST /upload | Status: 500 | Duration: 0.2812s | Client: 127.0.0.1
2025-05-07 21:15:51,809 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 21:16:24,586 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 21:16:24,593 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 21:16:24,626 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 21:16:24,626 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 21:16:24,632 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 21:16:24,632 - api.main - INFO - Memoria disponible: 0.60 GB
2025-05-07 21:16:29,657 - api.main - ERROR - Error en ingest.py: Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 20, in <module>
    from langchain_community.embeddings import HuggingFaceEmbeddings
ModuleNotFoundError: No module named 'langchain_community'

2025-05-07 21:16:29,659 - api.main - ERROR - Error ejecutando ingest.py: 500: Error al procesar el documento: Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 20, in <module>
    from langchain_community.embeddings import HuggingFaceEmbeddings
ModuleNotFoundError: No module named 'langchain_community'

2025-05-07 21:16:29,661 - api.main - INFO - Request: POST /upload | Status: 500 | Duration: 0.2257s | Client: 127.0.0.1
2025-05-07 21:16:59,906 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 21:17:53,961 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 21:17:53,967 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 21:17:53,994 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 21:17:53,994 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 21:17:54,000 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 21:17:54,000 - api.main - INFO - Memoria disponible: 0.57 GB
2025-05-07 21:18:06,229 - api.main - INFO - Request: GET /docs | Status: 200 | Duration: 0.0000s | Client: 127.0.0.1
2025-05-07 21:18:06,479 - api.main - INFO - Request: GET /openapi.json | Status: 200 | Duration: 0.0124s | Client: 127.0.0.1
2025-05-07 21:18:12,329 - api.main - ERROR - Error en ingest.py: Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 20, in <module>
    from langchain_community.embeddings import HuggingFaceEmbeddings
ModuleNotFoundError: No module named 'langchain_community'

2025-05-07 21:18:12,330 - api.main - ERROR - Error ejecutando ingest.py: 500: Error al procesar el documento: Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 20, in <module>
    from langchain_community.embeddings import HuggingFaceEmbeddings
ModuleNotFoundError: No module named 'langchain_community'

2025-05-07 21:18:12,332 - api.main - INFO - Request: POST /upload | Status: 500 | Duration: 0.2500s | Client: 127.0.0.1
2025-05-07 21:19:52,694 - api.main - INFO - Cerrando recursos y conexiones
2025-05-07 21:20:05,917 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-07 21:20:05,925 - api.main - INFO - Iniciando aplicación API RAG
2025-05-07 21:20:05,962 - api.main - INFO - Conexión a base de datos verificada
2025-05-07 21:20:05,963 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-07 21:20:05,969 - api.main - INFO - Memoria total: 5.85 GB
2025-05-07 21:20:05,970 - api.main - INFO - Memoria disponible: 0.61 GB
2025-05-07 21:20:11,131 - api.main - INFO - Request: GET /docs | Status: 200 | Duration: 0.0010s | Client: 127.0.0.1
2025-05-07 21:20:11,369 - api.main - INFO - Request: GET /openapi.json | Status: 200 | Duration: 0.0074s | Client: 127.0.0.1
2025-05-07 21:20:16,308 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-07 21:27:01,571 - api.main - INFO - Request: POST /upload | Status: 200 | Duration: 405.2792s | Client: 127.0.0.1
2025-05-07 21:34:13,322 - api.main - INFO - Request: OPTIONS /query | Status: 200 | Duration: 0.0076s | Client: 127.0.0.1
2025-05-07 21:34:13,487 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746664453-a7f645", "timestamp": "2025-05-07T21:34:13.484277", "query_length": 59, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 21:34:13,491 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-07 21:34:13,523 - api.main - INFO - Inicializando modelo de embeddings
2025-05-07 21:34:14,380 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-07 21:34:34,955 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 21:34:41,389 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 28.0529s | Client: 127.0.0.1
2025-05-07 21:34:41,394 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T21:34:41.393626", "query_length": 59, "num_sources": 4, "execution_time": 27.89514136314392, "language": "unknown"}
2025-05-07 21:35:50,157 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-07 21:37:01,545 - api.main - INFO - Request: POST /upload | Status: 200 | Duration: 71.4616s | Client: 127.0.0.1
2025-05-07 21:37:07,490 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746664627-a7f645", "timestamp": "2025-05-07T21:37:07.490649", "query_length": 59, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 21:37:07,493 - api.main - INFO - Respuesta obtenida de caché para query similar a: '¿Cómo evita Bitcoin que la misma moneda se gaste dos veces?'
2025-05-07 21:37:07,502 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0500s | Client: 127.0.0.1
2025-05-07 21:37:27,090 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-07 21:38:15,202 - api.main - INFO - Request: POST /upload | Status: 200 | Duration: 48.1176s | Client: 127.0.0.1
2025-05-07 21:38:19,928 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746664699-a82201", "timestamp": "2025-05-07T21:38:19.927144", "query_length": 93, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 21:38:24,266 - api.main - INFO - Document in en, query in es
2025-05-07 21:38:27,059 - api.main - WARNING - Error in translation process: name 'translate_text' is not defined, using original query results
2025-05-07 21:38:28,139 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 21:38:43,722 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 23.7991s | Client: 127.0.0.1
2025-05-07 21:38:43,725 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T21:38:43.725206", "query_length": 93, "num_sources": 4, "execution_time": 23.79305934906006, "language": "unknown"}
2025-05-07 21:45:34,625 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-07 21:46:26,832 - api.main - INFO - Request: POST /upload | Status: 200 | Duration: 52.2289s | Client: 127.0.0.1
2025-05-07 21:46:36,712 - api.main - INFO - Request: OPTIONS /query | Status: 200 | Duration: 0.0051s | Client: 127.0.0.1
2025-05-07 21:46:36,742 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746665196-ef6b47", "timestamp": "2025-05-07T21:46:36.742276", "query_length": 70, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 21:46:40,659 - api.main - INFO - Document in en, query in es
2025-05-07 21:46:43,190 - api.main - WARNING - Error in translation process: name 'translate_text' is not defined, using original query results
2025-05-07 21:46:44,083 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 21:46:56,333 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 19.6148s | Client: 127.0.0.1
2025-05-07 21:46:56,335 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T21:46:56.335546", "query_length": 70, "num_sources": 4, "execution_time": 19.592029094696045, "language": "unknown"}
2025-05-07 21:50:37,917 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-07 21:51:28,391 - api.main - INFO - Request: POST /upload | Status: 200 | Duration: 50.5047s | Client: 127.0.0.1
2025-05-07 21:51:32,646 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746665492-40aa6b", "timestamp": "2025-05-07T21:51:32.646802", "query_length": 97, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-07 21:51:37,068 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-07 21:51:47,420 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 14.8083s | Client: 127.0.0.1
2025-05-07 21:51:47,422 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-07T21:51:47.422318", "query_length": 97, "num_sources": 4, "execution_time": 14.7764892578125, "language": "unknown"}
2025-05-08 10:50:44,671 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-08 10:50:44,679 - api.main - INFO - Iniciando aplicación API RAG
2025-05-08 10:50:44,822 - api.main - INFO - Conexión a base de datos verificada
2025-05-08 10:50:44,823 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-08 10:50:44,828 - api.main - INFO - Memoria total: 5.85 GB
2025-05-08 10:50:44,828 - api.main - INFO - Memoria disponible: 0.32 GB
2025-05-08 10:51:48,966 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-08 10:52:49,827 - api.main - INFO - Request: POST /upload | Status: 200 | Duration: 60.8616s | Client: 127.0.0.1
2025-05-08 10:53:44,762 - api.main - INFO - Request: OPTIONS /query | Status: 200 | Duration: 0.0029s | Client: 127.0.0.1
2025-05-08 10:53:44,915 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746712424-53f0dd", "timestamp": "2025-05-08T10:53:44.914682", "query_length": 70, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 10:53:44,918 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-08 10:53:44,943 - api.main - INFO - Inicializando modelo de embeddings
2025-05-08 10:53:45,541 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-08 10:54:02,359 - api.main - INFO - Document in en, query in es
2025-05-08 10:54:04,787 - api.main - WARNING - Error in translation process: name 'translate_text' is not defined, using original query results
2025-05-08 10:54:06,068 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-08 10:54:24,231 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 39.4626s | Client: 127.0.0.1
2025-05-08 10:54:24,243 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-08T10:54:24.243365", "query_length": 70, "num_sources": 4, "execution_time": 39.30579948425293, "language": "unknown"}
2025-05-08 10:55:40,647 - api.main - INFO - Cerrando recursos y conexiones
2025-05-08 17:08:57,447 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-08 17:08:57,458 - api.main - INFO - Iniciando aplicación API RAG
2025-05-08 17:08:57,511 - api.main - INFO - Conexión a base de datos verificada
2025-05-08 17:08:57,512 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-08 17:08:57,518 - api.main - INFO - Memoria total: 5.85 GB
2025-05-08 17:08:57,518 - api.main - INFO - Memoria disponible: 0.46 GB
2025-05-08 17:09:52,160 - api.main - INFO - Request: GET /docs | Status: 200 | Duration: 0.0069s | Client: 127.0.0.1
2025-05-08 17:09:52,966 - api.main - INFO - Request: GET /openapi.json | Status: 200 | Duration: 0.0580s | Client: 127.0.0.1
2025-05-08 17:12:48,313 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746735168-b45cff", "timestamp": "2025-05-08T17:12:48.302360", "query_length": 6, "detected_language": "\u00bfQu\u00e9 papel cumple el timestamp server en el funcionamiento de Bitcoin?", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 17:12:48,330 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-08 17:12:48,373 - api.main - INFO - Inicializando modelo de embeddings
2025-05-08 17:12:49,305 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-08 17:13:08,370 - api.main - INFO - Document in en, query in ¿Qué papel cumple el timestamp server en el funcionamiento de Bitcoin?
2025-05-08 17:13:10,818 - api.main - INFO - After merging: 4 unique documents
2025-05-08 17:13:12,060 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-08 17:13:18,656 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 30.5588s | Client: 127.0.0.1
2025-05-08 17:13:18,662 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-08T17:13:18.661795", "query_length": 6, "num_sources": 4, "execution_time": 30.34760856628418, "language": "\u00bfQu\u00e9 papel cumple el timestamp server en el funcionamiento de Bitcoin?"}
2025-05-08 17:13:48,583 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746735228-ef6b47", "timestamp": "2025-05-08T17:13:48.583315", "query_length": 70, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 17:13:51,588 - api.main - INFO - Document in en, query in es
2025-05-08 17:13:54,588 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-08 17:14:03,001 - api.translation - INFO - Successfully translated text from es to en
2025-05-08 17:14:03,022 - api.main - INFO - Query translated from es to en
2025-05-08 17:14:10,662 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-08 17:14:10,665 - api.main - INFO - After merging: 2 unique documents
2025-05-08 17:14:11,419 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-08 17:14:24,492 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 35.9357s | Client: 127.0.0.1
2025-05-08 17:14:24,502 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-08T17:14:24.502753", "query_length": 70, "num_sources": 2, "execution_time": 35.887670040130615, "language": "es"}
2025-05-08 17:15:00,599 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746735300-40aa6b", "timestamp": "2025-05-08T17:15:00.599480", "query_length": 97, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 17:15:06,767 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-08 17:15:19,328 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 18.7719s | Client: 127.0.0.1
2025-05-08 17:15:19,333 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-08T17:15:19.333466", "query_length": 97, "num_sources": 4, "execution_time": 18.72512650489807, "language": "es"}
2025-05-08 17:15:39,380 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746735339-20a0f8", "timestamp": "2025-05-08T17:15:39.380510", "query_length": 71, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 17:15:43,682 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-08 17:15:51,570 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 12.1958s | Client: 127.0.0.1
2025-05-08 17:15:51,571 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-08T17:15:51.571852", "query_length": 71, "num_sources": 4, "execution_time": 12.189634799957275, "language": "es"}
2025-05-08 17:16:12,740 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746735372-6d1a5e", "timestamp": "2025-05-08T17:16:12.740010", "query_length": 70, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 17:16:15,905 - api.main - INFO - Document in en, query in es
2025-05-08 17:16:18,587 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-08 17:16:22,495 - api.translation - INFO - Successfully translated text from es to en
2025-05-08 17:16:22,519 - api.main - INFO - Query translated from es to en
2025-05-08 17:16:25,303 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-08 17:16:25,304 - api.main - INFO - After merging: 1 unique documents
2025-05-08 17:16:26,180 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-08 17:16:34,292 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 21.5534s | Client: 127.0.0.1
2025-05-08 17:16:34,296 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-08T17:16:34.296462", "query_length": 70, "num_sources": 1, "execution_time": 21.54980731010437, "language": "es"}
2025-05-08 17:16:59,574 - api.main - INFO - Cerrando recursos y conexiones
2025-05-08 17:18:23,383 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-08 17:18:23,395 - api.main - INFO - Iniciando aplicación API RAG
2025-05-08 17:18:23,430 - api.main - INFO - Conexión a base de datos verificada
2025-05-08 17:18:23,431 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-08 17:18:23,439 - api.main - INFO - Memoria total: 5.85 GB
2025-05-08 17:18:23,439 - api.main - INFO - Memoria disponible: 0.52 GB
2025-05-08 17:18:33,787 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746735513-20a0f8", "timestamp": "2025-05-08T17:18:33.786899", "query_length": 71, "detected_language": "es", "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 17:18:33,787 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-08 17:18:33,788 - api.main - INFO - Inicializando modelo de embeddings
2025-05-08 17:18:34,021 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-08 17:18:48,393 - api.main - INFO - Document in en, query in es
2025-05-08 17:18:51,064 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-08 17:18:55,712 - api.translation - INFO - Successfully translated text from es to en
2025-05-08 17:18:55,728 - api.main - INFO - Query translated from es to en
2025-05-08 17:18:58,251 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-08 17:18:58,252 - api.main - INFO - After merging: 5 unique documents
2025-05-08 17:18:58,978 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-08 17:19:17,434 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 43.6528s | Client: 127.0.0.1
2025-05-08 17:19:17,438 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-08T17:19:17.438658", "query_length": 71, "num_sources": 4, "execution_time": 43.646724462509155, "language": "es"}
2025-05-08 17:46:13,254 - api.main - INFO - Cerrando recursos y conexiones
2025-05-08 17:47:35,654 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-08 17:47:35,666 - api.main - INFO - Iniciando aplicación API RAG
2025-05-08 17:47:35,773 - api.main - INFO - Conexión a base de datos verificada
2025-05-08 17:47:35,773 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-08 17:47:35,779 - api.main - INFO - Memoria total: 5.85 GB
2025-05-08 17:47:35,779 - api.main - INFO - Memoria disponible: 0.32 GB
2025-05-08 17:57:39,979 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-08 17:58:31,794 - api.main - INFO - Request: POST /upload | Status: 200 | Duration: 51.8870s | Client: 127.0.0.1
2025-05-08 17:58:49,681 - api.main - INFO - Request: OPTIONS /query | Status: 200 | Duration: 0.0025s | Client: 127.0.0.1
2025-05-08 17:58:49,843 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746737929-20a0f8", "timestamp": "2025-05-08T17:58:49.842077", "query_length": 71, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 17:58:49,849 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-08 17:58:49,885 - api.main - INFO - Inicializando modelo de embeddings
2025-05-08 17:58:50,622 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-08 17:59:09,990 - api.main - INFO - Document in en, query in es
2025-05-08 17:59:14,670 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-08 17:59:21,537 - api.translation - INFO - Successfully translated text from es to en
2025-05-08 17:59:21,640 - api.main - INFO - Query translated from es to en
2025-05-08 17:59:25,060 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-08 17:59:25,061 - api.main - INFO - After merging: 4 unique documents
2025-05-08 17:59:26,092 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-08 17:59:41,049 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 51.3628s | Client: 127.0.0.1
2025-05-08 17:59:41,055 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-08T17:59:41.055465", "query_length": 71, "num_sources": 3, "execution_time": 51.20416593551636, "language": "unknown"}
2025-05-08 18:00:37,680 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746738037-40aa6b", "timestamp": "2025-05-08T18:00:37.680908", "query_length": 97, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 18:00:44,495 - api.main - INFO - Document in en, query in es
2025-05-08 18:00:47,071 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-08 18:00:51,273 - api.translation - INFO - Successfully translated text from es to en
2025-05-08 18:00:51,289 - api.main - INFO - Query translated from es to en
2025-05-08 18:00:53,862 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-08 18:00:53,863 - api.main - INFO - After merging: 3 unique documents
2025-05-08 18:00:54,646 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-08 18:01:07,865 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 30.2357s | Client: 127.0.0.1
2025-05-08 18:01:07,873 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-08T18:01:07.872094", "query_length": 97, "num_sources": 3, "execution_time": 30.179473161697388, "language": "unknown"}
2025-05-08 18:05:08,861 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-08 18:05:27,809 - api.main - ERROR - Error en ingest.py: 2025-05-08 18:05:14,822 - __main__ - INFO - Configuración de ingesta cargada: {'docs_dir': WindowsPath('C:/Users/Gonzalo/Desktop/RAG-as-a-Service/backend/api/../docs'), 'cache_dir': WindowsPath('.cache'), 'embed_model': 'intfloat/multilingual-e5-base', 'collection_name': 'manual_e5_multi', 'chunk_size': 384, 'chunk_overlap': 64, 'batch_size': 128, 'max_workers': 11, 'max_embed_workers': 4, 'allowed_languages': {'es', 'en'}, 'file_extensions': ['pdf'], 'deduplication': True, 'similarity_threshold': 0.95, 'incremental': False, 'semantic_chunking': True, 'dynamic_chunking': True, 'reset_vector_collection': False}
2025-05-08 18:05:14,823 - __main__ - INFO - Memoria inicial: 213.78 MB
2025-05-08 18:05:14,824 - __main__ - INFO - Cargando modelo de embeddings: intfloat/multilingual-e5-base...
C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py:1508: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.
  embeddings = HuggingFaceEmbeddings(
2025-05-08 18:05:23,016 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base

2025-05-08 18:05:27,824 - api.main - ERROR - Error ejecutando ingest.py: 500: Error al procesar el documento: 2025-05-08 18:05:14,822 - __main__ - INFO - Configuración de ingesta cargada: {'docs_dir': WindowsPath('C:/Users/Gonzalo/Desktop/RAG-as-a-Service/backend/api/../docs'), 'cache_dir': WindowsPath('.cache'), 'embed_model': 'intfloat/multilingual-e5-base', 'collection_name': 'manual_e5_multi', 'chunk_size': 384, 'chunk_overlap': 64, 'batch_size': 128, 'max_workers': 11, 'max_embed_workers': 4, 'allowed_languages': {'es', 'en'}, 'file_extensions': ['pdf'], 'deduplication': True, 'similarity_threshold': 0.95, 'incremental': False, 'semantic_chunking': True, 'dynamic_chunking': True, 'reset_vector_collection': False}
2025-05-08 18:05:14,823 - __main__ - INFO - Memoria inicial: 213.78 MB
2025-05-08 18:05:14,824 - __main__ - INFO - Cargando modelo de embeddings: intfloat/multilingual-e5-base...
C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py:1508: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.
  embeddings = HuggingFaceEmbeddings(
2025-05-08 18:05:23,016 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base

2025-05-08 18:05:27,844 - api.main - INFO - Request: POST /upload | Status: 500 | Duration: 19.0384s | Client: 127.0.0.1
2025-05-08 18:06:25,185 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-08 18:06:40,572 - api.main - ERROR - Error en ingest.py: 2025-05-08 18:06:29,613 - __main__ - INFO - Configuración de ingesta cargada: {'docs_dir': WindowsPath('C:/Users/Gonzalo/Desktop/RAG-as-a-Service/backend/api/../docs'), 'cache_dir': WindowsPath('.cache'), 'embed_model': 'intfloat/multilingual-e5-base', 'collection_name': 'manual_e5_multi', 'chunk_size': 384, 'chunk_overlap': 64, 'batch_size': 128, 'max_workers': 11, 'max_embed_workers': 4, 'allowed_languages': {'es', 'en'}, 'file_extensions': ['pdf'], 'deduplication': True, 'similarity_threshold': 0.95, 'incremental': False, 'semantic_chunking': True, 'dynamic_chunking': True, 'reset_vector_collection': False}
2025-05-08 18:06:29,614 - __main__ - INFO - Memoria inicial: 213.06 MB
2025-05-08 18:06:29,614 - __main__ - INFO - Cargando modelo de embeddings: intfloat/multilingual-e5-base...
C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py:1508: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.
  embeddings = HuggingFaceEmbeddings(
2025-05-08 18:06:36,380 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base

2025-05-08 18:06:40,576 - api.main - ERROR - Error ejecutando ingest.py: 500: Error al procesar el documento: 2025-05-08 18:06:29,613 - __main__ - INFO - Configuración de ingesta cargada: {'docs_dir': WindowsPath('C:/Users/Gonzalo/Desktop/RAG-as-a-Service/backend/api/../docs'), 'cache_dir': WindowsPath('.cache'), 'embed_model': 'intfloat/multilingual-e5-base', 'collection_name': 'manual_e5_multi', 'chunk_size': 384, 'chunk_overlap': 64, 'batch_size': 128, 'max_workers': 11, 'max_embed_workers': 4, 'allowed_languages': {'es', 'en'}, 'file_extensions': ['pdf'], 'deduplication': True, 'similarity_threshold': 0.95, 'incremental': False, 'semantic_chunking': True, 'dynamic_chunking': True, 'reset_vector_collection': False}
2025-05-08 18:06:29,614 - __main__ - INFO - Memoria inicial: 213.06 MB
2025-05-08 18:06:29,614 - __main__ - INFO - Cargando modelo de embeddings: intfloat/multilingual-e5-base...
C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py:1508: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.
  embeddings = HuggingFaceEmbeddings(
2025-05-08 18:06:36,380 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base

2025-05-08 18:06:40,580 - api.main - INFO - Request: POST /upload | Status: 500 | Duration: 15.4021s | Client: 127.0.0.1
2025-05-08 18:08:13,576 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-08 18:08:29,614 - api.main - ERROR - Error en ingest.py: 2025-05-08 18:08:18,323 - __main__ - INFO - Configuración de ingesta cargada: {'docs_dir': WindowsPath('C:/Users/Gonzalo/Desktop/RAG-as-a-Service/backend/api/../docs'), 'cache_dir': WindowsPath('.cache'), 'embed_model': 'intfloat/multilingual-e5-base', 'collection_name': 'manual_e5_multi', 'chunk_size': 384, 'chunk_overlap': 64, 'batch_size': 128, 'max_workers': 11, 'max_embed_workers': 4, 'allowed_languages': {'es', 'en'}, 'file_extensions': ['pdf'], 'deduplication': True, 'similarity_threshold': 0.95, 'incremental': False, 'semantic_chunking': True, 'dynamic_chunking': True, 'reset_vector_collection': False}
2025-05-08 18:08:18,323 - __main__ - INFO - Memoria inicial: 213.63 MB
2025-05-08 18:08:18,323 - __main__ - INFO - Cargando modelo de embeddings: intfloat/multilingual-e5-base...
C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py:1508: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.
  embeddings = HuggingFaceEmbeddings(
2025-05-08 18:08:25,205 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base

2025-05-08 18:08:29,619 - api.main - ERROR - Error ejecutando ingest.py: 500: Error al procesar el documento: 2025-05-08 18:08:18,323 - __main__ - INFO - Configuración de ingesta cargada: {'docs_dir': WindowsPath('C:/Users/Gonzalo/Desktop/RAG-as-a-Service/backend/api/../docs'), 'cache_dir': WindowsPath('.cache'), 'embed_model': 'intfloat/multilingual-e5-base', 'collection_name': 'manual_e5_multi', 'chunk_size': 384, 'chunk_overlap': 64, 'batch_size': 128, 'max_workers': 11, 'max_embed_workers': 4, 'allowed_languages': {'es', 'en'}, 'file_extensions': ['pdf'], 'deduplication': True, 'similarity_threshold': 0.95, 'incremental': False, 'semantic_chunking': True, 'dynamic_chunking': True, 'reset_vector_collection': False}
2025-05-08 18:08:18,323 - __main__ - INFO - Memoria inicial: 213.63 MB
2025-05-08 18:08:18,323 - __main__ - INFO - Cargando modelo de embeddings: intfloat/multilingual-e5-base...
C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py:1508: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.
  embeddings = HuggingFaceEmbeddings(
2025-05-08 18:08:25,205 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base

2025-05-08 18:08:29,622 - api.main - INFO - Request: POST /upload | Status: 500 | Duration: 16.1532s | Client: 127.0.0.1
2025-05-08 18:10:35,383 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-08 18:10:51,265 - api.main - ERROR - Error en ingest.py: 2025-05-08 18:10:39,993 - __main__ - INFO - Configuración de ingesta cargada: {'docs_dir': WindowsPath('C:/Users/Gonzalo/Desktop/RAG-as-a-Service/backend/api/../docs'), 'cache_dir': WindowsPath('.cache'), 'embed_model': 'intfloat/multilingual-e5-base', 'collection_name': 'manual_e5_multi', 'chunk_size': 384, 'chunk_overlap': 64, 'batch_size': 128, 'max_workers': 11, 'max_embed_workers': 4, 'allowed_languages': {'en', 'es'}, 'file_extensions': ['pdf'], 'deduplication': True, 'similarity_threshold': 0.95, 'incremental': False, 'semantic_chunking': True, 'dynamic_chunking': True, 'reset_vector_collection': False}
2025-05-08 18:10:39,994 - __main__ - INFO - Memoria inicial: 213.36 MB
2025-05-08 18:10:39,994 - __main__ - INFO - Cargando modelo de embeddings: intfloat/multilingual-e5-base...
C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py:1508: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.
  embeddings = HuggingFaceEmbeddings(
2025-05-08 18:10:46,933 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base

2025-05-08 18:10:51,270 - api.main - ERROR - Error ejecutando ingest.py: 500: Error al procesar el documento: 2025-05-08 18:10:39,993 - __main__ - INFO - Configuración de ingesta cargada: {'docs_dir': WindowsPath('C:/Users/Gonzalo/Desktop/RAG-as-a-Service/backend/api/../docs'), 'cache_dir': WindowsPath('.cache'), 'embed_model': 'intfloat/multilingual-e5-base', 'collection_name': 'manual_e5_multi', 'chunk_size': 384, 'chunk_overlap': 64, 'batch_size': 128, 'max_workers': 11, 'max_embed_workers': 4, 'allowed_languages': {'en', 'es'}, 'file_extensions': ['pdf'], 'deduplication': True, 'similarity_threshold': 0.95, 'incremental': False, 'semantic_chunking': True, 'dynamic_chunking': True, 'reset_vector_collection': False}
2025-05-08 18:10:39,994 - __main__ - INFO - Memoria inicial: 213.36 MB
2025-05-08 18:10:39,994 - __main__ - INFO - Cargando modelo de embeddings: intfloat/multilingual-e5-base...
C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py:1508: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.
  embeddings = HuggingFaceEmbeddings(
2025-05-08 18:10:46,933 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base

2025-05-08 18:10:51,278 - api.main - INFO - Request: POST /upload | Status: 500 | Duration: 15.9038s | Client: 127.0.0.1
2025-05-08 18:11:21,642 - api.main - INFO - Cerrando recursos y conexiones
2025-05-08 18:11:51,435 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-08 18:11:51,445 - api.main - INFO - Iniciando aplicación API RAG
2025-05-08 18:11:51,538 - api.main - INFO - Conexión a base de datos verificada
2025-05-08 18:11:51,538 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-08 18:11:51,543 - api.main - INFO - Memoria total: 5.85 GB
2025-05-08 18:11:51,544 - api.main - INFO - Memoria disponible: 0.49 GB
2025-05-08 18:12:39,461 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-08 18:13:48,328 - api.main - INFO - Request: POST /upload | Status: 200 | Duration: 68.9097s | Client: 127.0.0.1
2025-05-08 18:14:02,538 - api.main - INFO - Request: OPTIONS /query | Status: 200 | Duration: 0.0030s | Client: 127.0.0.1
2025-05-08 18:14:02,684 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746738842-40aa6b", "timestamp": "2025-05-08T18:14:02.683277", "query_length": 97, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 18:14:02,689 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-08 18:14:02,709 - api.main - INFO - Inicializando modelo de embeddings
2025-05-08 18:14:03,288 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-08 18:14:19,049 - api.main - INFO - Document in en, query in es
2025-05-08 18:14:22,532 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-08 18:14:28,412 - api.translation - INFO - Successfully translated text from es to en
2025-05-08 18:14:28,443 - api.main - INFO - Query translated from es to en
2025-05-08 18:14:32,123 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-08 18:14:32,124 - api.main - INFO - After merging: 3 unique documents
2025-05-08 18:14:32,908 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-08 18:14:48,416 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 45.8720s | Client: 127.0.0.1
2025-05-08 18:14:48,420 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-08T18:14:48.419395", "query_length": 97, "num_sources": 3, "execution_time": 45.734318256378174, "language": "unknown"}
2025-05-08 18:18:21,389 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-08 18:18:38,756 - api.main - ERROR - Error en ingest.py: 2025-05-08 18:18:26,749 - __main__ - INFO - Configuración de ingesta cargada: {'docs_dir': WindowsPath('C:/Users/Gonzalo/Desktop/RAG-as-a-Service/backend/api/../docs'), 'cache_dir': WindowsPath('.cache'), 'embed_model': 'intfloat/multilingual-e5-base', 'collection_name': 'manual_e5_multi', 'chunk_size': 384, 'chunk_overlap': 64, 'batch_size': 128, 'max_workers': 11, 'max_embed_workers': 4, 'allowed_languages': {'es', 'en'}, 'file_extensions': ['pdf'], 'deduplication': True, 'similarity_threshold': 0.95, 'incremental': False, 'semantic_chunking': True, 'dynamic_chunking': True, 'reset_vector_collection': False}
2025-05-08 18:18:26,750 - __main__ - INFO - Memoria inicial: 213.09 MB
2025-05-08 18:18:26,750 - __main__ - INFO - Cargando modelo de embeddings: intfloat/multilingual-e5-base...
C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py:1508: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.
  embeddings = HuggingFaceEmbeddings(
2025-05-08 18:18:33,779 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base

2025-05-08 18:18:38,762 - api.main - ERROR - Error ejecutando ingest.py: 500: Error al procesar el documento: 2025-05-08 18:18:26,749 - __main__ - INFO - Configuración de ingesta cargada: {'docs_dir': WindowsPath('C:/Users/Gonzalo/Desktop/RAG-as-a-Service/backend/api/../docs'), 'cache_dir': WindowsPath('.cache'), 'embed_model': 'intfloat/multilingual-e5-base', 'collection_name': 'manual_e5_multi', 'chunk_size': 384, 'chunk_overlap': 64, 'batch_size': 128, 'max_workers': 11, 'max_embed_workers': 4, 'allowed_languages': {'es', 'en'}, 'file_extensions': ['pdf'], 'deduplication': True, 'similarity_threshold': 0.95, 'incremental': False, 'semantic_chunking': True, 'dynamic_chunking': True, 'reset_vector_collection': False}
2025-05-08 18:18:26,750 - __main__ - INFO - Memoria inicial: 213.09 MB
2025-05-08 18:18:26,750 - __main__ - INFO - Cargando modelo de embeddings: intfloat/multilingual-e5-base...
C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py:1508: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.
  embeddings = HuggingFaceEmbeddings(
2025-05-08 18:18:33,779 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base

2025-05-08 18:18:38,784 - api.main - INFO - Request: POST /upload | Status: 500 | Duration: 17.5099s | Client: 127.0.0.1
2025-05-08 18:20:38,953 - api.main - INFO - Cerrando recursos y conexiones
2025-05-08 18:20:59,492 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-08 18:20:59,501 - api.main - INFO - Iniciando aplicación API RAG
2025-05-08 18:20:59,589 - api.main - INFO - Conexión a base de datos verificada
2025-05-08 18:20:59,589 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-08 18:20:59,595 - api.main - INFO - Memoria total: 5.85 GB
2025-05-08 18:20:59,595 - api.main - INFO - Memoria disponible: 0.76 GB
2025-05-08 18:21:10,098 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-08 18:21:54,474 - api.main - INFO - Request: POST /upload | Status: 200 | Duration: 44.3794s | Client: 127.0.0.1
2025-05-08 18:22:10,366 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746739330-9240cf", "timestamp": "2025-05-08T18:22:10.365202", "query_length": 196, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 18:22:10,369 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-08 18:22:10,379 - api.main - INFO - Inicializando modelo de embeddings
2025-05-08 18:22:10,776 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-08 18:22:27,588 - api.main - INFO - Document in en, query in es
2025-05-08 18:22:31,296 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-08 18:22:37,848 - api.translation - INFO - Successfully translated text from es to en
2025-05-08 18:22:37,863 - api.main - INFO - Query translated from es to en
2025-05-08 18:22:42,664 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-08 18:22:42,665 - api.main - INFO - After merging: 3 unique documents
2025-05-08 18:22:43,696 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-08 18:22:52,909 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 42.6197s | Client: 127.0.0.1
2025-05-08 18:22:52,912 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-08T18:22:52.912663", "query_length": 196, "num_sources": 3, "execution_time": 42.544461727142334, "language": "unknown"}
2025-05-08 18:23:23,169 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-08 18:23:40,310 - api.main - ERROR - Error en ingest.py: 2025-05-08 18:23:28,722 - __main__ - INFO - Configuración de ingesta cargada: {'docs_dir': WindowsPath('C:/Users/Gonzalo/Desktop/RAG-as-a-Service/backend/api/../docs'), 'cache_dir': WindowsPath('.cache'), 'embed_model': 'intfloat/multilingual-e5-base', 'collection_name': 'manual_e5_multi', 'chunk_size': 384, 'chunk_overlap': 64, 'batch_size': 128, 'max_workers': 11, 'max_embed_workers': 4, 'allowed_languages': {'en', 'es'}, 'file_extensions': ['pdf'], 'deduplication': True, 'similarity_threshold': 0.95, 'incremental': True, 'semantic_chunking': True, 'dynamic_chunking': True, 'reset_vector_collection': False}
2025-05-08 18:23:28,723 - __main__ - INFO - Memoria inicial: 213.47 MB
2025-05-08 18:23:28,723 - __main__ - INFO - Cargando modelo de embeddings: intfloat/multilingual-e5-base...
C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py:1508: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.
  embeddings = HuggingFaceEmbeddings(
2025-05-08 18:23:36,149 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-08 18:23:39,040 - __main__ - ERROR - Error durante el procesamiento: El archivo de paginación es demasiado pequeño para completar la operación. (os error 1455)
2025-05-08 18:23:39,348 - __main__ - ERROR - Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 1508, in main
    embeddings = HuggingFaceEmbeddings(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_core\_api\deprecation.py", line 224, in warn_if_direct_instance
    return wrapped(self, *args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_community\embeddings\huggingface.py", line 92, in __init__
    self.client = sentence_transformers.SentenceTransformer(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 309, in __init__
    modules, self.module_kwargs = self._load_sbert_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 1808, in _load_sbert_model
    module = module_class(model_name_or_path, cache_dir=cache_folder, backend=self.backend, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 81, in __init__
    self._load_model(model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 181, in _load_model
    self.auto_model = AutoModel.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\models\auto\auto_factory.py", line 571, in from_pretrained
    return model_class.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 279, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4399, in from_pretrained
    ) = cls._load_pretrained_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4638, in _load_pretrained_model
    load_state_dict(checkpoint_files[0], map_location="meta", weights_only=weights_only).keys()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 513, in load_state_dict
    with safe_open(checkpoint_file, framework="pt") as f:
OSError: El archivo de paginación es demasiado pequeño para completar la operación. (os error 1455)

2025-05-08 18:23:39,348 - __main__ - CRITICAL - Error crítico en el proceso de ingesta: El archivo de paginación es demasiado pequeño para completar la operación. (os error 1455)
2025-05-08 18:23:39,348 - __main__ - CRITICAL - Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 1508, in main
    embeddings = HuggingFaceEmbeddings(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_core\_api\deprecation.py", line 224, in warn_if_direct_instance
    return wrapped(self, *args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_community\embeddings\huggingface.py", line 92, in __init__
    self.client = sentence_transformers.SentenceTransformer(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 309, in __init__
    modules, self.module_kwargs = self._load_sbert_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 1808, in _load_sbert_model
    module = module_class(model_name_or_path, cache_dir=cache_folder, backend=self.backend, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 81, in __init__
    self._load_model(model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 181, in _load_model
    self.auto_model = AutoModel.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\models\auto\auto_factory.py", line 571, in from_pretrained
    return model_class.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 279, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4399, in from_pretrained
    ) = cls._load_pretrained_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4638, in _load_pretrained_model
    load_state_dict(checkpoint_files[0], map_location="meta", weights_only=weights_only).keys()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 513, in load_state_dict
    with safe_open(checkpoint_file, framework="pt") as f:
OSError: El archivo de paginación es demasiado pequeño para completar la operación. (os error 1455)

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 1684, in <module>
    main()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 1508, in main
    embeddings = HuggingFaceEmbeddings(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_core\_api\deprecation.py", line 224, in warn_if_direct_instance
    return wrapped(self, *args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_community\embeddings\huggingface.py", line 92, in __init__
    self.client = sentence_transformers.SentenceTransformer(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 309, in __init__
    modules, self.module_kwargs = self._load_sbert_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 1808, in _load_sbert_model
    module = module_class(model_name_or_path, cache_dir=cache_folder, backend=self.backend, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 81, in __init__
    self._load_model(model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 181, in _load_model
    self.auto_model = AutoModel.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\models\auto\auto_factory.py", line 571, in from_pretrained
    return model_class.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 279, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4399, in from_pretrained
    ) = cls._load_pretrained_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4638, in _load_pretrained_model
    load_state_dict(checkpoint_files[0], map_location="meta", weights_only=weights_only).keys()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 513, in load_state_dict
    with safe_open(checkpoint_file, framework="pt") as f:
OSError: El archivo de paginación es demasiado pequeño para completar la operación. (os error 1455)

2025-05-08 18:23:40,323 - api.main - ERROR - Error ejecutando ingest.py: 500: Error al procesar el documento: 2025-05-08 18:23:28,722 - __main__ - INFO - Configuración de ingesta cargada: {'docs_dir': WindowsPath('C:/Users/Gonzalo/Desktop/RAG-as-a-Service/backend/api/../docs'), 'cache_dir': WindowsPath('.cache'), 'embed_model': 'intfloat/multilingual-e5-base', 'collection_name': 'manual_e5_multi', 'chunk_size': 384, 'chunk_overlap': 64, 'batch_size': 128, 'max_workers': 11, 'max_embed_workers': 4, 'allowed_languages': {'en', 'es'}, 'file_extensions': ['pdf'], 'deduplication': True, 'similarity_threshold': 0.95, 'incremental': True, 'semantic_chunking': True, 'dynamic_chunking': True, 'reset_vector_collection': False}
2025-05-08 18:23:28,723 - __main__ - INFO - Memoria inicial: 213.47 MB
2025-05-08 18:23:28,723 - __main__ - INFO - Cargando modelo de embeddings: intfloat/multilingual-e5-base...
C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py:1508: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.
  embeddings = HuggingFaceEmbeddings(
2025-05-08 18:23:36,149 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-08 18:23:39,040 - __main__ - ERROR - Error durante el procesamiento: El archivo de paginación es demasiado pequeño para completar la operación. (os error 1455)
2025-05-08 18:23:39,348 - __main__ - ERROR - Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 1508, in main
    embeddings = HuggingFaceEmbeddings(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_core\_api\deprecation.py", line 224, in warn_if_direct_instance
    return wrapped(self, *args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_community\embeddings\huggingface.py", line 92, in __init__
    self.client = sentence_transformers.SentenceTransformer(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 309, in __init__
    modules, self.module_kwargs = self._load_sbert_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 1808, in _load_sbert_model
    module = module_class(model_name_or_path, cache_dir=cache_folder, backend=self.backend, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 81, in __init__
    self._load_model(model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 181, in _load_model
    self.auto_model = AutoModel.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\models\auto\auto_factory.py", line 571, in from_pretrained
    return model_class.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 279, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4399, in from_pretrained
    ) = cls._load_pretrained_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4638, in _load_pretrained_model
    load_state_dict(checkpoint_files[0], map_location="meta", weights_only=weights_only).keys()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 513, in load_state_dict
    with safe_open(checkpoint_file, framework="pt") as f:
OSError: El archivo de paginación es demasiado pequeño para completar la operación. (os error 1455)

2025-05-08 18:23:39,348 - __main__ - CRITICAL - Error crítico en el proceso de ingesta: El archivo de paginación es demasiado pequeño para completar la operación. (os error 1455)
2025-05-08 18:23:39,348 - __main__ - CRITICAL - Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 1508, in main
    embeddings = HuggingFaceEmbeddings(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_core\_api\deprecation.py", line 224, in warn_if_direct_instance
    return wrapped(self, *args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_community\embeddings\huggingface.py", line 92, in __init__
    self.client = sentence_transformers.SentenceTransformer(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 309, in __init__
    modules, self.module_kwargs = self._load_sbert_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 1808, in _load_sbert_model
    module = module_class(model_name_or_path, cache_dir=cache_folder, backend=self.backend, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 81, in __init__
    self._load_model(model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 181, in _load_model
    self.auto_model = AutoModel.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\models\auto\auto_factory.py", line 571, in from_pretrained
    return model_class.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 279, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4399, in from_pretrained
    ) = cls._load_pretrained_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4638, in _load_pretrained_model
    load_state_dict(checkpoint_files[0], map_location="meta", weights_only=weights_only).keys()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 513, in load_state_dict
    with safe_open(checkpoint_file, framework="pt") as f:
OSError: El archivo de paginación es demasiado pequeño para completar la operación. (os error 1455)

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 1684, in <module>
    main()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 1508, in main
    embeddings = HuggingFaceEmbeddings(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_core\_api\deprecation.py", line 224, in warn_if_direct_instance
    return wrapped(self, *args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_community\embeddings\huggingface.py", line 92, in __init__
    self.client = sentence_transformers.SentenceTransformer(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 309, in __init__
    modules, self.module_kwargs = self._load_sbert_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 1808, in _load_sbert_model
    module = module_class(model_name_or_path, cache_dir=cache_folder, backend=self.backend, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 81, in __init__
    self._load_model(model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 181, in _load_model
    self.auto_model = AutoModel.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\models\auto\auto_factory.py", line 571, in from_pretrained
    return model_class.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 279, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4399, in from_pretrained
    ) = cls._load_pretrained_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4638, in _load_pretrained_model
    load_state_dict(checkpoint_files[0], map_location="meta", weights_only=weights_only).keys()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 513, in load_state_dict
    with safe_open(checkpoint_file, framework="pt") as f:
OSError: El archivo de paginación es demasiado pequeño para completar la operación. (os error 1455)

2025-05-08 18:23:40,333 - api.main - INFO - Request: POST /upload | Status: 500 | Duration: 17.1777s | Client: 127.0.0.1
2025-05-08 18:24:42,372 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-08 18:24:57,488 - api.main - ERROR - Error en ingest.py: 2025-05-08 18:24:47,392 - __main__ - INFO - Configuración de ingesta cargada: {'docs_dir': WindowsPath('C:/Users/Gonzalo/Desktop/RAG-as-a-Service/backend/api/../docs'), 'cache_dir': WindowsPath('.cache'), 'embed_model': 'intfloat/multilingual-e5-base', 'collection_name': 'manual_e5_multi', 'chunk_size': 384, 'chunk_overlap': 64, 'batch_size': 128, 'max_workers': 11, 'max_embed_workers': 4, 'allowed_languages': {'en', 'es'}, 'file_extensions': ['pdf'], 'deduplication': True, 'similarity_threshold': 0.95, 'incremental': True, 'semantic_chunking': True, 'dynamic_chunking': True, 'reset_vector_collection': False}
2025-05-08 18:24:47,393 - __main__ - INFO - Memoria inicial: 213.23 MB
2025-05-08 18:24:47,393 - __main__ - INFO - Cargando modelo de embeddings: intfloat/multilingual-e5-base...
C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py:1508: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.
  embeddings = HuggingFaceEmbeddings(
2025-05-08 18:24:54,089 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-08 18:24:56,570 - __main__ - ERROR - Error durante el procesamiento: El archivo de paginación es demasiado pequeño para completar la operación. (os error 1455)
2025-05-08 18:24:56,580 - __main__ - ERROR - Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 1508, in main
    embeddings = HuggingFaceEmbeddings(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_core\_api\deprecation.py", line 224, in warn_if_direct_instance
    return wrapped(self, *args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_community\embeddings\huggingface.py", line 92, in __init__
    self.client = sentence_transformers.SentenceTransformer(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 309, in __init__
    modules, self.module_kwargs = self._load_sbert_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 1808, in _load_sbert_model
    module = module_class(model_name_or_path, cache_dir=cache_folder, backend=self.backend, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 81, in __init__
    self._load_model(model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 181, in _load_model
    self.auto_model = AutoModel.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\models\auto\auto_factory.py", line 571, in from_pretrained
    return model_class.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 279, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4399, in from_pretrained
    ) = cls._load_pretrained_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4638, in _load_pretrained_model
    load_state_dict(checkpoint_files[0], map_location="meta", weights_only=weights_only).keys()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 513, in load_state_dict
    with safe_open(checkpoint_file, framework="pt") as f:
OSError: El archivo de paginación es demasiado pequeño para completar la operación. (os error 1455)

2025-05-08 18:24:56,581 - __main__ - CRITICAL - Error crítico en el proceso de ingesta: El archivo de paginación es demasiado pequeño para completar la operación. (os error 1455)
2025-05-08 18:24:56,581 - __main__ - CRITICAL - Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 1508, in main
    embeddings = HuggingFaceEmbeddings(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_core\_api\deprecation.py", line 224, in warn_if_direct_instance
    return wrapped(self, *args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_community\embeddings\huggingface.py", line 92, in __init__
    self.client = sentence_transformers.SentenceTransformer(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 309, in __init__
    modules, self.module_kwargs = self._load_sbert_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 1808, in _load_sbert_model
    module = module_class(model_name_or_path, cache_dir=cache_folder, backend=self.backend, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 81, in __init__
    self._load_model(model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 181, in _load_model
    self.auto_model = AutoModel.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\models\auto\auto_factory.py", line 571, in from_pretrained
    return model_class.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 279, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4399, in from_pretrained
    ) = cls._load_pretrained_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4638, in _load_pretrained_model
    load_state_dict(checkpoint_files[0], map_location="meta", weights_only=weights_only).keys()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 513, in load_state_dict
    with safe_open(checkpoint_file, framework="pt") as f:
OSError: El archivo de paginación es demasiado pequeño para completar la operación. (os error 1455)

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 1684, in <module>
    main()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 1508, in main
    embeddings = HuggingFaceEmbeddings(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_core\_api\deprecation.py", line 224, in warn_if_direct_instance
    return wrapped(self, *args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_community\embeddings\huggingface.py", line 92, in __init__
    self.client = sentence_transformers.SentenceTransformer(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 309, in __init__
    modules, self.module_kwargs = self._load_sbert_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 1808, in _load_sbert_model
    module = module_class(model_name_or_path, cache_dir=cache_folder, backend=self.backend, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 81, in __init__
    self._load_model(model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 181, in _load_model
    self.auto_model = AutoModel.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\models\auto\auto_factory.py", line 571, in from_pretrained
    return model_class.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 279, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4399, in from_pretrained
    ) = cls._load_pretrained_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4638, in _load_pretrained_model
    load_state_dict(checkpoint_files[0], map_location="meta", weights_only=weights_only).keys()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 513, in load_state_dict
    with safe_open(checkpoint_file, framework="pt") as f:
OSError: El archivo de paginación es demasiado pequeño para completar la operación. (os error 1455)

2025-05-08 18:24:57,499 - api.main - ERROR - Error ejecutando ingest.py: 500: Error al procesar el documento: 2025-05-08 18:24:47,392 - __main__ - INFO - Configuración de ingesta cargada: {'docs_dir': WindowsPath('C:/Users/Gonzalo/Desktop/RAG-as-a-Service/backend/api/../docs'), 'cache_dir': WindowsPath('.cache'), 'embed_model': 'intfloat/multilingual-e5-base', 'collection_name': 'manual_e5_multi', 'chunk_size': 384, 'chunk_overlap': 64, 'batch_size': 128, 'max_workers': 11, 'max_embed_workers': 4, 'allowed_languages': {'en', 'es'}, 'file_extensions': ['pdf'], 'deduplication': True, 'similarity_threshold': 0.95, 'incremental': True, 'semantic_chunking': True, 'dynamic_chunking': True, 'reset_vector_collection': False}
2025-05-08 18:24:47,393 - __main__ - INFO - Memoria inicial: 213.23 MB
2025-05-08 18:24:47,393 - __main__ - INFO - Cargando modelo de embeddings: intfloat/multilingual-e5-base...
C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py:1508: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.
  embeddings = HuggingFaceEmbeddings(
2025-05-08 18:24:54,089 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-08 18:24:56,570 - __main__ - ERROR - Error durante el procesamiento: El archivo de paginación es demasiado pequeño para completar la operación. (os error 1455)
2025-05-08 18:24:56,580 - __main__ - ERROR - Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 1508, in main
    embeddings = HuggingFaceEmbeddings(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_core\_api\deprecation.py", line 224, in warn_if_direct_instance
    return wrapped(self, *args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_community\embeddings\huggingface.py", line 92, in __init__
    self.client = sentence_transformers.SentenceTransformer(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 309, in __init__
    modules, self.module_kwargs = self._load_sbert_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 1808, in _load_sbert_model
    module = module_class(model_name_or_path, cache_dir=cache_folder, backend=self.backend, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 81, in __init__
    self._load_model(model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 181, in _load_model
    self.auto_model = AutoModel.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\models\auto\auto_factory.py", line 571, in from_pretrained
    return model_class.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 279, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4399, in from_pretrained
    ) = cls._load_pretrained_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4638, in _load_pretrained_model
    load_state_dict(checkpoint_files[0], map_location="meta", weights_only=weights_only).keys()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 513, in load_state_dict
    with safe_open(checkpoint_file, framework="pt") as f:
OSError: El archivo de paginación es demasiado pequeño para completar la operación. (os error 1455)

2025-05-08 18:24:56,581 - __main__ - CRITICAL - Error crítico en el proceso de ingesta: El archivo de paginación es demasiado pequeño para completar la operación. (os error 1455)
2025-05-08 18:24:56,581 - __main__ - CRITICAL - Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 1508, in main
    embeddings = HuggingFaceEmbeddings(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_core\_api\deprecation.py", line 224, in warn_if_direct_instance
    return wrapped(self, *args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_community\embeddings\huggingface.py", line 92, in __init__
    self.client = sentence_transformers.SentenceTransformer(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 309, in __init__
    modules, self.module_kwargs = self._load_sbert_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 1808, in _load_sbert_model
    module = module_class(model_name_or_path, cache_dir=cache_folder, backend=self.backend, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 81, in __init__
    self._load_model(model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 181, in _load_model
    self.auto_model = AutoModel.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\models\auto\auto_factory.py", line 571, in from_pretrained
    return model_class.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 279, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4399, in from_pretrained
    ) = cls._load_pretrained_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4638, in _load_pretrained_model
    load_state_dict(checkpoint_files[0], map_location="meta", weights_only=weights_only).keys()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 513, in load_state_dict
    with safe_open(checkpoint_file, framework="pt") as f:
OSError: El archivo de paginación es demasiado pequeño para completar la operación. (os error 1455)

Traceback (most recent call last):
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 1684, in <module>
    main()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\ingest.py", line 1508, in main
    embeddings = HuggingFaceEmbeddings(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_core\_api\deprecation.py", line 224, in warn_if_direct_instance
    return wrapped(self, *args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\langchain_community\embeddings\huggingface.py", line 92, in __init__
    self.client = sentence_transformers.SentenceTransformer(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 309, in __init__
    modules, self.module_kwargs = self._load_sbert_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\SentenceTransformer.py", line 1808, in _load_sbert_model
    module = module_class(model_name_or_path, cache_dir=cache_folder, backend=self.backend, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 81, in __init__
    self._load_model(model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\sentence_transformers\models\Transformer.py", line 181, in _load_model
    self.auto_model = AutoModel.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\models\auto\auto_factory.py", line 571, in from_pretrained
    return model_class.from_pretrained(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 279, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4399, in from_pretrained
    ) = cls._load_pretrained_model(
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 4638, in _load_pretrained_model
    load_state_dict(checkpoint_files[0], map_location="meta", weights_only=weights_only).keys()
  File "C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\lib\site-packages\transformers\modeling_utils.py", line 513, in load_state_dict
    with safe_open(checkpoint_file, framework="pt") as f:
OSError: El archivo de paginación es demasiado pequeño para completar la operación. (os error 1455)

2025-05-08 18:24:57,509 - api.main - INFO - Request: POST /upload | Status: 500 | Duration: 15.1565s | Client: 127.0.0.1
2025-05-08 18:26:24,881 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-08 18:27:08,363 - api.main - INFO - Request: POST /upload | Status: 200 | Duration: 43.4914s | Client: 127.0.0.1
2025-05-08 18:27:23,279 - api.main - INFO - Request: OPTIONS /query | Status: 200 | Duration: 0.0054s | Client: 127.0.0.1
2025-05-08 18:27:23,350 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746739643-9240cf", "timestamp": "2025-05-08T18:27:23.349331", "query_length": 196, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 18:27:23,352 - api.main - INFO - Respuesta obtenida de caché para query similar a: '¿Podrías explicarme, como si no supiera nada del tema, cuál es el principal problema que este sistema de efectivo electrónico busca resolver y por qué los métodos tradicionales no son suficientes?'
2025-05-08 18:27:23,364 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0791s | Client: 127.0.0.1
2025-05-08 18:27:34,792 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746739654-fbb79e", "timestamp": "2025-05-08T18:27:34.792818", "query_length": 139, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 18:27:39,686 - api.main - INFO - Document in en, query in es
2025-05-08 18:27:42,688 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-08 18:27:46,986 - api.translation - INFO - Successfully translated text from es to en
2025-05-08 18:27:47,001 - api.main - INFO - Query translated from es to en
2025-05-08 18:27:49,458 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-08 18:27:49,459 - api.main - INFO - After merging: 1 unique documents
2025-05-08 18:27:50,211 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-08 18:27:59,242 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 24.4610s | Client: 127.0.0.1
2025-05-08 18:27:59,244 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-08T18:27:59.244509", "query_length": 139, "num_sources": 1, "execution_time": 24.449814319610596, "language": "unknown"}
2025-05-08 18:29:01,865 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746739741-ebc9d6", "timestamp": "2025-05-08T18:29:01.865139", "query_length": 104, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 18:29:06,158 - api.main - INFO - Document in en, query in es
2025-05-08 18:29:08,961 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-08 18:29:13,599 - api.translation - INFO - Successfully translated text from es to en
2025-05-08 18:29:13,615 - api.main - INFO - Query translated from es to en
2025-05-08 18:29:16,249 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-08 18:29:16,251 - api.main - INFO - After merging: 1 unique documents
2025-05-08 18:29:16,928 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-08 18:29:27,091 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 25.2409s | Client: 127.0.0.1
2025-05-08 18:29:27,096 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-08T18:29:27.096049", "query_length": 104, "num_sources": 1, "execution_time": 25.221906900405884, "language": "unknown"}
2025-05-08 18:31:30,293 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-08 18:32:15,570 - api.main - INFO - Request: POST /upload | Status: 200 | Duration: 45.3208s | Client: 127.0.0.1
2025-05-08 18:32:20,016 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746739940-ebc9d6", "timestamp": "2025-05-08T18:32:20.016492", "query_length": 104, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 18:32:20,020 - api.main - INFO - Respuesta obtenida de caché para query similar a: 'En este sistema, ¿qué impide que alguien simplemente copie una moneda electrónica y la use varias veces?'
2025-05-08 18:32:20,027 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0377s | Client: 127.0.0.1
2025-05-08 18:32:35,160 - api.main - INFO - Cerrando recursos y conexiones
2025-05-08 20:43:33,847 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-08 20:43:33,857 - api.main - INFO - Iniciando aplicación API RAG
2025-05-08 20:43:33,958 - api.main - INFO - Conexión a base de datos verificada
2025-05-08 20:43:33,959 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-08 20:43:33,964 - api.main - INFO - Memoria total: 5.85 GB
2025-05-08 20:43:33,964 - api.main - INFO - Memoria disponible: 0.53 GB
2025-05-08 20:44:06,120 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-08 20:44:51,320 - api.main - INFO - Request: POST /upload | Status: 200 | Duration: 45.2014s | Client: 127.0.0.1
2025-05-08 20:44:58,621 - api.main - INFO - Request: OPTIONS /query | Status: 200 | Duration: 0.0020s | Client: 127.0.0.1
2025-05-08 20:44:58,716 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746747898-a18aa4", "timestamp": "2025-05-08T20:44:58.715477", "query_length": 156, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 20:44:58,718 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-08 20:44:58,735 - api.main - INFO - Inicializando modelo de embeddings
2025-05-08 20:44:59,316 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-08 20:45:16,108 - api.main - INFO - Document in en, query in es
2025-05-08 20:45:18,720 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-08 20:45:30,840 - api.translation - INFO - Successfully translated text from es to en
2025-05-08 20:45:30,888 - api.main - INFO - Query translated from es to en
2025-05-08 20:45:33,916 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-08 20:45:33,917 - api.main - INFO - After merging: 1 unique documents
2025-05-08 20:45:35,078 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-08 20:45:49,900 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 51.2740s | Client: 127.0.0.1
2025-05-08 20:45:49,905 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-08T20:45:49.905903", "query_length": 156, "num_sources": 1, "execution_time": 51.183255672454834, "language": "unknown"}
2025-05-08 21:07:51,518 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-08 21:08:38,269 - api.main - INFO - Request: POST /upload | Status: 200 | Duration: 46.8398s | Client: 127.0.0.1
2025-05-08 21:08:41,899 - api.main - INFO - Request: OPTIONS /query | Status: 200 | Duration: 0.0026s | Client: 127.0.0.1
2025-05-08 21:08:41,959 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746749321-a18aa4", "timestamp": "2025-05-08T21:08:41.958270", "query_length": 156, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 21:08:41,965 - api.main - INFO - Respuesta obtenida de caché para query similar a: '¿Qué pasaría si un grupo de atacantes lograra tener más potencia de CPU que el resto de la red? ¿Podrían hacer cualquier cosa, como crear dinero de la nada?'
2025-05-08 21:08:41,979 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0740s | Client: 127.0.0.1
2025-05-08 21:10:01,828 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746749401-61efac", "timestamp": "2025-05-08T21:10:01.827928", "query_length": 158, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 21:10:10,060 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-08 21:10:17,478 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 15.6553s | Client: 127.0.0.1
2025-05-08 21:10:17,484 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-08T21:10:17.484832", "query_length": 158, "num_sources": 4, "execution_time": 15.644754409790039, "language": "unknown"}
2025-05-08 21:10:28,933 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746749428-61efac", "timestamp": "2025-05-08T21:10:28.932599", "query_length": 158, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 21:10:28,934 - api.main - INFO - Respuesta obtenida de caché para query similar a: 'El texto habla de "reclamar espacio en disco" descartando transacciones antiguas. ¿Cómo es esto posible sin comprometer la integridad de la cadena de bloques?'
2025-05-08 21:10:28,936 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0220s | Client: 127.0.0.1
2025-05-08 21:10:43,361 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-08 21:11:31,241 - api.main - INFO - Request: POST /upload | Status: 200 | Duration: 47.8972s | Client: 127.0.0.1
2025-05-08 21:11:37,703 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746749497-61efac", "timestamp": "2025-05-08T21:11:37.702892", "query_length": 158, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 21:11:37,705 - api.main - INFO - Respuesta obtenida de caché para query similar a: 'El texto habla de "reclamar espacio en disco" descartando transacciones antiguas. ¿Cómo es esto posible sin comprometer la integridad de la cadena de bloques?'
2025-05-08 21:11:37,708 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0150s | Client: 127.0.0.1
2025-05-08 21:11:44,355 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746749504-3e5aaf", "timestamp": "2025-05-08T21:11:44.355198", "query_length": 176, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 21:11:48,260 - api.main - INFO - Document in en, query in es
2025-05-08 21:11:50,874 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-08 21:11:55,586 - api.translation - INFO - Successfully translated text from es to en
2025-05-08 21:11:55,601 - api.main - INFO - Query translated from es to en
2025-05-08 21:11:58,450 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-08 21:11:58,451 - api.main - INFO - After merging: 2 unique documents
2025-05-08 21:11:59,210 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-08 21:12:12,392 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 28.0397s | Client: 127.0.0.1
2025-05-08 21:12:12,396 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-08T21:12:12.396476", "query_length": 176, "num_sources": 2, "execution_time": 28.03219699859619, "language": "unknown"}
2025-05-08 21:14:19,053 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746749659-3e5aaf", "timestamp": "2025-05-08T21:14:19.051495", "query_length": 176, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 21:14:19,061 - api.main - INFO - Respuesta obtenida de caché para query similar a: 'Para alguien que no quiere correr un nodo completo de la red, ¿existe alguna forma simplificada de verificar los pagos y qué tan segura es?    

Fuentes y contenido relacionado'
2025-05-08 21:14:19,068 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0516s | Client: 127.0.0.1
2025-05-08 21:14:22,415 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746749662-3e5aaf", "timestamp": "2025-05-08T21:14:22.415078", "query_length": 176, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 21:14:22,417 - api.main - INFO - Respuesta obtenida de caché para query similar a: 'Para alguien que no quiere correr un nodo completo de la red, ¿existe alguna forma simplificada de verificar los pagos y qué tan segura es?    

Fuentes y contenido relacionado'
2025-05-08 21:14:22,419 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0062s | Client: 127.0.0.1
2025-05-08 21:14:55,394 - api.main - INFO - Cerrando recursos y conexiones
2025-05-08 21:15:18,066 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-08 21:15:18,075 - api.main - INFO - Iniciando aplicación API RAG
2025-05-08 21:15:18,156 - api.main - INFO - Conexión a base de datos verificada
2025-05-08 21:15:18,156 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-08 21:15:18,162 - api.main - INFO - Memoria total: 5.85 GB
2025-05-08 21:15:18,162 - api.main - INFO - Memoria disponible: 0.31 GB
2025-05-08 21:15:52,107 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746749752-3e5aaf", "timestamp": "2025-05-08T21:15:52.107591", "query_length": 176, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 21:15:52,108 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-08 21:15:52,109 - api.main - INFO - Inicializando modelo de embeddings
2025-05-08 21:15:52,312 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-08 21:16:07,539 - api.main - INFO - Document in en, query in es
2025-05-08 21:16:11,481 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-08 21:16:15,776 - api.translation - INFO - Successfully translated text from es to en
2025-05-08 21:16:15,792 - api.main - INFO - Query translated from es to en
2025-05-08 21:16:19,099 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-08 21:16:19,100 - api.main - INFO - After merging: 2 unique documents
2025-05-08 21:16:20,026 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-08 21:16:32,449 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 40.3503s | Client: 127.0.0.1
2025-05-08 21:16:32,452 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-08T21:16:32.452653", "query_length": 176, "num_sources": 2, "execution_time": 40.34196162223816, "language": "unknown"}
2025-05-08 21:19:22,022 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-08 21:20:07,415 - api.main - INFO - Request: POST /upload | Status: 200 | Duration: 45.4861s | Client: 127.0.0.1
2025-05-08 21:20:26,425 - api.main - INFO - Request: OPTIONS /query | Status: 200 | Duration: 0.0050s | Client: 127.0.0.1
2025-05-08 21:20:26,477 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746750026-ebc9d6", "timestamp": "2025-05-08T21:20:26.476584", "query_length": 104, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 21:20:30,066 - api.main - INFO - Document in en, query in es
2025-05-08 21:20:31,836 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-08 21:20:35,667 - api.translation - INFO - Successfully translated text from es to en
2025-05-08 21:20:35,687 - api.main - INFO - Query translated from es to en
2025-05-08 21:20:40,596 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-08 21:20:40,597 - api.main - INFO - After merging: 1 unique documents
2025-05-08 21:20:41,544 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-08 21:20:55,885 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 29.4563s | Client: 127.0.0.1
2025-05-08 21:20:55,891 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-08T21:20:55.891993", "query_length": 104, "num_sources": 1, "execution_time": 29.40204882621765, "language": "unknown"}
2025-05-08 21:22:42,883 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746750162-ebc9d6", "timestamp": "2025-05-08T21:22:42.881092", "query_length": 104, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 21:22:42,892 - api.main - INFO - Respuesta obtenida de caché para query similar a: 'En este sistema, ¿qué impide que alguien simplemente copie una moneda electrónica y la use varias veces?'
2025-05-08 21:22:42,900 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0601s | Client: 127.0.0.1
2025-05-08 21:24:24,495 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746750264-ebc9d6", "timestamp": "2025-05-08T21:24:24.495452", "query_length": 104, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 21:24:24,496 - api.main - INFO - Respuesta obtenida de caché para query similar a: 'En este sistema, ¿qué impide que alguien simplemente copie una moneda electrónica y la use varias veces?'
2025-05-08 21:24:24,498 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0069s | Client: 127.0.0.1
2025-05-08 21:24:38,123 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746750278-ebc9d6", "timestamp": "2025-05-08T21:24:38.121880", "query_length": 104, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 21:24:38,124 - api.main - INFO - Respuesta obtenida de caché para query similar a: 'En este sistema, ¿qué impide que alguien simplemente copie una moneda electrónica y la use varias veces?'
2025-05-08 21:24:38,124 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0043s | Client: 127.0.0.1
2025-05-08 21:24:48,508 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746750288-ebc9d6", "timestamp": "2025-05-08T21:24:48.508603", "query_length": 104, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 21:24:48,509 - api.main - INFO - Respuesta obtenida de caché para query similar a: 'En este sistema, ¿qué impide que alguien simplemente copie una moneda electrónica y la use varias veces?'
2025-05-08 21:24:48,511 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0060s | Client: 127.0.0.1
2025-05-08 21:25:20,186 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746750320-ebc9d6", "timestamp": "2025-05-08T21:25:20.186629", "query_length": 104, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 21:25:20,187 - api.main - INFO - Respuesta obtenida de caché para query similar a: 'En este sistema, ¿qué impide que alguien simplemente copie una moneda electrónica y la use varias veces?'
2025-05-08 21:25:20,187 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0061s | Client: 127.0.0.1
2025-05-08 21:25:29,129 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746750329-40aa6b", "timestamp": "2025-05-08T21:25:29.129794", "query_length": 97, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 21:25:36,266 - api.main - INFO - Document in en, query in es
2025-05-08 21:25:40,411 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-08 21:25:44,653 - api.translation - INFO - Successfully translated text from es to en
2025-05-08 21:25:44,666 - api.main - INFO - Query translated from es to en
2025-05-08 21:25:47,893 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-08 21:25:47,895 - api.main - INFO - After merging: 1 unique documents
2025-05-08 21:25:48,648 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-08 21:25:57,768 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 28.6409s | Client: 127.0.0.1
2025-05-08 21:25:57,775 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-08T21:25:57.775464", "query_length": 97, "num_sources": 1, "execution_time": 28.63089346885681, "language": "unknown"}
2025-05-08 21:29:02,382 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746750542-40aa6b", "timestamp": "2025-05-08T21:29:02.379379", "query_length": 97, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 21:29:02,397 - api.main - INFO - Respuesta obtenida de caché para query similar a: '¿Por qué es importante que la mayoría del poder computacional esté controlado por nodos honestos?'
2025-05-08 21:29:02,406 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0757s | Client: 127.0.0.1
2025-05-08 21:29:21,133 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746750561-40aa6b", "timestamp": "2025-05-08T21:29:21.133079", "query_length": 97, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 21:29:21,135 - api.main - INFO - Respuesta obtenida de caché para query similar a: '¿Por qué es importante que la mayoría del poder computacional esté controlado por nodos honestos?'
2025-05-08 21:29:21,136 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0040s | Client: 127.0.0.1
2025-05-08 21:29:31,842 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746750571-40aa6b", "timestamp": "2025-05-08T21:29:31.841571", "query_length": 97, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 21:29:31,843 - api.main - INFO - Respuesta obtenida de caché para query similar a: '¿Por qué es importante que la mayoría del poder computacional esté controlado por nodos honestos?'
2025-05-08 21:29:31,844 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0053s | Client: 127.0.0.1
2025-05-08 21:29:38,205 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746750578-40aa6b", "timestamp": "2025-05-08T21:29:38.205279", "query_length": 97, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 21:29:38,206 - api.main - INFO - Respuesta obtenida de caché para query similar a: '¿Por qué es importante que la mayoría del poder computacional esté controlado por nodos honestos?'
2025-05-08 21:29:38,207 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0060s | Client: 127.0.0.1
2025-05-08 22:21:35,881 - api.main - INFO - Request: OPTIONS /query | Status: 200 | Duration: 0.0050s | Client: 127.0.0.1
2025-05-08 22:21:36,153 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746753696-40aa6b", "timestamp": "2025-05-08T22:21:36.152419", "query_length": 97, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 22:21:36,156 - api.main - INFO - Respuesta obtenida de caché para query similar a: '¿Por qué es importante que la mayoría del poder computacional esté controlado por nodos honestos?'
2025-05-08 22:21:36,163 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0295s | Client: 127.0.0.1
2025-05-08 22:21:43,741 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746753703-40aa6b", "timestamp": "2025-05-08T22:21:43.741370", "query_length": 97, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 22:21:43,742 - api.main - INFO - Respuesta obtenida de caché para query similar a: '¿Por qué es importante que la mayoría del poder computacional esté controlado por nodos honestos?'
2025-05-08 22:21:43,743 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0050s | Client: 127.0.0.1
2025-05-08 22:21:54,764 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746753714-40aa6b", "timestamp": "2025-05-08T22:21:54.764972", "query_length": 97, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 22:21:54,765 - api.main - INFO - Respuesta obtenida de caché para query similar a: '¿Por qué es importante que la mayoría del poder computacional esté controlado por nodos honestos?'
2025-05-08 22:21:54,767 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0040s | Client: 127.0.0.1
2025-05-08 22:24:32,292 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746753872-40aa6b", "timestamp": "2025-05-08T22:24:32.290639", "query_length": 97, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 22:24:32,297 - api.main - INFO - Respuesta obtenida de caché para query similar a: '¿Por qué es importante que la mayoría del poder computacional esté controlado por nodos honestos?'
2025-05-08 22:24:32,300 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0241s | Client: 127.0.0.1
2025-05-08 22:25:28,465 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746753928-40aa6b", "timestamp": "2025-05-08T22:25:28.465478", "query_length": 97, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 22:25:28,465 - api.main - INFO - Respuesta obtenida de caché para query similar a: '¿Por qué es importante que la mayoría del poder computacional esté controlado por nodos honestos?'
2025-05-08 22:25:28,467 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0050s | Client: 127.0.0.1
2025-05-08 22:26:11,539 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746753971-40aa6b", "timestamp": "2025-05-08T22:26:11.539271", "query_length": 97, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 22:26:11,541 - api.main - INFO - Respuesta obtenida de caché para query similar a: '¿Por qué es importante que la mayoría del poder computacional esté controlado por nodos honestos?'
2025-05-08 22:26:11,542 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0074s | Client: 127.0.0.1
2025-05-08 22:27:34,074 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746754054-40aa6b", "timestamp": "2025-05-08T22:27:34.074761", "query_length": 97, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 22:27:34,075 - api.main - INFO - Respuesta obtenida de caché para query similar a: '¿Por qué es importante que la mayoría del poder computacional esté controlado por nodos honestos?'
2025-05-08 22:27:34,077 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0591s | Client: 127.0.0.1
2025-05-08 22:28:26,821 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746754106-40aa6b", "timestamp": "2025-05-08T22:28:26.821272", "query_length": 97, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 22:28:26,823 - api.main - INFO - Respuesta obtenida de caché para query similar a: '¿Por qué es importante que la mayoría del poder computacional esté controlado por nodos honestos?'
2025-05-08 22:28:26,824 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0050s | Client: 127.0.0.1
2025-05-08 22:31:29,090 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746754289-40aa6b", "timestamp": "2025-05-08T22:31:29.090450", "query_length": 97, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 22:31:29,091 - api.main - INFO - Respuesta obtenida de caché para query similar a: '¿Por qué es importante que la mayoría del poder computacional esté controlado por nodos honestos?'
2025-05-08 22:31:29,093 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0050s | Client: 127.0.0.1
2025-05-08 22:32:30,835 - api.main - INFO - Request: OPTIONS /query | Status: 200 | Duration: 0.0030s | Client: 127.0.0.1
2025-05-08 22:32:30,844 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746754350-d218a6", "timestamp": "2025-05-08T22:32:30.844403", "query_length": 76, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 22:32:36,678 - api.main - INFO - Document in en, query in es
2025-05-08 22:32:40,830 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-08 22:32:44,682 - api.translation - INFO - Successfully translated text from es to en
2025-05-08 22:32:44,696 - api.main - INFO - Query translated from es to en
2025-05-08 22:32:47,903 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-08 22:32:47,905 - api.main - INFO - After merging: 2 unique documents
2025-05-08 22:32:48,852 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-08 22:33:05,505 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 34.6580s | Client: 127.0.0.1
2025-05-08 22:33:05,522 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-08T22:33:05.521592", "query_length": 76, "num_sources": 2, "execution_time": 34.62714338302612, "language": "unknown"}
2025-05-08 22:34:28,995 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746754468-d218a6", "timestamp": "2025-05-08T22:34:28.994988", "query_length": 76, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 22:34:29,000 - api.main - INFO - Respuesta obtenida de caché para query similar a: '¿Cómo se asegura la red de Bitcoin de que la cadena más larga sea la válida?'
2025-05-08 22:34:29,004 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0678s | Client: 127.0.0.1
2025-05-08 22:34:45,647 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746754485-d218a6", "timestamp": "2025-05-08T22:34:45.647146", "query_length": 76, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-08 22:34:45,648 - api.main - INFO - Respuesta obtenida de caché para query similar a: '¿Cómo se asegura la red de Bitcoin de que la cadena más larga sea la válida?'
2025-05-08 22:34:45,649 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 0.0060s | Client: 127.0.0.1
2025-05-09 00:02:48,042 - api.main - INFO - Request: OPTIONS /query | Status: 200 | Duration: 0.0066s | Client: 127.0.0.1
2025-05-09 00:02:48,281 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746759768-4524fb", "timestamp": "2025-05-09T00:02:48.280154", "query_length": 36, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": false}
2025-05-09 00:02:56,882 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-09 00:03:16,345 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 28.0874s | Client: 127.0.0.1
2025-05-09 00:03:16,352 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-09T00:03:16.351393", "query_length": 36, "num_sources": 4, "execution_time": 28.063286304473877, "language": "unknown"}
2025-05-09 15:32:34,131 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-09 15:32:34,139 - api.main - INFO - Iniciando aplicación API RAG
2025-05-09 15:32:38,211 - api.main - ERROR - Error durante la inicialización: connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

2025-05-09 15:33:38,487 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-09 15:33:38,496 - api.main - INFO - Iniciando aplicación API RAG
2025-05-09 15:33:38,610 - api.main - INFO - Conexión a base de datos verificada
2025-05-09 15:33:38,610 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-09 15:33:38,618 - api.main - INFO - Memoria total: 5.85 GB
2025-05-09 15:33:38,619 - api.main - INFO - Memoria disponible: 0.25 GB
2025-05-09 15:34:07,471 - api.main - INFO - Request: GET /upload | Status: 405 | Duration: 0.0106s | Client: 127.0.0.1
2025-05-09 15:34:08,369 - api.main - INFO - Request: GET /favicon.ico | Status: 404 | Duration: 0.0010s | Client: 127.0.0.1
2025-05-11 11:32:20,177 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-11 11:32:20,187 - api.main - INFO - Iniciando aplicación API RAG
2025-05-11 11:32:20,227 - api.main - INFO - Conexión a base de datos verificada
2025-05-11 11:32:20,227 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-11 11:32:20,235 - api.main - INFO - Memoria total: 5.85 GB
2025-05-11 11:32:20,236 - api.main - INFO - Memoria disponible: 0.42 GB
2025-05-11 11:35:13,305 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-11 11:36:01,912 - api.main - INFO - Request: POST /upload | Status: 200 | Duration: 48.6825s | Client: 127.0.0.1
2025-05-11 11:37:01,238 - api.main - INFO - Request: OPTIONS /query | Status: 200 | Duration: 0.0047s | Client: 127.0.0.1
2025-05-11 11:37:01,376 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746974221-f05805", "timestamp": "2025-05-11T11:37:01.376975", "query_length": 149, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-11 11:37:01,383 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-11 11:37:01,409 - api.main - INFO - Inicializando modelo de embeddings
2025-05-11 11:37:02,108 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-11 11:37:17,490 - api.main - INFO - Document in en, query in es
2025-05-11 11:37:20,682 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-11 11:37:28,638 - api.translation - INFO - Successfully translated text from es to en
2025-05-11 11:37:28,652 - api.main - INFO - Query translated from es to en
2025-05-11 11:37:32,493 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-11 11:37:32,494 - api.main - INFO - After merging: 3 unique documents
2025-05-11 11:37:33,415 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 11:37:53,289 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 52.0439s | Client: 127.0.0.1
2025-05-11 11:37:53,291 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-11T11:37:53.291983", "query_length": 149, "num_sources": 2, "execution_time": 51.91239786148071, "language": "unknown"}
2025-05-11 11:38:29,623 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746974309-951bfc", "timestamp": "2025-05-11T11:38:29.623091", "query_length": 148, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-11 11:38:33,139 - api.main - INFO - Document in en, query in es
2025-05-11 11:38:36,274 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-11 11:38:41,200 - api.translation - INFO - Successfully translated text from es to en
2025-05-11 11:38:41,216 - api.main - INFO - Query translated from es to en
2025-05-11 11:38:44,188 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-11 11:38:44,188 - api.main - INFO - After merging: 3 unique documents
2025-05-11 11:38:44,704 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 11:39:07,083 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 37.4637s | Client: 127.0.0.1
2025-05-11 11:39:07,085 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-11T11:39:07.085742", "query_length": 148, "num_sources": 3, "execution_time": 37.45972681045532, "language": "unknown"}
2025-05-11 11:50:18,193 - api.main - INFO - Request: OPTIONS /query | Status: 200 | Duration: 0.0083s | Client: 127.0.0.1
2025-05-11 11:50:18,391 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746975018-904572", "timestamp": "2025-05-11T11:50:18.390536", "query_length": 158, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-11 11:50:25,721 - api.main - INFO - Document in en, query in es
2025-05-11 11:50:29,529 - api.translation - INFO - Initializing translation model Helsinki-NLP/opus-mt-es-en on CPU
2025-05-11 11:50:34,939 - api.translation - INFO - Successfully translated text from es to en
2025-05-11 11:50:34,954 - api.main - INFO - Query translated from es to en
2025-05-11 11:50:38,939 - api.main - INFO - Retrieved 4 documents from translated query
2025-05-11 11:50:38,941 - api.main - INFO - After merging: 4 unique documents
2025-05-11 11:50:40,009 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 11:51:02,158 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 43.8141s | Client: 127.0.0.1
2025-05-11 11:51:02,165 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-11T11:51:02.165598", "query_length": 158, "num_sources": 4, "execution_time": 43.762696504592896, "language": "unknown"}
2025-05-11 11:57:26,980 - api.main - INFO - Cerrando recursos y conexiones
2025-05-11 11:57:51,820 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-11 11:57:51,846 - api.main - INFO - Iniciando aplicación API RAG
2025-05-11 11:57:51,962 - api.main - INFO - Conexión a base de datos verificada
2025-05-11 11:57:51,963 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-11 11:57:51,973 - api.main - INFO - Memoria total: 5.85 GB
2025-05-11 11:57:51,973 - api.main - INFO - Memoria disponible: 0.47 GB
2025-05-11 11:58:05,338 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-11 11:58:05,344 - api.main - INFO - Iniciando aplicación API RAG
2025-05-11 11:58:05,396 - api.main - INFO - Conexión a base de datos verificada
2025-05-11 11:58:05,397 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-11 11:58:05,403 - api.main - INFO - Memoria total: 5.85 GB
2025-05-11 11:58:05,403 - api.main - INFO - Memoria disponible: 0.56 GB
2025-05-11 11:58:25,238 - api.main - INFO - Cerrando recursos y conexiones
2025-05-11 11:58:41,119 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-11 11:58:41,130 - api.main - INFO - Iniciando aplicación API RAG
2025-05-11 11:58:41,174 - api.main - INFO - Conexión a base de datos verificada
2025-05-11 11:58:41,174 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-11 11:58:41,182 - api.main - INFO - Memoria total: 5.85 GB
2025-05-11 11:58:41,182 - api.main - INFO - Memoria disponible: 0.40 GB
2025-05-11 11:59:53,893 - api.main - INFO - Cerrando recursos y conexiones
2025-05-11 12:00:20,488 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-11 12:00:20,506 - api.main - INFO - Iniciando aplicación API RAG
2025-05-11 12:00:20,720 - api.main - INFO - Conexión a base de datos verificada
2025-05-11 12:00:20,721 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-11 12:00:20,730 - api.main - INFO - Memoria total: 5.85 GB
2025-05-11 12:00:20,730 - api.main - INFO - Memoria disponible: 0.38 GB
2025-05-11 12:00:45,819 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-11 12:00:45,833 - api.main - INFO - Iniciando aplicación API RAG
2025-05-11 12:00:45,894 - api.main - INFO - Conexión a base de datos verificada
2025-05-11 12:00:45,896 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-11 12:00:45,906 - api.main - INFO - Memoria total: 5.85 GB
2025-05-11 12:00:45,907 - api.main - INFO - Memoria disponible: 0.52 GB
2025-05-11 12:00:46,872 - api.main - INFO - Cerrando recursos y conexiones
2025-05-11 12:01:09,049 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-11 12:01:09,060 - api.main - INFO - Iniciando aplicación API RAG
2025-05-11 12:01:09,105 - api.main - INFO - Conexión a base de datos verificada
2025-05-11 12:01:09,105 - api.main - INFO - No se detectó GPU, usando CPU
2025-05-11 12:01:09,111 - api.main - INFO - Memoria total: 5.85 GB
2025-05-11 12:01:09,112 - api.main - INFO - Memoria disponible: 0.37 GB
2025-05-11 12:01:26,465 - api.main - INFO - Usando Python para ingest: C:\Users\Gonzalo\Desktop\RAG-as-a-Service\backend\.venv\Scripts\python.exe
2025-05-11 12:04:35,801 - api.main - INFO - Request: POST /upload | Status: 200 | Duration: 189.3415s | Client: 127.0.0.1
2025-05-11 12:09:05,239 - api.main - INFO - Request: OPTIONS /query | Status: 200 | Duration: 0.0088s | Client: 127.0.0.1
2025-05-11 12:09:05,372 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746976145-607a6e", "timestamp": "2025-05-11T12:09:05.370498", "query_length": 89, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-11 12:09:05,376 - api.main - INFO - Inicializando retriever con optimización de lotes
2025-05-11 12:09:05,398 - api.main - INFO - Inicializando modelo de embeddings
2025-05-11 12:09:06,035 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-base
2025-05-11 12:09:25,711 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 12:09:41,833 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 36.5848s | Client: 127.0.0.1
2025-05-11 12:09:41,839 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-11T12:09:41.838661", "query_length": 89, "num_sources": 4, "execution_time": 36.46150255203247, "language": "unknown"}
2025-05-11 12:10:13,221 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746976213-46392d", "timestamp": "2025-05-11T12:10:13.221448", "query_length": 112, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-11 12:10:16,074 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 12:10:26,042 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 12.8281s | Client: 127.0.0.1
2025-05-11 12:10:26,044 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-11T12:10:26.044188", "query_length": 112, "num_sources": 3, "execution_time": 12.821579456329346, "language": "unknown"}
2025-05-11 12:10:53,425 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746976253-3a239c", "timestamp": "2025-05-11T12:10:53.424606", "query_length": 97, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-11 12:10:56,638 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 12:11:07,407 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 13.9962s | Client: 127.0.0.1
2025-05-11 12:11:07,411 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-11T12:11:07.410687", "query_length": 97, "num_sources": 4, "execution_time": 13.982823133468628, "language": "unknown"}
2025-05-11 12:11:28,746 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746976288-0d1bdc", "timestamp": "2025-05-11T12:11:28.746809", "query_length": 45, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-11 12:11:31,396 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 12:11:45,440 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 16.6950s | Client: 127.0.0.1
2025-05-11 12:11:45,441 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-11T12:11:45.441849", "query_length": 45, "num_sources": 4, "execution_time": 16.69284415245056, "language": "unknown"}
2025-05-11 12:12:02,453 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746976322-713a00", "timestamp": "2025-05-11T12:12:02.453522", "query_length": 74, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-11 12:12:05,396 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 12:12:15,768 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 13.3166s | Client: 127.0.0.1
2025-05-11 12:12:15,770 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-11T12:12:15.770710", "query_length": 74, "num_sources": 4, "execution_time": 13.313779592514038, "language": "unknown"}
2025-05-11 12:26:20,367 - api.main - INFO - Request: OPTIONS /query | Status: 200 | Duration: 0.0081s | Client: 127.0.0.1
2025-05-11 12:26:20,565 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746977180-2dd919", "timestamp": "2025-05-11T12:26:20.564728", "query_length": 106, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-11 12:26:26,343 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 12:26:35,444 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 14.9092s | Client: 127.0.0.1
2025-05-11 12:26:35,447 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-11T12:26:35.447306", "query_length": 106, "num_sources": 4, "execution_time": 14.881358861923218, "language": "unknown"}
2025-05-11 12:48:02,598 - api.main - INFO - Request: OPTIONS /query | Status: 200 | Duration: 0.0068s | Client: 127.0.0.1
2025-05-11 12:48:02,796 - api.main - INFO - Nueva consulta recibida: {"query_id": "q-1746978482-16a31d", "timestamp": "2025-05-11T12:48:02.795764", "query_length": 96, "detected_language": null, "client_ip": "127.0.0.1", "detailed_feedback_requested": true}
2025-05-11 12:48:09,606 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 12:48:21,759 - api.main - INFO - Request: POST /query | Status: 200 | Duration: 18.9930s | Client: 127.0.0.1
2025-05-11 12:48:21,764 - api.main - INFO - Métricas de consulta: {"timestamp": "2025-05-11T12:48:21.764209", "query_length": 96, "num_sources": 4, "execution_time": 18.955931425094604, "language": "unknown"}
2025-05-11 13:00:12,769 - api.main - INFO - Request: GET /docs | Status: 200 | Duration: 0.0199s | Client: 127.0.0.1
2025-05-11 13:00:13,794 - api.main - INFO - Request: GET /openapi.json | Status: 200 | Duration: 0.1676s | Client: 127.0.0.1
2025-05-11 13:00:17,012 - api.main - INFO - Request: GET /docs | Status: 200 | Duration: 0.0084s | Client: 127.0.0.1
2025-05-11 13:00:17,226 - api.main - INFO - Request: GET /openapi.json | Status: 200 | Duration: 0.0011s | Client: 127.0.0.1
2025-05-11 13:00:18,792 - api.main - INFO - Request: GET / | Status: 404 | Duration: 0.0028s | Client: 127.0.0.1
2025-05-11 13:00:19,026 - api.main - INFO - Request: GET /favicon.ico | Status: 404 | Duration: 0.0013s | Client: 127.0.0.1
2025-05-11 13:17:09,421 - api.main - INFO - Cerrando recursos y conexiones
2025-05-12 17:47:18,275 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-12 17:47:18,288 - api.main - INFO - Iniciando aplicación API RAG
2025-05-12 17:47:22,395 - api.main - ERROR - Error durante la inicialización: connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

2025-05-12 17:49:41,405 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-12 17:49:41,414 - api.main - INFO - Iniciando aplicación API RAG
2025-05-12 17:49:45,480 - api.main - ERROR - Error durante la inicialización: connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

2025-05-12 17:51:30,382 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-12 17:52:28,976 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-12 18:11:10,393 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-12 18:12:17,550 - api.main - CRITICAL - Error al cargar configuración: 13 validation errors for Settings
pg_conn
  Field required [type=missing, input_value={'deepseek_api_key': 'sk-...ombshafewg.supabase.co'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
postgres_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres://postgres.lxmz...uire&supa=base-pooler.x', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_prisma_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres://postgres.lxmz...uire&supa=base-pooler.x', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
supabase_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='https://lxmzevbsruombshafewg.supabase.co', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
next_public_supabase_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='https://lxmzevbsruombshafewg.supabase.co', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_url_non_pooling
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres://postgres.lxmz...ostgres?sslmode=require', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
supabase_jwt_secret
  Extra inputs are not permitted [type=extra_forbidden, input_value='j15MQvn9eBYrlA/nTZsOyn3d...Qg/P+XrVb7aYlCgzbStNQ==', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_user
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
next_public_supabase_anon_key
  Extra inputs are not permitted [type=extra_forbidden, input_value='eyJhbGciOiJIUzI1NiIsInR5...TaKuzCsruANY-Wa3XeoZvpU', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_password
  Extra inputs are not permitted [type=extra_forbidden, input_value='JXEyuLLHxXe6U1Lq', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_database
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
supabase_service_role_key
  Extra inputs are not permitted [type=extra_forbidden, input_value='eyJhbGciOiJIUzI1NiIsInR5...W3R5vd2MR4Uif9H7wN2DdD8', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_host
  Extra inputs are not permitted [type=extra_forbidden, input_value='db.lxmzevbsruombshafewg.supabase.co', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
2025-05-12 18:12:54,309 - api.main - CRITICAL - Error al cargar configuración: 12 validation errors for Settings
postgres_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres://postgres.lxmz...uire&supa=base-pooler.x', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_prisma_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres://postgres.lxmz...uire&supa=base-pooler.x', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
supabase_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='https://lxmzevbsruombshafewg.supabase.co', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
next_public_supabase_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='https://lxmzevbsruombshafewg.supabase.co', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_url_non_pooling
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres://postgres.lxmz...ostgres?sslmode=require', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
supabase_jwt_secret
  Extra inputs are not permitted [type=extra_forbidden, input_value='j15MQvn9eBYrlA/nTZsOyn3d...Qg/P+XrVb7aYlCgzbStNQ==', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_user
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
next_public_supabase_anon_key
  Extra inputs are not permitted [type=extra_forbidden, input_value='eyJhbGciOiJIUzI1NiIsInR5...TaKuzCsruANY-Wa3XeoZvpU', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_password
  Extra inputs are not permitted [type=extra_forbidden, input_value='JXEyuLLHxXe6U1Lq', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_database
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
supabase_service_role_key
  Extra inputs are not permitted [type=extra_forbidden, input_value='eyJhbGciOiJIUzI1NiIsInR5...W3R5vd2MR4Uif9H7wN2DdD8', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_host
  Extra inputs are not permitted [type=extra_forbidden, input_value='db.lxmzevbsruombshafewg.supabase.co', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
2025-05-12 18:13:49,135 - api.main - CRITICAL - Error al cargar configuración: 13 validation errors for Settings
pg_conn
  Field required [type=missing, input_value={'deepseek_api_key': 'sk-...ombshafewg.supabase.co'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
postgres_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres://postgres.lxmz...uire&supa=base-pooler.x', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_prisma_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres://postgres.lxmz...uire&supa=base-pooler.x', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
supabase_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='https://lxmzevbsruombshafewg.supabase.co', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
next_public_supabase_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='https://lxmzevbsruombshafewg.supabase.co', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_url_non_pooling
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres://postgres.lxmz...ostgres?sslmode=require', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
supabase_jwt_secret
  Extra inputs are not permitted [type=extra_forbidden, input_value='j15MQvn9eBYrlA/nTZsOyn3d...Qg/P+XrVb7aYlCgzbStNQ==', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_user
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
next_public_supabase_anon_key
  Extra inputs are not permitted [type=extra_forbidden, input_value='eyJhbGciOiJIUzI1NiIsInR5...TaKuzCsruANY-Wa3XeoZvpU', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_password
  Extra inputs are not permitted [type=extra_forbidden, input_value='JXEyuLLHxXe6U1Lq', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_database
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
supabase_service_role_key
  Extra inputs are not permitted [type=extra_forbidden, input_value='eyJhbGciOiJIUzI1NiIsInR5...W3R5vd2MR4Uif9H7wN2DdD8', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_host
  Extra inputs are not permitted [type=extra_forbidden, input_value='db.lxmzevbsruombshafewg.supabase.co', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
2025-05-12 18:25:18,631 - api.main - CRITICAL - Error al cargar configuración: 2 validation errors for Settings
supabase_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='https://lxmzevbsruombshafewg.supabase.co', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
supabase_service_role_key
  Extra inputs are not permitted [type=extra_forbidden, input_value='eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
2025-05-12 18:26:51,948 - api.main - CRITICAL - Error al cargar configuración: 12 validation errors for Settings
postgres_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres://postgres.lxmz...uire&supa=base-pooler.x', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_prisma_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres://postgres.lxmz...uire&supa=base-pooler.x', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
supabase_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='https://lxmzevbsruombshafewg.supabase.co', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
next_public_supabase_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='https://lxmzevbsruombshafewg.supabase.co', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_url_non_pooling
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres://postgres.lxmz...ostgres?sslmode=require', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
supabase_jwt_secret
  Extra inputs are not permitted [type=extra_forbidden, input_value='j15MQvn9eBYrlA/nTZsOyn3d...Qg/P+XrVb7aYlCgzbStNQ==', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_user
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
next_public_supabase_anon_key
  Extra inputs are not permitted [type=extra_forbidden, input_value='eyJhbGciOiJIUzI1NiIsInR5...TaKuzCsruANY-Wa3XeoZvpU', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_password
  Extra inputs are not permitted [type=extra_forbidden, input_value='JXEyuLLHxXe6U1Lq', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_database
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
supabase_service_role_key
  Extra inputs are not permitted [type=extra_forbidden, input_value='eyJhbGciOiJIUzI1NiIsInR5...W3R5vd2MR4Uif9H7wN2DdD8', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_host
  Extra inputs are not permitted [type=extra_forbidden, input_value='db.lxmzevbsruombshafewg.supabase.co', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
2025-05-12 18:27:51,123 - api.main - CRITICAL - Error al cargar configuración: 12 validation errors for Settings
postgres_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres://postgres.lxmz...uire&supa=base-pooler.x', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_prisma_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres://postgres.lxmz...uire&supa=base-pooler.x', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
supabase_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='https://lxmzevbsruombshafewg.supabase.co', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
next_public_supabase_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='https://lxmzevbsruombshafewg.supabase.co', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_url_non_pooling
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres://postgres.lxmz...ostgres?sslmode=require', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
supabase_jwt_secret
  Extra inputs are not permitted [type=extra_forbidden, input_value='j15MQvn9eBYrlA/nTZsOyn3d...Qg/P+XrVb7aYlCgzbStNQ==', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_user
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
next_public_supabase_anon_key
  Extra inputs are not permitted [type=extra_forbidden, input_value='eyJhbGciOiJIUzI1NiIsInR5...TaKuzCsruANY-Wa3XeoZvpU', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_password
  Extra inputs are not permitted [type=extra_forbidden, input_value='JXEyuLLHxXe6U1Lq', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_database
  Extra inputs are not permitted [type=extra_forbidden, input_value='postgres', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
supabase_service_role_key
  Extra inputs are not permitted [type=extra_forbidden, input_value='eyJhbGciOiJIUzI1NiIsInR5...W3R5vd2MR4Uif9H7wN2DdD8', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
postgres_host
  Extra inputs are not permitted [type=extra_forbidden, input_value='db.lxmzevbsruombshafewg.supabase.co', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
2025-05-12 18:29:15,039 - api.main - CRITICAL - Error al cargar configuración: 2 validation errors for Settings
supabase_url
  Extra inputs are not permitted [type=extra_forbidden, input_value='https://lxmzevbsruombshafewg.supabase.co', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
supabase_service_role_key
  Extra inputs are not permitted [type=extra_forbidden, input_value='eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden
2025-05-12 18:29:38,008 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-12 18:30:31,484 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-12 18:33:32,777 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-12 18:34:16,686 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-12 18:36:22,327 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-12 18:40:35,660 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-12 18:41:26,713 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-12 18:41:26,812 - api.main - INFO - Iniciando aplicación API RAG
2025-05-12 18:41:26,859 - api.main - ERROR - Error durante la inicialización: could not translate host name "db.lxmzevbsruombshafewg.supabase.co" to address: Host desconocido. 

2025-05-12 18:44:09,240 - api.main - WARNING - Production environment with wildcard CORS origins is not recommended
2025-05-12 18:44:09,326 - api.main - INFO - Iniciando aplicación API RAG
2025-05-12 18:44:51,435 - api.main - ERROR - Error durante la inicialización: connection to server at "lxmzevbsruombshafewg.supabase.co" (172.64.149.246), port 5432 failed: Connection timed out (0x0000274C/10060)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "lxmzevbsruombshafewg.supabase.co" (104.18.38.10), port 5432 failed: Connection timed out (0x0000274C/10060)
	Is the server running on that host and accepting TCP/IP connections?

